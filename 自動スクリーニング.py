# -*- coding: utf-8 -*-
"""
è‡ªå‹•ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°_å®Œå…¨çµ±åˆç‰ˆ + å³è‚©ä¸ŠãŒã‚Šï¼ˆTemplateç‰ˆ/ä¸¡ç«‹ãƒ•ã‚£ãƒ«ã‚¿/Gmail/ã‚ªãƒ•ãƒ©ã‚¤ãƒ³HTML/ç¥æ—¥å¯¾å¿œ/MIDDAYè‡ªå‹•ï¼‰

ä¿®æ­£ç‚¹ï¼ˆã“ã®ç‰ˆï¼‰
- HTMLå‡ºåŠ›ãƒ•ã‚§ãƒ¼ã‚ºã® JSON ç”Ÿæˆã§ã€DataFrame å†…ã® bytes / NaN / pandas.Timestamp / NumPy ã‚¹ã‚«ãƒ©ãƒ¼ã‚’
  å®‰å…¨ã«å¤‰æ›ã§ãã‚‹ã‚ˆã†ã«ä¿®æ­£ï¼ˆTypeError: bytes is not JSON serializable å¯¾ç­–ï¼‰

æ©Ÿèƒ½ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆ
- EOD/MIDDAY è‡ªå‹•åˆ¤å®šï¼ˆJST 11:30â€“12:30 ã¯ MIDDAY ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã€ãã‚Œä»¥å¤–ã¯ EODï¼‰
- ç¥æ—¥/åœŸæ—¥ã‚¹ã‚­ãƒƒãƒ—ï¼ˆjpholiday + è¿½åŠ ä¼‘å ´æ—¥ãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œï¼‰
- yahooquery ã§ quotes / history ã‚’ä¸€æ‹¬å–å¾—ï¼ˆåˆå›ã¯ 12moã€é€šå¸¸ã¯ 10dï¼‰
- åˆå‹•/åº•æ‰“ã¡/ä¸Šæ˜‡ä½™åœ°ã‚¹ã‚³ã‚¢/å³è‚©ä¸ŠãŒã‚Šã‚¹ã‚³ã‚¢ ã®åˆ¤å®šã¨ãƒ­ã‚°ï¼ˆsignals_logï¼‰
- å‰å–¶æ¥­æ—¥ã®ç¿Œæ—¥æ¤œè¨¼ï¼ˆåˆ¤å®šã¨CSVå‡ºåŠ›ï¼‰
- ã‚ªãƒ•ãƒ©ã‚¤ãƒ³1ãƒ•ã‚¡ã‚¤ãƒ«HTMLãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼ˆå€™è£œä¸€è¦§/æ¤œè¨¼/å…¨ã‚«ãƒ©ãƒ /price_history/signals_logï¼‰
- Gmail ã§ index.html ã‚’é€ä¿¡ï¼ˆä»»æ„ã€ZIPåŒæ¢±å¯ï¼‰

å‰æ: Python 3.11 / pip install yahooquery pandas jpholiday
"""

from email.message import EmailMessage
from jinja2 import Environment, FileSystemLoader, select_autoescape
from logging.handlers import RotatingFileHandler
from markupsafe import Markup, escape
from pathlib import Path
from typing import Literal
from urllib.parse import quote as _q
from zoneinfo import ZoneInfo
import datetime as dtm
import jpholiday
import json
import logging
import math
import numpy as np
import os
import pandas as pd
import re
import requests
import smtplib
import sqlite3
import ssl
import subprocess
import sys
import time
import warnings
import webbrowser
import yfinance as yf
import zipfile
from yahooquery import Ticker as YQ

# ========= bulk utils (v8 additions) =========
def _chunked(seq, n=500):
    it = iter(seq)
    while True:
        buf = []
        try:
            for _ in range(n):
                buf.append(next(it))
        except StopIteration:
            if buf: 
                yield buf
            break
        yield buf

def exec_many(conn, sql, rows, chunk=500):
    cur = conn.cursor()
    try:
        for part in _chunked(rows, chunk):
            cur.executemany(sql, part)
        conn.commit()
    finally:
        cur.close()
# ========= end bulk utils =========
# ========= price series features (v9 additions) =========
def add_price_features(df):
    """
    ä¾¡æ ¼ç³»åˆ—ã®å…¸å‹æŒ‡æ¨™ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã§ä¸€æ‹¬ä»˜ä¸ã™ã‚‹ãƒ†ãƒ³ãƒ—ãƒ¬é–¢æ•°ã€‚
    - å‰æ: df ã« ['ã‚³ãƒ¼ãƒ‰','æ—¥ä»˜','çµ‚å€¤','é«˜å€¤','å®‰å€¤','å‡ºæ¥é«˜'] ãŒã‚ã‚‹
    - å‡ºåŠ›: åŒã˜ df ã«å„ç¨®åˆ—ã‚’è¿½åŠ ã—ã¦è¿”ã™ï¼ˆinplaceã§ã¯ãªã„ï¼‰
    """
    if df.empty:
        return df
    # é˜²å¾¡: å¿…é ˆåˆ—ã®ã¿ã§é€²ã‚ã‚‹
    need = ["ã‚³ãƒ¼ãƒ‰","æ—¥ä»˜","çµ‚å€¤"]
    for c in need:
        if c not in df.columns:
            return df

    df = df.sort_values(["ã‚³ãƒ¼ãƒ‰","æ—¥ä»˜"]).copy()
    grp = df.groupby("ã‚³ãƒ¼ãƒ‰", sort=False)

    # ç§»å‹•å¹³å‡
    if "çµ‚å€¤" in df.columns:
        df["çµ‚å€¤_ma5"]  = grp["çµ‚å€¤"].transform(lambda s: s.rolling(5,  min_periods=1).mean())
        df["çµ‚å€¤_ma13"] = grp["çµ‚å€¤"].transform(lambda s: s.rolling(13, min_periods=1).mean())
        df["çµ‚å€¤_ma20"] = grp["çµ‚å€¤"].transform(lambda s: s.rolling(20, min_periods=1).mean())
        df["çµ‚å€¤_ma26"] = grp["çµ‚å€¤"].transform(lambda s: s.rolling(26, min_periods=1).mean())

    # å‡ºæ¥é«˜å¹³å‡ã¨RVOL
    if "å‡ºæ¥é«˜" in df.columns:
        df["å‡ºæ¥é«˜_ma5"]  = grp["å‡ºæ¥é«˜"].transform(lambda s: s.rolling(5,  min_periods=1).mean())
        df["å‡ºæ¥é«˜_ma20"] = grp["å‡ºæ¥é«˜"].transform(lambda s: s.rolling(20, min_periods=1).mean())
        with pd.option_context('mode.use_inf_as_na', True):
            df["RVOL20"] = (df["å‡ºæ¥é«˜"] / df["å‡ºæ¥é«˜_ma20"]).replace([np.inf, -np.inf], np.nan)

    # ATRé¢¨ï¼ˆé«˜å€¤-å®‰å€¤ã®20MAï¼‰
    if "é«˜å€¤" in df.columns and "å®‰å€¤" in df.columns:
        df["_hl"]   = (df["é«˜å€¤"].astype(float) - df["å®‰å€¤"].astype(float))
        df["ATR20"] = grp["_hl"].transform(lambda s: s.rolling(20, min_periods=1).mean())
        df.drop(columns=["_hl"], inplace=True)

    # å¤‰åŒ–ç‡ï¼ˆå‚è€ƒ: å½“æ—¥/å‰æ—¥-1ï¼‰
    try:
        df["çµ‚å€¤_pct1"] = grp["çµ‚å€¤"].transform(lambda s: s.pct_change(1) * 100.0)
    except Exception:
        pass

    # --- legacy column aliases for backward compatibility ---
    # ä¸€éƒ¨ã®å‡¦ç†ãŒ "MA13"/"MA26" ãªã©æ—§åã‚’å‚ç…§ã™ã‚‹ãŸã‚ã€çµ‚å€¤ç³»MAã«åˆ¥åã‚’ä»˜ä¸
    for _new, _legacy in [("çµ‚å€¤_ma5","MA5"), ("çµ‚å€¤_ma13","MA13"),
                          ("çµ‚å€¤_ma20","MA20"), ("çµ‚å€¤_ma26","MA26")]:
        if _new in df.columns and _legacy not in df.columns:
            try:
                df[_legacy] = df[_new]
            except Exception:
                # ä½•ã‹äº‹æƒ…ã§ä»£å…¥ã«å¤±æ•—ã—ã¦ã‚‚ä»–å‡¦ç†ã‚’æ­¢ã‚ãªã„
                pass
    # -------------------------------------------------------

    return df
# ========= end price series features =========



# ===== Constants (centralized) =====
# --- MISC settings ---
# eps
EPS = 0.0
# jst
JST = dtm.timezone(dtm.timedelta(hours=9))
# ===== ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆå¥½ã¿ã§å¾®èª¿æ•´ï¼‰ =====
LOOKBACK = 90
# yq

# --- KARAURI settings ---
# JS ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
KARAURI_PY_PATH = r"H:\desctop\æ ªæ”»ç•¥\1-ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°è‡ªå‹•åŒ–ãƒ—ãƒ­ã‚°ãƒ©ãƒ \ç©ºå£²ã‚Šç„¡ã—ãƒªã‚¹ãƒˆå‡ºã—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ.py"
# ç©ºå£²ã‚Šé–¢é€£ã®è¨­å®š
KARAURI_OUTPUT_TXT = r"H:\desctop\æ ªæ”»ç•¥\1-ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°è‡ªå‹•åŒ–ãƒ—ãƒ­ã‚°ãƒ©ãƒ \ç©ºå£²ã‚Šç„¡ã—ãƒªã‚¹ãƒˆ.txt"

# --- RUN settings ---
# ======== å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ ========
RUN_SESSION = "EOD"

# --- AUTO settings ---
# æ©Ÿèƒ½ãƒ•ãƒ©ã‚°ï¼ˆON/OFFï¼‰
AUTO_MODE = True

# --- GMAIL settings ---
# gmail app password
GMAIL_APP_PASSWORD = "pzunutpfqophuoae"
# gmail body
GMAIL_BODY = "index.html ã‚’æ·»ä»˜ã—ã¾ã™ï¼ˆã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã§é–‹ã‘ã¾ã™ï¼‰ã€‚"
# gmail subj
GMAIL_SUBJ = "ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚° ãƒ¬ãƒãƒ¼ãƒˆ"
# gmail to
GMAIL_TO = "tomoyupo9@gmail.com"
# ======== é€ä¿¡è¨­å®šï¼ˆGmailï¼‰ ========
GMAIL_USER = "tomoyupo9@gmail.com"

# --- SEND settings ---
# send html as zip
SEND_HTML_AS_ZIP = False

# --- DB settings ---
# ======== ãƒ‘ã‚¹ ========
DB_PATH = r"H:\desctop\æ ªæ”»ç•¥\1-ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°è‡ªå‹•åŒ–ãƒ—ãƒ­ã‚°ãƒ©ãƒ \kani2.db"

# --- CSV settings ---
# ãƒ•ã‚¡ã‚¤ãƒ«/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹
CSV_INPUT_PATH = r"H:\desctop\æ ªæ”»ç•¥\1-ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°è‡ªå‹•åŒ–ãƒ—ãƒ­ã‚°ãƒ©ãƒ \screen_data\screener_result.csv"

# --- KARA settings ---
# ãƒ•ã‚¡ã‚¤ãƒ«/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹
KARA_URI_NASHI_PATH = r"H:\desctop\æ ªæ”»ç•¥\1-ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°è‡ªå‹•åŒ–ãƒ—ãƒ­ã‚°ãƒ©ãƒ \ç©ºå£²ã‚Šç„¡ã—ãƒªã‚¹ãƒˆ.txt"

# --- MASTER settings ---
# ãƒ•ã‚¡ã‚¤ãƒ«/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹
MASTER_CODES_PATH = r"H:\desctop\æ ªæ”»ç•¥\1-ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°è‡ªå‹•åŒ–ãƒ—ãƒ­ã‚°ãƒ©ãƒ \æ ªã‚³ãƒ¼ãƒ‰ç•ªå·.txt"

# --- OUTPUT settings ---
# ãƒ•ã‚¡ã‚¤ãƒ«/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹
OUTPUT_DIR = r"H:\desctop\æ ªæ”»ç•¥\1-ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°è‡ªå‹•åŒ–ãƒ—ãƒ­ã‚°ãƒ©ãƒ \screen_data"

# --- EXTRA settings ---
# ãƒ•ã‚¡ã‚¤ãƒ«/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹
EXTRA_CLOSED_PATH = r"H:\desctop\æ ªæ”»ç•¥\1-ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°è‡ªå‹•åŒ–ãƒ—ãƒ­ã‚°ãƒ©ãƒ \market_closed_extra.txt"

# --- USE settings ---
# ======== ã‚ªãƒ—ã‚·ãƒ§ãƒ³ ========
USE_CSV = True

# --- TEST settings ---
# æœ€å¤§ä»¶æ•°/ä¸Šé™
TEST_LIMIT = 50
# æ©Ÿèƒ½ãƒ•ãƒ©ã‚°ï¼ˆON/OFFï¼‰
TEST_MODE = False

# --- YQ settings ---
# EODå‡¦ç†ã®ãƒãƒƒãƒã‚µã‚¤ã‚º
YQ_BATCH_EOD = 400
# ä¸­é–“å‡¦ç†ã®ãƒãƒƒãƒã‚µã‚¤ã‚º
YQ_BATCH_MID = 400
# yahooquery ã®è¨­å®š
YQ_SLEEP_EOD = 0.15
# yahooquery ã®è¨­å®š
YQ_SLEEP_MID = 0.10

# --- HISTORY settings ---
# å±¥æ­´å–å¾—
HISTORY_PERIOD_DAILY = "10d"
# history period full
HISTORY_PERIOD_FULL = "12mo"

# --- SIGNAL settings ---
# ã‚·ã‚°ãƒŠãƒ«è¨ˆç®—ã«èª­ã¿è¾¼ã‚€éå»æ—¥æ•°ï¼ˆDBã‹ã‚‰ï¼‰
SIGNAL_LOOKBACK_DAYS = 300

# --- MIDDAY settings ---
# MIDDAYã®å¯¾è±¡ã‚’çµã‚‹ï¼ˆTrueã§é€Ÿã„ï¼‰
MIDDAY_FILTER_BY_FLAGS = False

# --- REJUDGE settings ---
# ===== å¤–ã‚Œâ†’å†è©•ä¾¡ ãƒ«ãƒ¼ãƒ«ï¼ˆé…ã‚Œã¦æˆåŠŸã‚’æ‹¾ã†ï¼‰ =====
REJUDGE_LOOKAHEAD_DAYS = 5
# å‰²åˆï¼ˆ0ã€œ1æƒ³å®šï¼‰
REJUDGE_MAX_ADVERSE_PCT = 7.0
# å‰²åˆï¼ˆ0ã€œ1æƒ³å®šï¼‰
REJUDGE_REQ_HIGH_PCT = 5.0

# --- MID settings ---
# === ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆå¿…è¦ãªã‚‰èª¿æ•´ï¼‰ ===
MID_MA = 25

# --- BREAKOUT settings ---
# æœŸé–“/çª“ã‚µã‚¤ã‚ºï¼ˆæ—¥æ•°ï¼‰
BREAKOUT_LOOKBACK = 90

# --- MIN settings ---
# æ—¥æ•°
MIN_DAYS = 60

# --- SLOPE settings ---
# slope min ann
SLOPE_MIN_ANN = 0.08

# --- R2 settings ---
# ä¸‹é™
R2_MIN = 0.30

# --- MDD settings ---
# ä¸Šé™
MDD_MAX = 0.30

# --- RIBBON settings ---
# æ—¥æ•°
RIBBON_KEEP_DAYS = 30

# --- WEEK settings ---
# ä¸‹é™
WEEK_UP_MIN = 0.55

# --- HL settings ---
# hl win
HL_WIN = 5

# --- THRESH settings ---
# ã—ãã„å€¤
THRESH_SCORE = 70



# ==== [Short-term Trading Enhancements] Derived Metrics (schema assumed) ====
def _calculate_atr_ewm(df: pd.DataFrame, period: int = 14) -> pd.Series:
    # df: å¿…é ˆåˆ— ['é«˜å€¤','å®‰å€¤','çµ‚å€¤'] ã‚’æƒ³å®šã€‚index ã¯æ—¥ä»˜é †ã€‚
    try:
        h = pd.to_numeric(df.get("é«˜å€¤"), errors="coerce")
        l = pd.to_numeric(df.get("å®‰å€¤"), errors="coerce")
        c = pd.to_numeric(df.get("çµ‚å€¤"), errors="coerce")
        tr = pd.concat([
            (h - l).abs(),
            (h - c.shift(1)).abs(),
            (l - c.shift(1)).abs()
        ], axis=1).max(axis=1)
        return tr.ewm(span=period, adjust=False).mean()
    except Exception as e:
        print("[derive-update][WARN] _calculate_atr_ewm:", e)
        return pd.Series(index=df.index, dtype=float)

def _apply_shortterm_metrics(conn: sqlite3.Connection):
    """
    ã‚¹ã‚­ãƒ¼ãƒ/ãƒ†ãƒ¼ãƒ–ãƒ«ã¯æ—¢ã«æ‹¡å¼µæ¸ˆã¿ã§å­˜åœ¨ã™ã‚‹å‰æ:
      - latest_prices(ã‚³ãƒ¼ãƒ‰, æ—¥ä»˜, çµ‚å€¤|ç¾åœ¨å€¤, ..., ATR_14, Rate_Since_Signal_High, Days_Since_Signal_High)
      - price_history(ã‚³ãƒ¼ãƒ‰, æ—¥ä»˜, å§‹å€¤, é«˜å€¤, å®‰å€¤, çµ‚å€¤, å‡ºæ¥é«˜)
    """
    cur = conn.cursor()
    try:
        hist_tbl = "price_history"

        cur.execute("SELECT rowid, * FROM latest_prices")
        rows = cur.fetchall()
        col_names = [d[0] for d in cur.description]

        def idx(name, default=-1):
            try: return col_names.index(name)
            except ValueError: return default

        i_code = idx("ã‚³ãƒ¼ãƒ‰")
        i_date = idx("æ—¥ä»˜")
        i_close = idx("çµ‚å€¤") if idx("çµ‚å€¤") != -1 else idx("ç¾åœ¨å€¤")
        i_sig = idx("signal_date")
        if i_sig == -1:
            i_sig = idx("ã‚·ã‚°ãƒŠãƒ«æ›´æ–°æ—¥")

        updates = []

        for r in rows:
            code = r[i_code]
            ldate = r[i_date]
            close_v = r[i_close]

            # ATR(14)
            q_hist = f"SELECT æ—¥ä»˜, é«˜å€¤, å®‰å€¤, çµ‚å€¤ FROM {hist_tbl} WHERE ã‚³ãƒ¼ãƒ‰ = ? ORDER BY æ—¥ä»˜"
            hdf = pd.read_sql_query(q_hist, conn, params=[code], parse_dates=["æ—¥ä»˜"])
            hdf = hdf.set_index("æ—¥ä»˜").sort_index()
            atr14 = float(_calculate_atr_ewm(hdf, 14).iloc[-1])

            # ã‚·ã‚°ãƒŠãƒ«å¾Œãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ 
            sig_val = r[i_sig]
            signal_date = pd.to_datetime(str(sig_val), errors="coerce")

            q2 = f"SELECT æ—¥ä»˜, é«˜å€¤, çµ‚å€¤ FROM {hist_tbl} WHERE ã‚³ãƒ¼ãƒ‰ = ? AND æ—¥ä»˜ >= ? ORDER BY æ—¥ä»˜"
            h2 = pd.read_sql_query(q2, conn, params=[code, str(signal_date.date())], parse_dates=["æ—¥ä»˜"])
            max_high = float(pd.to_numeric(h2["é«˜å€¤"], errors="coerce").max())
            idx_max = h2.loc[pd.to_numeric(h2["é«˜å€¤"], errors="coerce").idxmax(), "æ—¥ä»˜"]

            cur_close = float(close_v) if close_v is not None else float(pd.to_numeric(h2["çµ‚å€¤"].iloc[-1], errors="coerce"))
            rate_since = (cur_close / max_high - 1.0) * 100.0
            base_date = pd.to_datetime(ldate)
            days_since = int((base_date - idx_max).days)

            updates.append((atr14, rate_since, days_since, r[0]))

        cur.executemany(
            "UPDATE latest_prices SET ATR_14 = ?, Rate_Since_Signal_High = ?, Days_Since_Signal_High = ? WHERE rowid = ?",
            updates
        )
        conn.commit()
        print(f"[derive-update] ATR_14/Rate/Days updated: {len(updates)} rows")
    finally:
        try: cur.close()
        except Exception: pass

# ==== æœ€æ–°è¡ŒåŒæœŸï¼ˆprice_history -> latest_pricesï¼‰ ====
def phase_sync_latest_prices(conn: sqlite3.Connection):
    """
    Sync the latest row per code from price_history into latest_prices (UPSERT).
    Only updates æ—¥ä»˜ and çµ‚å€¤; other columns remain as-is.
    """
    sql = """
    INSERT INTO latest_prices (ã‚³ãƒ¼ãƒ‰, æ—¥ä»˜, çµ‚å€¤)
    SELECT ph.ã‚³ãƒ¼ãƒ‰, ph.æ—¥ä»˜, ph.çµ‚å€¤
    FROM price_history ph
    JOIN (
      SELECT ã‚³ãƒ¼ãƒ‰, MAX(æ—¥ä»˜) AS max_date
      FROM price_history
      GROUP BY ã‚³ãƒ¼ãƒ‰
    ) AS t
      ON ph.ã‚³ãƒ¼ãƒ‰ = t.ã‚³ãƒ¼ãƒ‰ AND ph.æ—¥ä»˜ = t.max_date
    ON CONFLICT(ã‚³ãƒ¼ãƒ‰) DO UPDATE SET
      æ—¥ä»˜ = excluded.æ—¥ä»˜,
      çµ‚å€¤ = excluded.çµ‚å€¤;
    """
    cur = conn.cursor()
    try:
        cur.execute("PRAGMA foreign_keys = ON")
        cur.execute("BEGIN")
        cur.execute(sql)
        conn.commit()
        print("[sync-latest] latest_prices upserted from price_history")
    except Exception as e:
        conn.rollback()
        print("[sync-latest][WARN]", e)
    finally:
        try: cur.close()
        except Exception: pass


def phase_shortterm_enhancements(conn: sqlite3.Connection):
    """
    æ—¢å­˜ãƒ•ãƒ­ãƒ¼ã®ä»»æ„ã®å ´æ‰€ï¼ˆæ´¾ç”Ÿå€¤æ›´æ–°ã®ç›´å¾Œãªã©ï¼‰ã§å‘¼ã³å‡ºã—ã¦ãã ã•ã„ã€‚
    - ATR(14) ã¨ since-signal ã‚’è¨ˆç®—ã—ã¦ latest_prices ã«åæ˜ ï¼ˆã‚¹ã‚­ãƒ¼ãƒã¯æ—¢ã«æ•´å‚™æ¸ˆã¿å‰æï¼‰
    """
    _apply_shortterm_metrics(conn)

# --- DASH settings ---
# dash template str
DASH_TEMPLATE_STR = r"""<!doctype html>
<html lang="ja">
<head>
<meta http-equiv="Cache-Control" content="no-store">
<meta http-equiv="Pragma" content="no-cache">
<meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1">
<title>ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚° ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰</title>
<style>
  :root{
    --ink:#1f2937; --muted:#6b7280; --bg:#f9fafb; --line:#e5e7eb;
    --blue:#0d3b66; --green:#15803d; --orange:#b45309; --yellow:#a16207;
    --hit:#ffe6ef; --rowhover:#f6faff;
  }

  /* å…¨ä½“ */
  body{
    font-family:system-ui,-apple-system,Segoe UI,Roboto,'Noto Sans JP',sans-serif;
    margin:16px; color:var(--ink); background:#fff;
  }

  nav{display:flex;gap:8px;margin-bottom:12px;flex-wrap:wrap}
  nav a{padding:6px 10px;border-radius:8px;text-decoration:none;background:#e1e8f0;color:#1f2d3d;font-weight:600}
  nav a.active{background:var(--blue);color:#fff}

  .toolbar{display:flex;gap:14px;align-items:center;margin:8px 0 10px;flex-wrap:wrap}
  .toolbar input[type="text"],.toolbar input[type="number"]{padding:6px 10px;border:1px solid #ccd;border-radius:8px;background:#fff}
  .toolbar input[type="number"]{width:80px}
  .btn{background:var(--blue);color:#fff;border:none;border-radius:8px;padding:6px 12px;cursor:pointer;font-weight:600}

  /* ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ©ãƒƒãƒ‘ï¼ˆè§’ä¸¸ï¼‹æ¨ªã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ï¼‰ */
  .tbl-wrap{
    border-radius:10px;
    overflow:auto; /* ç¸¦æ¨ª */
    -webkit-overflow-scrolling:touch;
    background:#fff;
    box-shadow:0 0 0 1px var(--line) inset;
    max-height:70vh;
  }

  /* ãƒ†ãƒ¼ãƒ–ãƒ«å…±é€šï¼ˆã‚³ãƒ³ãƒ‘ã‚¯ãƒˆåŒ–ï¼‰ */
  .tbl{ border-collapse:collapse; width:100%; background:#fff; }
  .tbl th,.tbl td{
    border-bottom:1px solid var(--line);
    padding:4px 6px;
    font-size:0.85em;
    vertical-align:top;
  }
  .tbl tbody tr:nth-child(even){background:#fcfdff}
  .tbl tbody tr:hover{background:var(--rowhover)}
  .tbl th.sortable{cursor:pointer;user-select:none}
  .tbl th.sortable .arrow{margin-left:6px;font-size:11px;color:#666}
  .num{text-align:right}
  .muted{color:var(--muted)}
  .hidden{display:none}
  .count{margin-left:6px;color:var(--muted)}
  .pager{display:flex;gap:8px;align-items:center}
  tr.hit>td{background:var(--hit)}

  /* ãƒãƒƒã‚¸ */
  .badge{display:inline-flex;gap:6px;align-items:center;padding:2px 8px;border-radius:999px;font-size:12px;line-height:1;font-weight:700}
  .b-green{background:#e7f6ed;color:var(--green);border:1px solid #cceedd}
  .b-orange{background:#fff4e6;color:#b45309;border:1px solid #ffe2c2}
  .b-yellow{background:#fff9db;color:var(--yellow);border:1px solid #ffe9a8}
  .b-gray{background:#eef2f7;color:#475569;border:1px solid #dbe4ef}

  /* æ¨å¥¨ãƒãƒƒã‚¸ */
  .rec-badge{display:inline-flex; align-items:center; gap:6px; padding:2px 8px; border-radius:999px; font-size:12px; font-weight:700; line-height:1; white-space:nowrap;}
  .rec-strong{ background:#e7f6ed; color:#166534; border:1px solid #cceedd; }
  .rec-small { background:#fff4e6; color:#9a3412; border:1px solid #ffe2c2; }
  .rec-watch { background:#eef2f7; color:#475569; border:1px solid #dbe4ef; }
  .rec-dot{ display:inline-block; width:6px; height:6px; border-radius:50%; background:currentColor;}

  /* ãƒ˜ãƒƒãƒ€ãƒ¼å›ºå®šï¼ˆå€™è£œä¸€è¦§ / å…¨ã‚«ãƒ©ãƒ ï¼‰ */
  #tbl-candidate thead th,
  #tbl-allcols  thead th{
    position:sticky;
    position:-webkit-sticky;
    top:0;
    background:#fff;
    z-index:2;
    border-bottom:2px solid #ccc;
  }

  /* ãƒ˜ãƒ«ãƒ—ï¼ˆå°çª“ï¼‹æš—å¹•ï¼‰ */
  .help-backdrop{
    position:fixed; inset:0; background:rgba(17,24,39,.45);
    z-index:9998; display:none;
  }
  .help-pop{
    position:absolute; z-index:9999; background:#fff; border:1px solid #e5e7eb;
    border-radius:12px; box-shadow:0 12px 32px rgba(0,0,0,.18);
    padding:12px 14px 14px; font-size:13px; line-height:1.55;
    display:none; width:clamp(720px, 90vw, 1200px);
  }
  .help-pop .help-head{ display:flex; align-items:center; justify-content:space-between; gap:12px; margin-bottom:6px; font-weight:700;}
  .help-pop .help-close{ display:inline-flex; align-items:center; justify-content:center; width:22px; height:22px; border-radius:6px; cursor:pointer; user-select:none; font-weight:700;}
  .help-pop .help-close:hover{ background:#f3f4f6; }

  /* ï¼Ÿã‚¢ã‚¤ã‚³ãƒ³ï¼ˆãƒ†ãƒ¼ãƒ–ãƒ«/ãƒ„ãƒ¼ãƒ«ãƒãƒ¼å…±é€šï¼‰ */
  .qhelp{ display:inline-flex; align-items:center; justify-content:center; width:18px; height:18px; margin-left:6px;
    border-radius:50%; border:1px solid #cbd5e1; font-size:12px; cursor:pointer; background:#eef2ff; color:#334155; font-weight:700; line-height:1;}
  .qhelp:hover{ background:#e0e7ff; }

  /* 1è¡Œå›ºå®šï¼ˆæ”¹è¡Œã¯æ½°ã™ï¼‰ */
  #tbl-candidate td, #tbl-candidate th,
  #tbl-allcols  td, #tbl-allcols  th{ white-space:nowrap !important; word-break:keep-all !important; }
  #tbl-candidate td br, #tbl-candidate th br,
  #tbl-allcols  td br, #tbl-allcols  th br{ display:none !important; }

  /* åˆ¤å®šç†ç”±ã¯æ¥µå°ã§æŠ˜ã‚Šè¿”ã—å¯ */
  th.reason-col, td.reason-col{ font-size:0.78em; line-height:1.2; white-space:normal !important; word-break:break-word !important; }

  .mini{ font-size:10px; color:var(--muted); }

  /* ã‚³ãƒ¼ãƒ‰ã‚³ãƒ”ãƒ¼ãƒªãƒ³ã‚¯ */
  .copylink{ color:var(--blue); text-decoration:underline; cursor:pointer; }
  .copylink.ok{ color:var(--green); text-decoration:none; font-weight:700; }

  /* äºˆæ¸¬ã‚¿ãƒ–ï¼šç†ç”±/ãƒ’ãƒ³ãƒˆã®å¼·èª¿ */
  .reason-col,.hint-col {vertical-align: top;}
  .reason-box{ display:inline-block; padding:6px 8px; border-radius:10px; background:#fff9db; line-height:1.4; white-space: pre-wrap; }

  /* è²¡å‹™ã‚³ãƒ¡ãƒ³ãƒˆï¼ˆè²¡å‹™ãƒªãƒ³ã‚¯å³ï¼‰ */
  .fn-note{
    color:#b91c1c; font-weight:700; font-size:0.78em; margin-left:8px;
    white-space:pre-wrap; overflow:visible; text-overflow:clip; display:inline-block;
    max-width:clamp(600px, 60vw, 1200px); vertical-align:bottom;
  }

  /* ãƒ„ãƒ¼ãƒ«ãƒãƒƒãƒ—/ãƒãƒƒãƒ—ã‚ªãƒ¼ãƒãƒ¼ã¯ã‚¯ãƒªãƒƒã‚¯è²«é€š */
  .tooltip, .popover { pointer-events:none; }
</style>
</head>

<body>
  <nav>
    <a href="#" id="lnk-cand" class="active">å€™è£œä¸€è¦§</a>
    <a href="#" id="lnk-tmr">æ˜æ—¥ç”¨</a>
    <a href="#" id="lnk-all">å…¨ã‚«ãƒ©ãƒ </a>
    <a href="#" id="lnk-earn">æ±ºç®—(å®Ÿç¸¾)</a>
    <a href="#" id="lnk-preearn">æ±ºç®—ã€ˆäºˆæ¸¬ã€‰</a>
    {% if include_log %}<a href="#" id="lnk-log">signals_log</a>{% endif %}
    <span class="mini" style="margin-left:auto">build: {{ build_id }}</span>
  </nav>

  <div id="toolbar" class="toolbar">
    <label><input type="checkbox" id="f_shodou"> åˆå‹•ã®ã¿</label>
    <label><input type="checkbox" id="f_tei"> åº•æ‰“ã¡ã®ã¿</label>
    <label><input type="checkbox" id="f_both"> ä¸¡ç«‹ã®ã¿</label>
    <label><input type="checkbox" id="f_rightup"> å³è‚©ä¸ŠãŒã‚Šã®ã¿</label>
    <label><input type="checkbox" id="f_early"> æ—©æœŸã®ã¿</label>
    <label><input type="checkbox" id="f_etype"> æ—©æœŸç¨®åˆ¥ã‚ã‚Š</label>
    <label><input type="checkbox" id="f_recstrong"> ã‚¨ãƒ³ãƒˆãƒªãƒ¼æœ‰åŠ›ã®ã¿</label>
    <label><input type="checkbox" id="f_smallpos"> å°å£ææ¡ˆã®ã¿</label>
    <label><input type="checkbox" id="f_noshor"> ç©ºå£²ã‚Šæ©Ÿé–¢ãªã—ã®ã¿</label>
    <label><input type="checkbox" id="f_opratio"> å‰²å®‰ï¼ˆå–¶åˆ©å¯¾æ™‚ä¾¡10%ä»¥ä¸Šï¼‰ã®ã¿</label>
    <label><input type="checkbox" id="f_hit"> å½“ãŸã‚Šã®ã¿</label>
    <div class="toolbar early-filter">
      <label class="ef-chk"><input type="checkbox" value="ãƒ–ãƒ¬ã‚¤ã‚¯" ><span>ãƒ–ãƒ¬ã‚¤ã‚¯</span></label>
      <label class="ef-chk"><input type="checkbox" value="ãƒã‚±ãƒƒãƒˆ" ><span>ãƒã‚±ãƒƒãƒˆ</span></label>
      <label class="ef-chk"><input type="checkbox" value="20MAãƒªãƒ" ><span>20MAãƒªãƒ</span></label>
      <label class="ef-chk"><input type="checkbox" value="200MAãƒªã‚¯ãƒ¬ã‚¤ãƒ " ><span>200MAãƒªã‚¯ãƒ¬ã‚¤ãƒ </span></label>
    </div>

    <label>ä¸Šæ˜‡ç‡â‰¥ <input type="number" id="th_rate" placeholder="3.0" step="0.1" inputmode="decimal" autocomplete="off"></label>
    <label>å£²è²·ä»£é‡‘â‰¥ <input type="number" id="th_turn" placeholder="10" step="0.1" inputmode="decimal" autocomplete="off"></label>
    <label>RVOLä»£é‡‘â‰¥ <input type="number" id="th_rvol" placeholder="3.0" step="0.1" inputmode="decimal" autocomplete="off"></label>
    <label><input type="checkbox" id="f_defaultset"> è¦å®š</label>

    <input type="text" id="q" placeholder="å…¨æ–‡æ¤œç´¢ï¼ˆã‚³ãƒ¼ãƒ‰/éŠ˜æŸ„/åˆ¤å®šç†ç”±ãªã©ï¼‰" style="min-width:240px">
    <button class="btn" id="btn-stats">å‚¾å‘ã‚°ãƒ©ãƒ•</button>
    <button class="btn" id="btn-ts">æ¨ç§»ã‚°ãƒ©ãƒ•</button>

    <span class="pager">
      <label>è¡¨ç¤ºä»¶æ•°
        <select id="perpage">
          <option value="200">200</option><option value="500">500</option>
          <option value="1000">1000</option><option value="2000" selected>2000</option>
        </select>
      </label>
      <button class="btn" id="prev">å‰ã¸</button>
      <button class="btn" id="next">æ¬¡ã¸</button>
      <span id="pageinfo" class="muted">- / -</span>
    </span>
    <span class="count">ä»¶æ•°: <b id="count">-</b></span>
  </div>

  <script id="__DATA__" type="application/json">{{ data_json|safe }}</script>

<script>
(function(){
  "use strict";

  // ---- data ----
  const RAW = (()=>{ try{ return JSON.parse(document.getElementById("__DATA__").textContent||"{}"); }catch(_){ return {}; } })();
  const DATA_CAND = Array.isArray(RAW.cand)? RAW.cand: [];
  const DATA_ALL  = Array.isArray(RAW.all) ? RAW.all : [];
  const DATA_LOG  = Array.isArray(RAW.logs)? RAW.logs: [];
  const DATA_EARN = Array.isArray(RAW.earnings) ? RAW.earnings : [];
  const _preSrc = RAW.preearn ?? RAW.pre ?? RAW.pre_rows ?? RAW.preearn_rows ?? RAW["pre-earnings"] ?? RAW.earnings_pre ?? [];
  const DATA_PREEARN = Array.isArray(_preSrc) ? _preSrc : [];

  // ---- utils ----
  const $  = (s,r=document)=>r.querySelector(s);
  const $$ = (s,r=document)=>Array.from(r.querySelectorAll(s));
  const num = (v)=>{ const s=String(v??"").replace(/[,\så††ï¼…%]/g,""); const n=parseFloat(s); return Number.isFinite(n)?n:NaN; };
  const cmp = (a,b)=>{ if(a==null&&b==null) return 0; if(a==null) return -1; if(b==null) return 1;
    const na=+a, nb=+b, da=new Date(a), db=new Date(b);
    if(!Number.isNaN(na)&&!Number.isNaN(nb)) return na-nb;
    if(!Number.isNaN(da)&&!Number.isNaN(db)) return da-db;
    return String(a).localeCompare(String(b),"ja"); };
  const hasKouho = (v)=> String(v||"").includes("å€™è£œ");

  function escapeHtml(s){ return String(s).replace(/[&<>"']/g, m=>({"&":"&amp;","<":"&lt;",">":"&gt;","\"":"&quot;","'":"&#39;"}[m])); }

  // copy link
  function codeLink(code){
    if(code==null) return "";
    const s = String(code).padStart(4, "0");
    return `<a href="#" class="copylink" data-copy="${s}" title="ã‚³ãƒ¼ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼">${s}</a>`;
  }
  document.addEventListener("click", async (e)=>{
    const a = e.target.closest && e.target.closest("a.copylink");
    if (!a) return;
    e.preventDefault();
    const text = a.dataset.copy || "";
    try{
      if (navigator.clipboard && window.isSecureContext !== false) {
        await navigator.clipboard.writeText(text);
      } else {
        const ta = document.createElement("textarea");
        ta.value = text; ta.style.position = "fixed"; ta.style.left = "-9999px";
        document.body.appendChild(ta); ta.select(); document.execCommand("copy"); document.body.removeChild(ta);
      }
      const old = a.textContent; a.classList.add("ok"); a.textContent = "ã‚³ãƒ”ãƒ¼æ¸ˆ";
      setTimeout(() => { a.classList.remove("ok"); a.textContent = old; }, 1200);
    } catch (_){
      const old = a.textContent; a.textContent = "å¤±æ•—"; setTimeout(() => { a.textContent = old; }, 1200);
    }
  });

  // offerings badge
  const OFFER_SET = new Set((Array.isArray(RAW.offer_codes) ? RAW.offer_codes : []).map(x => String(x).padStart(4,"0")));
  function offeringBadge(code){
    const c = String(code ?? "").padStart(4,"0");
    return OFFER_SET.has(c) ? `<span class="badge b-gray" title="ç›´è¿‘ã«å¢—è³‡/è¡Œä½¿/å£²å‡º/CBãªã©ã®å±¥æ­´ã‚ã‚Š">å¢—è³‡çµŒæ­´</span>` : "";
  }

  // finance modal
  function openFinanceHtml(code){
    closeAllTips();
    const back = ensureChartModal();
    const body = document.getElementById("__chart_body__");
    const src = `graph/finance_${String(code).padStart(4,"0")}.html`;
    body.innerHTML = `<iframe src="${src}" style="width:100%; height:80vh; border:0;"></iframe>`;
    back.style.display = "block";
    const box = document.querySelector(".help-pop");
    box.style.display = "block";
    const sx = window.scrollX||0, sy = window.scrollY||0;
    box.style.top = `${sy+60}px`;
    requestAnimationFrame(()=>{ box.style.left = `${sx + Math.max(10, (document.documentElement.clientWidth - box.offsetWidth)/2)}px`; });
  }
  function financeLink(code){
    if(code==null) return "";
    const s = String(code).padStart(4, "0");
    return `<a href="#" class="financelink" data-code="${s}" title="è²¡å‹™ã‚°ãƒ©ãƒ•ã‚’é–‹ã">è²¡å‹™</a>`;
  }
  function financeNote(row){
    let v = row?.["è²¡å‹™ã‚³ãƒ¡ãƒ³ãƒˆ"];
    if (!v) return "";
    let s = String(v).trim();
    // å…ˆé ­ã®ã€Œâš ã€ã€Œåˆ¤å®šï¼ˆâ€¦ï¼‰:ã€ã€Œåˆ¤å®š:ã€ã€Œã‚³ãƒ¡ãƒ³ãƒˆ:ã€ãªã©ã‚’é™¤å»
    s = s
      .replace(/^\s*[âš ï¸âš ï¸â–³â–²â€»ï¼Š*]?\s*åˆ¤å®šï¼ˆ[^ï¼‰]*ï¼‰\s*[:ï¼š]?\s*/i, "")
      .replace(/^\s*[âš ï¸âš ï¸â–³â–²â€»ï¼Š*]?\s*(åˆ¤å®š|ã‚³ãƒ¡ãƒ³ãƒˆ)\s*[:ï¼š]?\s*/i, "")
      .replace(/^\s*[ï¼š:\-ãƒ»]+\s*/, ""); // ä½™åˆ†ãªåŒºåˆ‡ã‚ŠãŒç¶šãå ´åˆã®æƒé™¤
    const t = escapeHtml(s);
    return ` <span class="fn-note" title="${t}">${t}</span>`;
  }
  document.addEventListener("click", (e)=>{
    const a = e.target.closest && e.target.closest("a.financelink");
    if(!a) return;
    e.preventDefault();
    const code = a.dataset.code;
    if(code) openFinanceHtml(code);
  });

  // DOM sort (generic)
  function wireDomSort(tableSelector){
    const table = document.querySelector(tableSelector); if(!table) return;
    const ths = Array.from(table.querySelectorAll('thead th.sortable'));
    const cellVal = (td)=>{
      if (!td) return '';
      const ds = td.getAttribute ? td.getAttribute('data-sort') : null;
      return (ds !== null && ds !== '') ? ds : (td.textContent || '');
    };
    const toNum = (s)=>{
      let t = String(s ?? '').trim().replace(/\s|[å††ï¼…%]/g,'');
      if (t.indexOf('.') === -1 && /^-?\d+,\d+$/.test(t)) t = t.replace(',', '.'); else t = t.replace(/,/g,'');
      const n = parseFloat(t);
      return Number.isFinite(n) ? n : NaN;
    };
    ths.forEach((th)=>{
      if (th.__wiredSort) return;
      th.__wiredSort = true;
      th.style.cursor = 'pointer';
      th.addEventListener('click', ()=>{
        const colIndex = th.cellIndex;
        const dirPrev = th.dataset.dir;
        ths.forEach(h=>{ h.dataset.dir=''; const a=h.querySelector('.arrow'); if(a) a.textContent=''; });
        const dir = (dirPrev === 'asc') ? 'desc' : 'asc';
        th.dataset.dir = dir;
        const typ = th.dataset.type || 'text';
        const rows = Array.from(table.querySelectorAll('tbody tr'));
        rows.sort((r1, r2)=>{
          const aRaw = cellVal(r1.children[colIndex]).trim();
          const bRaw = cellVal(r2.children[colIndex]).trim();
          if (typ === 'num'){
            const aKey = toNum(aRaw), bKey = toNum(bRaw);
            if (!Number.isNaN(aKey) && !Number.isNaN(bKey)){
              return dir==='asc' ? (aKey-bKey) : (bKey-aKey);
            }
          } else if (typ === 'date'){
            const aKey = Date.parse(aRaw), bKey = Date.parse(bRaw);
            if (!Number.isNaN(aKey) && !Number.isNaN(bKey)){
              return dir==='asc' ? (aKey-bKey) : (bKey-aKey);
            }
          }
          const sa = String(aRaw).toLowerCase();
          const sb = String(bRaw).toLowerCase();
          return dir==='asc' ? sa.localeCompare(sb,'ja') : sb.localeCompare(sa,'ja');
        });
        const tb = table.querySelector('tbody');
        rows.forEach(r=>tb.appendChild(r));
        const arrow = th.querySelector('.arrow'); if (arrow) arrow.textContent = (dir==='asc'?'â–²':'â–¼');
      });
    });
  }

  // state
  const state = { tab:"cand", page:1, per:parseInt($("#perpage")?.value||"500",10), sortKey:null, sortDir:1, q:"", data: DATA_CAND.slice() };
  window.state = state;

  const DEFAULTS = { rate:3, turn:5, rvol:2 };
  function applyDefaults(on){
    const ia=$("#th_rate"), it=$("#th_turn"), ir=$("#th_rvol");
    if(!ia||!it||!ir) return;
    if(on){ ia.value=DEFAULTS.rate; it.value=DEFAULTS.turn; ir.value=DEFAULTS.rvol; }
    else  { ia.value=""; it.value=""; ir.value=""; ia.removeAttribute("value"); it.removeAttribute("value"); ir.removeAttribute("value"); }
    state.page=1; render();
  }
  function forceClearThresholds(){
    const cb=$("#f_defaultset");
    if(cb) cb.checked=false;
    applyDefaults(false);
  }
  function thRate(){ const v=num($("#th_rate")?.value); return Number.isNaN(v)?null:v; }
  function thTurn(){ const v=num($("#th_turn")?.value); return Number.isNaN(v)?null:v; }
  function thRvol(){ const v=num($("#th_rvol")?.value); return Number.isNaN(v)?null:v; }

  function getSelectedTypes(){
    const box = document.querySelector(".early-filter");
    if (!box) return [];
    return Array.from(box.querySelectorAll(".ef-chk input:checked")).map(el => el.value);
  }

  function isHitRow(r){
    const v = String((r && (r["åˆ¤å®š"] ?? r["judge"] ?? "")) || "").trim().toLowerCase();
    if (/^å½“ãŸã‚Š/.test(v)) return true;
    if (v === "win" || v === "auto" || v === "å†è©•ä¾¡ok") return true;
    return false;
  }

  function applyFilter(rows){
    const q   = ($("#q")?.value||"").trim();
    const sel = getSelectedTypes();
    const useEarly = sel.length > 0;
    return rows.filter(r=>{
      const sh  = hasKouho(r["åˆå‹•ãƒ•ãƒ©ã‚°"]);
      const te  = hasKouho(r["åº•æ‰“ã¡ãƒ•ãƒ©ã‚°"]);
      const ru  = hasKouho(r["å³è‚©ä¸ŠãŒã‚Šãƒ•ãƒ©ã‚°"]);
      const ea  = hasKouho(r["å³è‚©æ—©æœŸãƒ•ãƒ©ã‚°"]);
      const etp = (String(r["å³è‚©æ—©æœŸç¨®åˆ¥"]||"").trim().length>0);
      const ns  = String(r["ç©ºå£²ã‚Šæ©Ÿé–¢ãªã—_flag"]||"0")==="1";
      const op  = String(r["å–¶åˆ©å¯¾æ™‚ä¾¡_flag"]||"0")==="1";
      const hit = isHitRow(r);
      if($("#f_shodou")?.checked && !sh) return false;
      if($("#f_tei")?.checked    && !te) return false;
      if($("#f_both")?.checked   && !(sh && ru)) return false;
      if($("#f_rightup")?.checked&& !ru) return false;
      if($("#f_early")?.checked  && !ea) return false;
      if($("#f_etype")?.checked  && !etp) return false;
      if($("#f_noshor")?.checked && !ns) return false;
      if($("#f_opratio")?.checked&& !op) return false;
      if($("#f_hit")?.checked    && !hit) return false;
      if (useEarly){
        const val = String(r["å³è‚©æ—©æœŸç¨®åˆ¥"]||"");
        if (!sel.some(v => val.includes(v))) return false;
      }
      const rate = num(r["å‰æ—¥çµ‚å€¤æ¯”ç‡"]);
      const turn = num(r["å£²è²·ä»£é‡‘(å„„)"]);
      const rvol = num(r["RVOLä»£é‡‘"]);
      const tr = thRate(), tt = thTurn(), tv = thRvol();
      if(tr!=null && !(rate>=tr)) return false;
      if(tt!=null && !(turn>=tt)) return false;
      if(tv!=null && !(rvol>=tv)) return false;

      if(q){
        const keys=["ã‚³ãƒ¼ãƒ‰","éŠ˜æŸ„å","åˆ¤å®šç†ç”±","å³è‚©æ—©æœŸç¨®åˆ¥","åˆå‹•ãƒ•ãƒ©ã‚°","åº•æ‰“ã¡ãƒ•ãƒ©ã‚°","å³è‚©ä¸ŠãŒã‚Šãƒ•ãƒ©ã‚°","å³è‚©æ—©æœŸãƒ•ãƒ©ã‚°","æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"];
        if(!keys.some(k=>String(r[k]??"").includes(q))) return false;
      }
      return true;
    });
  }

  function sortRows(rows){
    return state.sortKey ? rows.slice().sort((a,b)=> state.sortDir * cmp(a[state.sortKey], b[state.sortKey])) : rows;
  }

  function formatJudgeLabel(r){
    return isHitRow(r) ? "å½“ãŸã‚Šï¼(1)" : "å¤–ã‚Œï¼(1)";
  }

  // render: candidate
// render: candidate
function renderCand(){
  const body = document.querySelector("#tbl-candidate tbody");
  if(!body) return;
  const rows = sortRows(applyFilter(state.data));
  const total = rows.length, per = state.per, maxPage = Math.max(1, Math.ceil(total/per));
  state.page = Math.min(state.page, maxPage);
  const s = (state.page-1)*per, e = Math.min(s+per, total);

  let html = "";
  for (let i = s; i < e; i++) {
    const r = rows[i] || {};
    const et = (r["å³è‚©æ—©æœŸç¨®åˆ¥"] || "").trim();
    let etBadge = et;
    if (et === "ãƒ–ãƒ¬ã‚¤ã‚¯") etBadge = '<span class="badge b-green">â— ãƒ–ãƒ¬ã‚¤ã‚¯</span>';
    else if (et === "20MAãƒªãƒ") etBadge = '<span class="badge b-green">â— 20MAãƒªãƒ</span>';
    else if (et === "ãƒã‚±ãƒƒãƒˆ") etBadge = '<span class="badge b-orange">â— ãƒã‚±ãƒƒãƒˆ</span>';
    else if (et === "200MAãƒªã‚¯ãƒ¬ã‚¤ãƒ ") etBadge = '<span class="badge b-yellow">â— 200MAãƒªã‚¯ãƒ¬ã‚¤ãƒ </span>';

    const rec = (r["æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"] || "").trim();
    let recBadge = "";
    if (rec === "ã‚¨ãƒ³ãƒˆãƒªãƒ¼æœ‰åŠ›")      recBadge = '<span class="rec-badge rec-strong" title="ã‚¨ãƒ³ãƒˆãƒªãƒ¼æœ‰åŠ›"><span class="rec-dot"></span>æœ‰åŠ›</span>';
    else if (rec === "å°å£ææ¡ˆ")        recBadge = '<span class="rec-badge rec-small" title="å°å£ææ¡ˆ"><span class="rec-dot"></span>å°å£</span>';
    else if (rec)                       recBadge = `<span class="rec-badge rec-watch" title="${rec.replace(/"/g,'&quot;')}"><span class="rec-dot"></span>${rec}</span>`;

    const isHitTr = isHitRow(r);
    html += `<tr${isHitTr ? " class='hit'" : ""}>
      <td>${codeLink(r["ã‚³ãƒ¼ãƒ‰"])} ${offeringBadge(r["ã‚³ãƒ¼ãƒ‰"])}</td>
      <td>${r["éŠ˜æŸ„å"] ?? ""}</td>
      <td>${r["å¸‚å ´"] || "-"}</td>
      <td><a href="${r["yahoo_url"] ?? "#"}" target="_blank" rel="noopener">Yahoo</a></td>
      <td><a href="${r["x_url"] ?? "#"}" target="_blank" rel="noopener">Xæ¤œç´¢</a></td>
      <td class="num">${r["ç¾åœ¨å€¤"] ?? ""}</td>
      <td class="num">${r["å‰æ—¥çµ‚å€¤"] ?? ""}</td>
      <td class="num">${r["å‰æ—¥å††å·®"] ?? ""}</td>
      <td class="num">${r["å‰æ—¥çµ‚å€¤æ¯”ç‡"] ?? ""}</td>
      <td class="num">${r["å‡ºæ¥é«˜"] ?? ""}</td>
      <td class="num">${r["å£²è²·ä»£é‡‘(å„„)"] ?? ""}</td>
      <td>${financeLink(r["ã‚³ãƒ¼ãƒ‰"])}${financeNote(r)}</td>
      <!-- â–¼â–¼ ã“ã“ã‚’è¿½åŠ ï¼šthead ã®ã€Œã‚¹ã‚³ã‚¢ã€ã€Œé€²æ—ç‡ã€ã«å¯¾å¿œ â–¼â–¼ -->
      <td class="num">${r["ã‚¹ã‚³ã‚¢"] ?? ""}</td>
      <td class="num">${r["é€²æ—ç‡"] ?? ""}</td>
      <!-- â–²â–² è¿½åŠ ã“ã“ã¾ã§ â–²â–² -->
      <td>${r["å¢—è³‡ãƒªã‚¹ã‚¯"] ?? ""}</td>
      <td class="num">${r["å¢—è³‡ã‚¹ã‚³ã‚¢"] ?? ""}</td>
      <td class="reason-col">${r["å¢—è³‡ç†ç”±"] || ""}</td>
      <td>${r["åˆå‹•ãƒ•ãƒ©ã‚°"] || ""}</td>
      <td>${r["åº•æ‰“ã¡ãƒ•ãƒ©ã‚°"] || ""}</td>
      <td>${r["å³è‚©ä¸ŠãŒã‚Šãƒ•ãƒ©ã‚°"] || ""}</td>
      <td>${r["å³è‚©æ—©æœŸãƒ•ãƒ©ã‚°"] || ""}</td>
      <td class="num">${r["å³è‚©æ—©æœŸã‚¹ã‚³ã‚¢"] ?? ""}</td>
      <td>${etBadge}${r["å³è‚©æ—©æœŸç¨®åˆ¥_mini"] || ""}</td>
      <td>${formatJudgeLabel(r)}</td>
      <td class="reason-col">${r["åˆ¤å®šç†ç”±"] || ""}</td>
      <td>${recBadge}</td>
      <td class="num">${r["æ¨å¥¨æ¯”ç‡"] ?? ""}</td>
      <td>${r["ã‚·ã‚°ãƒŠãƒ«æ›´æ–°æ—¥"] || ""}</td>
    </tr>`;
  }
  body.innerHTML = html;
  document.querySelector("#count").textContent = String(total);
  document.querySelector("#pageinfo").textContent = `${state.page} / ${Math.max(1, Math.ceil(total/state.per))}`;
  wireDomSort("#tbl-candidate");
}


// === Tomorrow logic START =====================================

// æ­£è¦åŒ–: ä»»æ„ã® Date / æ–‡å­—åˆ— â†’ YYYY-MM-DD
function toKey(x){
  if (x instanceof Date) {
    const y=x.getFullYear(), m=('0'+(x.getMonth()+1)).slice(-2), d=('0'+x.getDate()).slice(-2);
    return `${y}-${m}-${d}`;
  }
  const s = String(x ?? "").trim().slice(0,10).replace(/[./]/g,'-').replace(/\//g,'-');
  const m = s.match(/^(\d{4})-(\d{1,2})-(\d{1,2})$/);
  if (m) return `${m[1]}-${m[2].padStart(2,'0')}-${m[3].padStart(2,'0')}`;
  const dt = new Date(s);
  if (isNaN(+dt)) return "";
  const yy=dt.getFullYear(), mm=('0'+(dt.getMonth()+1)).slice(-2), dd=('0'+dt.getDate()).slice(-2);
  return `${yy}-${mm}-${dd}`;
}

function latestUpdateDate(rows){
  const ds = (rows||[]).map(r=>toKey(r?.["ã‚·ã‚°ãƒŠãƒ«æ›´æ–°æ—¥"])).filter(Boolean);
  return ds.sort().pop() || null;
}

function localDateStr(d){
  const y=d.getFullYear(), m=('0'+(d.getMonth()+1)).slice(-2), da=('0'+d.getDate()).slice(-2);
  return `${y}-${m}-${da}`;
}
function prevBusinessDay(d){
  const dt=new Date(d); do{ dt.setDate(dt.getDate()-1);}while([0,6].includes(dt.getDay())); return dt;
}
function nextBusinessDay(d){
  const dt=new Date(d); do{ dt.setDate(dt.getDate()+1);}while([0,6].includes(dt.getDay())); return dt;
}

// ã€Œå€™è£œã€åˆ¤å®šï¼ˆåˆå‹•/å³è‚©/æ—©æœŸã®ã„ãšã‚Œã‹ï¼‰
function _hasCandidateFlag(r){
  return String(r?.["åˆå‹•ãƒ•ãƒ©ã‚°"]||"").includes("å€™è£œ")
      || String(r?.["å³è‚©ä¸ŠãŒã‚Šãƒ•ãƒ©ã‚°"]||"").includes("å€™è£œ")
      || String(r?.["å³è‚©æ—©æœŸãƒ•ãƒ©ã‚°"]||"").includes("å€™è£œ");
}

// åŸºæº–æ—¥ã‚­ãƒ¼ã«å¯¾ã—ã¦ã€Œå€™è£œã€ã ã‘ã‚’æŠ½å‡º
function _pickTomorrowRows(src, baseKey){
  if(!Array.isArray(src) || !baseKey) return [];
  return src.filter(r => toKey(r?.["ã‚·ã‚°ãƒŠãƒ«æ›´æ–°æ—¥"])===baseKey && _hasCandidateFlag(r));
}

// ãƒ­ãƒ¼ã‚«ãƒ«æ™‚è¨ˆã‹ã‚‰åŸºæº–æ—¥/å¯¾è±¡æ—¥ã‚’è¨ˆç®—ï¼ˆ14:30 å‡çµãƒ«ãƒ¼ãƒ«ï¼‰
function _computeBaseAndTargetFromLocalNow(){
  const now = new Date();
  const inFreeze = (now.getHours() < 14) || (now.getHours() === 14 && now.getMinutes() < 30);
  const today = new Date(now.getFullYear(), now.getMonth(), now.getDate());
  const baseDate = inFreeze ? prevBusinessDay(today) : today;
  const targetDate = nextBusinessDay(baseDate);
  return { inFreeze, baseDate, targetDate };
}

function renderTomorrow(rows){
  const body = document.querySelector("#tbl-tmr tbody");
  if (!body) return;
  let html = "";
  rows.forEach(r=>{
    const rec = (r["æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"] || "").trim();
    let recBadge = "";
    if (rec === "ã‚¨ãƒ³ãƒˆãƒªãƒ¼æœ‰åŠ›") recBadge = '<span class="rec-badge rec-strong" title="ã‚¨ãƒ³ãƒˆãƒªãƒ¼æœ‰åŠ›"><span class="rec-dot"></span>æœ‰åŠ›</span>';
    else if (rec === "å°å£ææ¡ˆ")   recBadge = '<span class="rec-badge rec-small" title="å°å£ææ¡ˆ"><span class="rec-dot"></span>å°å£</span>';
    else if (rec)                  recBadge = `<span class="rec-badge rec-watch" title="${rec.replace(/"/g,'&quot;')}"><span class="rec-dot"></span>${rec}</span>`;
    const isHit = isHitRow(r);
    html += `<tr${isHit ? " class='hit'" : ""}>
      <td>${codeLink(r["ã‚³ãƒ¼ãƒ‰"])} ${offeringBadge(r["ã‚³ãƒ¼ãƒ‰"])}</td>
      <td>${r["éŠ˜æŸ„å"] ?? ""}</td>
      <td>${r["å¸‚å ´"] || "-"}</td>
      <td><a href="${r["yahoo_url"]??"#"}" target="_blank" rel="noopener">Yahoo</a></td>
      <td><a href="${r["x_url"]??"#"}" target="_blank" rel="noopener">Xæ¤œç´¢</a></td>
      <td class="num" data-sort="${r['ç¾åœ¨å€¤_raw'] ?? ''}">${r['ç¾åœ¨å€¤'] ?? ''}</td>
      <td class="num" data-sort="${r['å‰æ—¥çµ‚å€¤æ¯”ç‡_raw'] ?? ''}">${r['å‰æ—¥çµ‚å€¤æ¯”ç‡'] ?? ''}</td>
      <td class="num">${r["å£²è²·ä»£é‡‘(å„„)"]??""}</td>
      <td>${financeLink(r["ã‚³ãƒ¼ãƒ‰"])}${financeNote(r)}</td>
      <td>${r["å¢—è³‡ãƒªã‚¹ã‚¯"] ?? ""}</td>
      <td class="num">${r["å¢—è³‡ã‚¹ã‚³ã‚¢"] ?? ""}</td>
      <td class="reason-col">${r["å¢—è³‡ç†ç”±"] || ""}</td>
      <td class="num">${r["å³è‚©æ—©æœŸã‚¹ã‚³ã‚¢"]??""}</td>
      <td>${(r["å³è‚©æ—©æœŸç¨®åˆ¥"]||"").trim()}</td>
      <td>${isHit ? "å½“ãŸã‚Šï¼(1)" : "å¤–ã‚Œï¼(1)"}</td>
      <td>${recBadge}</td>
    </tr>`;
  });
  body.innerHTML = html;
  wireDomSort("#tbl-tmr");
}

// ä¸¦ã³æ›¿ãˆï¼ˆæ¨å¥¨ > å³è‚©æ—©æœŸS > å£²è²·ä»£é‡‘ï¼‰
function _sortTomorrow(rows){
  return rows.slice().sort((a,b)=>{
    const rank = (x)=> x==="ã‚¨ãƒ³ãƒˆãƒªãƒ¼æœ‰åŠ›" ? 2 : (x==="å°å£ææ¡ˆ" ? 1 : 0);
    const r = rank((b["æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"]||"").trim()) - rank((a["æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"]||"").trim());
    if (r !== 0) return r;
    const s = (+b["å³è‚©æ—©æœŸã‚¹ã‚³ã‚¢"]||0) - (+a["å³è‚©æ—©æœŸã‚¹ã‚³ã‚¢"]||0);
    if (s !== 0) return s;
    return (+b["å£²è²·ä»£é‡‘(å„„)"]||0) - (+a["å£²è²·ä»£é‡‘(å„„)"]||0);
  });
}

function renderTomorrowWrapper(){
  // 1) åŸºæº–æ—¥/å¯¾è±¡æ—¥ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«æ™‚è¨ˆ & 14:30 å‡çµï¼‰
  const { inFreeze, baseDate, targetDate } = _computeBaseAndTargetFromLocalNow();
  const baseKey = toKey(baseDate);
  const targetKey = toKey(targetDate);

  // 2) ãƒ‡ãƒ¼ã‚¿å´ã®æœ€æ–°æ›´æ–°æ—¥ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
  const latestKey = latestUpdateDate(DATA_CAND);

  // 3) æŠ½å‡ºï¼ˆã‚¼ãƒ­å›é¿ã®å¤šæ®µãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
  let reason = `åŸºæº–æ—¥ã®ã€Œå€™è£œã€`;
  let rows = _pickTomorrowRows(DATA_CAND, baseKey);

  if (rows.length === 0 && latestKey && latestKey !== baseKey){
    rows = _pickTomorrowRows(DATA_CAND, latestKey);
    if (rows.length) reason = `æœ€æ–°æ—¥(${latestKey})ã®ã€Œå€™è£œã€ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯`;
  }
  if (rows.length === 0){
    rows = (DATA_CAND||[]).filter(r => toKey(r?.["ã‚·ã‚°ãƒŠãƒ«æ›´æ–°æ—¥"])===baseKey);
    if (rows.length) reason = `åŸºæº–æ—¥(${baseKey})ã®å…¨ä»¶ï¼ˆå€™è£œæ¡ä»¶ãªã—ï¼‰`;
  }
  if (rows.length === 0 && latestKey){
    rows = (DATA_CAND||[]).filter(r => toKey(r?.["ã‚·ã‚°ãƒŠãƒ«æ›´æ–°æ—¥"])===latestKey);
    if (rows.length) reason = `æœ€æ–°æ—¥(${latestKey})ã®å…¨ä»¶ï¼ˆå€™è£œæ¡ä»¶ãªã—ï¼‰`;
  }
  if (rows.length === 0){
    rows = (DATA_CAND||[]).slice();
    reason = `å…¨ä½“ã‹ã‚‰ã®ã‚µãƒ³ãƒ—ãƒ«`;
  }

  // ä¸¦ã³æ›¿ãˆ & ä¸Šé™ï¼ˆè¦‹ã‚„ã™ã•ç”¨ã«æœ€å¤§2000ã¯ãã®ã¾ã¾ï¼‰
  rows = _sortTomorrow(rows);

  // 4) ãƒ©ãƒ™ãƒ«æ›´æ–°ï¼ˆåŸºæº–æ—¥ãƒ»å¯¾è±¡æ—¥ãƒ»å‡çµçŠ¶æ…‹ãƒ»æŠ½å‡ºæ ¹æ‹ ï¼‰
  const lbl = document.getElementById("tmr-label");
  if (lbl){
    const baseStr = localDateStr(baseDate);
    const tgtStr  = localDateStr(targetDate);
    const freezeStr = inFreeze ? "ON" : "OFF";
    lbl.textContent = `ğŸ“… ${tgtStr} å‘ã‘ï¼ˆåŸºæº–æ—¥: ${baseStr} / å‡çµ: ${freezeStr} / æŠ½å‡º: ${rows.length}ä»¶ãƒ»${reason}ï¼‰`;
  }

  // 5) æç”»
  window.DATA_TMR = rows;
  renderTomorrow(rows);
}

// === Tomorrow logic END =====================================




  // all
  function renderAll(){
    const head = document.querySelector("#all-head"), body = document.querySelector("#all-body");
    if(!head||!body) return;
    head.innerHTML=body.innerHTML="";
    const rows=DATA_ALL;
    if(!rows.length) return;
    const cols=Object.keys(rows[0]);
    head.innerHTML=cols.map(c=>{
      const typ=(c.includes("ãƒ•ãƒ©ã‚°")?"flag":(c.includes("æ—¥")||c.includes("æ›´æ–°")||c==="æ—¥æ™‚"?"date":(["ç¾åœ¨å€¤","å‡ºæ¥é«˜","å£²è²·ä»£é‡‘(å„„)","æ™‚ä¾¡ç·é¡å„„å††","å³è‚©æ—©æœŸã‚¹ã‚³ã‚¢","æ¨å¥¨æ¯”ç‡","å‰æ—¥çµ‚å€¤æ¯”ç‡","å‰æ—¥çµ‚å€¤æ¯”ç‡ï¼ˆï¼…ï¼‰"].includes(c)?"num":"text")));
      return `<th class="sortable ${typ==='num'?'num':''}" data-col="${c}" data-type="${typ}">${c}<span class="arrow"></span></th>`;
    }).join("");
    body.innerHTML=rows.slice(0,2000).map(r=>`<tr>${
      cols.map(c=>{
        let v = (c === "åˆ¤å®š") ? formatJudgeLabel(r) : (r[c] ?? "");
        if (c === "ã‚³ãƒ¼ãƒ‰") v = codeLink(v);
        const isNum = ['ç¾åœ¨å€¤','å‡ºæ¥é«˜','å£²è²·ä»£é‡‘(å„„)','æ™‚ä¾¡ç·é¡å„„å††','å³è‚©æ—©æœŸã‚¹ã‚³ã‚¢','æ¨å¥¨æ¯”ç‡','å‰æ—¥çµ‚å€¤æ¯”ç‡','å‰æ—¥çµ‚å€¤æ¯”ç‡ï¼ˆï¼…ï¼‰'].includes(c);
        return `<td class="${isNum?'num':''}">${v}</td>`;
      }).join("")
    }</tr>`).join("");
    wireDomSort("#tbl-allcols");
  }
  
  // --- ã“ã“ã‹ã‚‰è¿½åŠ  ---
  // ã‚¿ãƒ–å…±é€šãƒ¬ãƒ³ãƒ€ãƒ©ãƒ¼ï¼ˆãƒ•ã‚£ãƒ«ã‚¿/ãƒšãƒ¼ã‚¸ãƒ£/åˆæœŸåŒ–ã‹ã‚‰å‘¼ã°ã‚Œã‚‹ï¼‰
  function render(){
    if (state.tab === "all") { renderAll(); return; }
    if (state.tab === "tmr") { renderTomorrowWrapper(); return; }
    // æ—¢å®šã¯å€™è£œä¸€è¦§
    renderCand();
  }
  // --- ã“ã“ã¾ã§è¿½åŠ  ---

  // earn
  function fmtTime(ts){
    try{
      const d = new Date(ts);
      if (!isNaN(d)) {
        const y=d.getFullYear(), m=('0'+(d.getMonth()+1)).slice(-2), da=('0'+d.getDate()).slice(-2);
        const hh=('0'+d.getHours()).slice(-2), mm=('0'+d.getMinutes()).slice(-2);
        return `${y}/${m}/${da} ${hh}:${mm}`;
      }
      return String(ts ?? "");
    }catch(_){ return String(ts ?? ""); }
  }
  function renderEarnings(rows){
    const tbody = document.getElementById("earn-body"); if(!tbody) return;
    if(!rows.length){ tbody.innerHTML = `<tr><td colspan="4" class="muted">ãƒ‡ãƒ¼ã‚¿ãªã—</td></tr>`; return; }
    tbody.innerHTML = rows.map(r=>{
      const name = r.name ?? r.symbol ?? r.éŠ˜æŸ„ ?? "";
      const sentiment = (r.sentiment ?? "").toString().toLowerCase();
      const pillClass = sentiment.includes("pos") || sentiment.includes("ãƒã‚¸") ? "b-green"
                     : sentiment.includes("neg") || sentiment.includes("ãƒã‚¬") ? "b-orange"
                     : "b-yellow";
      const pill = `<span class="badge ${pillClass}">â— ${r.sentiment ?? "ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«"}</span>`;
      return `<tr>
        <td>${name}</td>
        <td>${pill}</td>
        <td>${r.title ?? ""}</td>
        <td class="mono">${fmtTime(r.time)}</td>
      </tr>`;
    }).join("");
    wireDomSort("#tbl-earn");
  }

  // pre-earn
  function _fmt2num(x){
    if (x === null || x === undefined) return "";
    const n = parseFloat(String(x).replace(/[,ï¼…%]/g,""));
    if (!Number.isFinite(n)) return String(x ?? "");
    return Number.isInteger(n) ? String(n) : n.toFixed(2);
  }
  function _formatTwoDecimals(tableSelector){
    const tbl = document.querySelector(tableSelector);
    if (!tbl) return;
    const ths = Array.from(tbl.querySelectorAll("thead th"));
    const targets = [];
    const norm = (s)=> String(s||"").replace(/\s+/g,"").replace(/[ï¼ˆï¼‰]/g, v=> (v==="ï¼ˆ"?"(" : ")")).trim();
    ths.forEach((th, idx)=>{
      const t = norm(th.textContent);
      if (t.includes("å‰æ—¥çµ‚å€¤æ¯”ç‡")) targets.push(idx);
      if (t === "å£²è²·ä»£é‡‘(å„„)" || t === "å£²è²·ä»£é‡‘å„„") targets.push(idx);
      if (t === "ç¾åœ¨å€¤" || t === "å‰æ—¥çµ‚å€¤" || t === "å‰æ—¥æ¯”(å††)") targets.push(idx);
    });
    if (!targets.length) return;
    const rows = tbl.querySelectorAll("tbody tr");
    rows.forEach(tr=>{
      targets.forEach(ci=>{
        const td = tr.children[ci]; if (!td) return;
        const raw = td.textContent.trim(); if (!raw) return;
        td.textContent = _fmt2num(raw); td.classList.add("num");
      });
    });
  }
  function renderPreEarnings(rows){
    const tbody = document.getElementById("preearn-body"); if(!tbody) return;
    if(!rows.length){
      tbody.innerHTML = `<tr><td colspan="9" class="muted">ãƒ‡ãƒ¼ã‚¿ãªã—</td></tr>`;
      return;
    }
    tbody.innerHTML = rows.map(r=>`
      <tr>
        <td>${r.name ?? r.symbol ?? r.éŠ˜æŸ„ ?? ""}</td>
        <td class="num">${_fmt2num(r.pre_score)}</td>
        <td class="num">${_fmt2num(r.edge_score)}</td>
        <td class="num">${_fmt2num(r.momentum_score)}</td>
        <td class="reason-col"><div class="reason-box">${(r["ã‚¹ã‚³ã‚¢ç†ç”±"] ?? "æ ¹æ‹ è–„ã‚ï¼ˆæš«å®šï¼‰")}</div></td>
        <td class="hint-col"><div class="reason-box">${(r["äºˆæ¸¬ãƒ’ãƒ³ãƒˆ"] ?? "ï¼ˆæº–å‚™ä¸­ï¼‰")}</div></td>
        <td class="num">${_fmt2num(r["æœŸå¾…æ ªä¾¡"]) || (_fmt2num(r.ç¾åœ¨å€¤) || "")}</td>
        <td>${r["ä¿®æ­£è¦‹é€šã—"] ?? "ä¸­ç«‹"}</td>
        <td>${r["éç†±åº¦"] ?? "ä¸­ç«‹"}</td>
      </tr>
    `).join("");
    wireDomSort("#tbl-preearn");
    _formatTwoDecimals("#tbl-preearn");
  }

  // help & modal
  function ensureHelpDom(){
    let bd=document.querySelector(".help-backdrop");
    if(!bd){ bd=document.createElement("div"); bd.className="help-backdrop"; document.body.appendChild(bd); }
    let pp=document.querySelector(".help-pop");
    if(!pp){ pp=document.createElement("div"); pp.className="help-pop"; pp.innerHTML='<div class="help-head"><div>ãƒ˜ãƒ«ãƒ—</div><div class="help-close">Ã—</div></div><div class="help-body"></div>'; document.body.appendChild(pp); }
    pp.querySelector(".help-close").onclick=()=>{ pp.style.display="none"; bd.style.display="none"; };
    bd.onclick=()=>{ pp.style.display="none"; bd.style.display="none"; };
    return {bd,pp};
  }
  function closeAllTips(){ const t=document.querySelectorAll('.tooltip, .popover'); t.forEach(el=>el.remove()); }
  function ensureChartModal(){
    let bd=document.getElementById("__chart_back__");
    if(!bd){ bd=document.createElement("div"); bd.id="__chart_back__"; bd.className="help-backdrop"; document.body.appendChild(bd); }
    let pp=document.querySelector("#__chart_box__");
    if(!pp){
      pp=document.createElement("div"); pp.id="__chart_box__"; pp.className="help-pop";
      pp.innerHTML=`<div class="help-head"><div>ã‚°ãƒ©ãƒ•</div><div class="help-close">Ã—</div></div><div id="__chart_body__"></div>`;
      document.body.appendChild(pp);
    }
    pp.querySelector(".help-close").onclick=()=>{ pp.style.display="none"; bd.style.display="none"; };
    bd.onclick=()=>{ pp.style.display="none"; bd.style.display="none"; };
    return bd;
  }

  // charts (simple canvas)
  function drawBar(canvas, labels, values, title){
    const ctx = canvas.getContext("2d"), W = canvas.width, H = canvas.height, pad = 40;
    ctx.clearRect(0,0,W,H);
    ctx.fillStyle = "#000"; ctx.font = "14px system-ui"; ctx.fillText(title, pad, 24);
    ctx.strokeStyle = "#ccc"; ctx.lineWidth = 1;
    ctx.beginPath(); ctx.moveTo(pad, H - pad); ctx.lineTo(W - pad, H - pad); ctx.stroke();
    ctx.beginPath(); ctx.moveTo(pad, H - pad); ctx.lineTo(pad, pad); ctx.stroke();
    const nums = values.map(v => (v === "" || v == null ? NaN : +v));
    const finite = nums.filter(Number.isFinite);
    if (!finite.length) { ctx.fillText("ãƒ‡ãƒ¼ã‚¿ãªã—ï¼ˆæ¬ æï¼‰", pad, H/2); return; }
    const max = Math.max(1, ...finite);
    const bw  = (W - pad*2) / labels.length * 0.7;
    labels.forEach((lb, i) => {
      const v = Number.isFinite(nums[i]) ? nums[i] : 0;
      const x = pad + (i + 0.15) * (W - pad*2) / labels.length;
      const h = (H - pad*2) * (v / max);
      ctx.fillStyle = "#4a90e2";
      if (h > 0) ctx.fillRect(x, H - pad - h, bw, h);
      ctx.fillStyle = "#333"; ctx.font = "12px system-ui";
      ctx.fillText(lb, x, H - pad + 14);
      ctx.fillText(String(v), x, H - pad - h - 4);
    });
  }
  function drawLine(canvas, labels, values, title){
    const ctx = canvas.getContext("2d"), W = canvas.width, H = canvas.height, pad = 40;
    ctx.clearRect(0,0,W,H);
    ctx.fillStyle = "#000"; ctx.font = "14px system-ui"; ctx.fillText(title, pad, 24);
    ctx.strokeStyle = "#ccc"; ctx.lineWidth = 1;
    ctx.beginPath(); ctx.moveTo(pad, H - pad); ctx.lineTo(W - pad, H - pad); ctx.stroke();
    ctx.beginPath(); ctx.moveTo(pad, H - pad); ctx.lineTo(pad, pad); ctx.stroke();
    const nums = values.map(v => (v === "" || v == null ? NaN : +v));
    const finite = nums.filter(Number.isFinite);
    if (!finite.length) { ctx.fillText("ãƒ‡ãƒ¼ã‚¿ãªã—ï¼ˆæ¬ æï¼‰", pad, H/2); return; }
    const max = Math.max(1, ...finite);
    const min = Math.min(0, ...finite);
    const step = (W - pad*2) / Math.max(1, labels.length - 1);
    ctx.strokeStyle = "#4a90e2"; ctx.lineWidth = 2; ctx.beginPath();
    nums.forEach((v, i) => {
      const val = Number.isFinite(v) ? v : 0;
      const x = pad + i * step;
      const y = H - pad - (H - pad*2) * ((val - min) / (max - min || 1));
      if (i === 0) ctx.moveTo(x, y); else ctx.lineTo(x, y);
    });
    ctx.stroke();
    if (labels.length === 1) { const x = pad; const val = Number.isFinite(nums[0]) ? nums[0] : 0;
      const y = H - pad - (H - pad*2) * ((val - min) / (max - min || 1));
      ctx.fillStyle = "#4a90e2"; ctx.beginPath(); ctx.arc(x, y, 3, 0, Math.PI*2); ctx.fill(); }
    ctx.fillStyle = "#333"; ctx.font = "12px system-ui";
    labels.forEach((lb, i) => { const x = pad + i * step; ctx.fillText(lb, x - 10, H - pad + 14); });
  }

  function openStatsChart(){
    const back = ensureChartModal(), body = $("#__chart_body__");
    const rows = applyFilter(state.data);
    const rvolBuckets=["<1","1-2","2-3","3-5","5+"], rvolCnt=[0,0,0,0,0];
    const turnBuckets=["<5","5-10","10-50","50-100","100+"], turnCnt=[0,0,0,0,0];
    rows.forEach(r=>{
      const rvol = num(r["RVOLä»£é‡‘"]);
      if(!Number.isNaN(rvol)){ if(rvol<1)rvolCnt[0]++; else if(rvol<2)rvolCnt[1]++; else if(rvol<3)rvolCnt[2]++; else if(rvol<5)rvolCnt[3]++; else rvolCnt[4]++; }
      const turn = num(r["å£²è²·ä»£é‡‘(å„„)"]);
      if(!Number.isNaN(turn)){ if(turn<5)turnCnt[0]++; else if(turn<10)turnCnt[1]++; else if(turn<50)turnCnt[2]++; else if(turn<100)turnCnt[3]++; else turnCnt[4]++; }
    });
    body.innerHTML = `<h3>å‚¾å‘ã‚°ãƒ©ãƒ•ï¼ˆè¡¨ç¤ºä¸­ãƒ‡ãƒ¼ã‚¿ï¼‰</h3><canvas id="cv1" style="width:100%;height:340px;"></canvas><canvas id="cv2" style="width:100%;height:340px;margin-top:16px;"></canvas>`;
    const c1 = body.querySelector("#cv1"), c2 = body.querySelector("#cv2");
    const fit = ()=>{
      const cssW = body.clientWidth || 900, cssH = 340, dpr = window.devicePixelRatio || 1;
      [c1,c2].forEach(cv=>{
        cv.width = Math.floor(cssW*dpr); cv.height = Math.floor(cssH*dpr);
        cv.style.width = cssW+"px"; cv.style.height = cssH+"px";
        const ctx = cv.getContext("2d"); if (ctx && ctx.setTransform) ctx.setTransform(dpr,0,0,dpr,0,0);
      });
      drawBar(c1, rvolBuckets, rvolCnt, "RVOLä»£é‡‘ã®åˆ†å¸ƒ");
      drawBar(c2, turnBuckets, turnCnt, "å£²è²·ä»£é‡‘(å„„)ã®åˆ†å¸ƒ");
    };
    if (window.__stats_fit__) window.removeEventListener("resize", window.__stats_fit__);
    window.__stats_fit__ = fit;
    window.addEventListener("resize", fit, { passive:true });
    fit();
    back.style.display="block";
    const box = document.querySelector("#__chart_box__"); box.style.display="block";
    const sy = window.scrollY||0; box.style.top = `${sy+80}px`;
    requestAnimationFrame(()=>{ box.style.left = `${Math.max(10,(document.documentElement.clientWidth - box.offsetWidth)/2)}px`; });
  }

  function openTrendChart(){
    const back = ensureChartModal(), body = $("#__chart_body__");
    let src = [];
    try { const RAW = JSON.parse(document.getElementById("__DATA__").textContent || "{}"); if (Array.isArray(RAW.hist) && RAW.hist.length) src = RAW.hist; } catch(_) {}
    if (!src.length) src = applyFilter(state.data);
    const byDay = new Map();
    src.forEach(r=>{
      const d = String(r["ã‚·ã‚°ãƒŠãƒ«æ›´æ–°æ—¥"]||r["æ—¥ä»˜"]||r["æ—¥æ™‚"]||"").slice(0,10);
      if(!d) return;
      const hit = isHitRow(r) ? 1 : 0;
      const o = byDay.get(d) || {tot:0,hit:0};
      o.tot++; o.hit += hit;
      byDay.set(d,o);
    });
    const days = Array.from(byDay.keys()).sort();
    const rate = days.map(d=>{ const o = byDay.get(d)||{tot:0,hit:0}; return o.tot ? Math.round(1000*o.hit/o.tot)/10 : 0; });
    body.innerHTML = `<h3>æ¨ç§»ã‚°ãƒ©ãƒ•ï¼ˆæ—¥åˆ¥ å½“ãŸã‚Šç‡ %ï¼‰</h3><canvas id="cv3" style="width:100%;height:340px;"></canvas>`;
    const cv = body.querySelector("#cv3");
    const fit = ()=>{
      const cssW = body.clientWidth || 900, cssH = 340, dpr = window.devicePixelRatio || 1;
      cv.width = Math.floor(cssW*dpr); cv.height = Math.floor(cssH*dpr);
      cv.style.width = cssW+"px"; cv.style.height = cssH+"px";
      const ctx = cv.getContext("2d"); if (ctx && ctx.setTransform) ctx.setTransform(dpr,0,0,dpr,0,0);
      drawLine(cv, days, rate, "å½“ãŸã‚Šç‡ï¼ˆ%ï¼‰");
    };
    if (window.__trend_fit__) window.removeEventListener("resize", window.__trend_fit__);
    window.__trend_fit__ = fit;
    window.addEventListener("resize", fit, {passive:true});
    fit();
    back.style.display="block";
    const box = document.querySelector("#__chart_box__"); box.style.display="block";
    const sy = window.scrollY||0; box.style.top = `${sy+80}px`;
    requestAnimationFrame(()=>{ box.style.left = `${Math.max(10,(document.documentElement.clientWidth - box.offsetWidth)/2)}px`; });
  }

  // events
  $("#perpage")?.addEventListener("change",(e)=>{ const v=parseInt(e.target.value,10); state.per=Number.isFinite(v)?v:500; state.page=1; render(); });
  $("#prev")?.addEventListener("click",()=>{ if(state.page>1){state.page--; render();} });
  $("#next")?.addEventListener("click",()=>{ state.page++; render(); });
  $("#q")?.addEventListener("input",(e)=>{ state.q=e.target.value||""; state.page=1; render(); });
  ["th_rate","th_turn","th_rvol","f_shodou","f_tei","f_both","f_rightup","f_early","f_etype","f_recstrong","f_smallpos","f_noshor","f_opratio","f_hit"]
    .forEach(id=>{ $("#"+id)?.addEventListener("input", ()=>{ state.page=1; render(); });
                   $("#"+id)?.addEventListener("change",()=>{ state.page=1; render(); }); });
  $("#btn-stats")?.addEventListener("click",openStatsChart);
  $("#btn-ts")?.addEventListener("click",openTrendChart);
  $("#f_defaultset")?.addEventListener("change",(e)=>applyDefaults(e.target.checked));

  // tabs
  function switchTab(to){
    state.tab = to;
    $$(".tab").forEach(el=>el.classList.add("hidden"));
    $$("nav a").forEach(a=>a.classList.remove("active"));
    if (to === "cand"){
      $("#tab-candidate")?.classList.remove("hidden");
      $("#lnk-cand")?.classList.add("active");
      state.data = DATA_CAND.slice();
      state.page = 1;
      render();
      return;
    }
    if (to === "tmr"){
      $("#tab-tmr")?.classList.remove("hidden");
      $("#lnk-tmr")?.classList.add("active");
      renderTomorrowWrapper();
      return;
    }
    if (to === "all"){
      $("#tab-all")?.classList.remove("hidden");
      $("#lnk-all")?.classList.add("active");
      state.page = 1;
      render();
      return;
    }
    if (to === "log"){
      $("#tab-log")?.classList.remove("hidden");
      $("#lnk-log")?.classList.add("active");
      const lb = $("#log-body");
      if (lb && !lb.getAttribute("data-inited")){
        lb.innerHTML = (DATA_LOG||[]).map(r=> `<tr><td>${r["æ—¥æ™‚"]||""}</td><td>${r["ã‚³ãƒ¼ãƒ‰"]||""}</td><td>${r["ç¨®åˆ¥"]||""}</td><td>${r["è©³ç´°"]||""}</td></tr>`).join("");
        lb.setAttribute("data-inited","1");
      }
      return;
    }
    if (to === "earn"){
      $("#tab-earn")?.classList.remove("hidden");
      $("#lnk-earn")?.classList.add("active");
      renderEarnings(DATA_EARN);
      return;
    }
    if (to === "preearn"){
      $("#tab-preearn")?.classList.remove("hidden");
      $("#lnk-preearn")?.classList.add("active");
      renderPreEarnings(DATA_PREEARN);
      return;
    }
  }
  (function(){
    const map = { "lnk-cand":"cand","lnk-tmr":"tmr","lnk-all":"all","lnk-log":"log","lnk-earn":"earn","lnk-preearn":"preearn" };
    Object.keys(map).forEach(id=>{
      const a = document.getElementById(id);
      if (!a) return;
      a.addEventListener("click", (e)=>{ e.preventDefault(); switchTab(map[id]); });
    });
  })();

  // initialï¼ˆã“ã“ã‚’å·®ã—æ›¿ãˆï¼‰
  window.addEventListener("DOMContentLoaded", () => {
    // 1) ã‚¿ãƒ–åˆæœŸåŒ–ï¼ˆã“ã®æ™‚ç‚¹ã§DOMãŒå‡ºæ¥ã¦ã„ã‚‹ã®ã§æç”»ã•ã‚Œã‚‹ï¼‰
    switchTab("cand");
    forceClearThresholds();

    // 2) 1è¡Œè¡¨ã§ã® <br> ã‚’ã‚¹ãƒšãƒ¼ã‚¹ã«ç½®æ›ï¼ˆå…ƒã®å‡¦ç†ã‚’çµ±åˆï¼‰
    document.querySelectorAll('#tbl-candidate td br, #tbl-allcols td br')
      .forEach(br => br.replaceWith(' '));
  });


})();</script>

  <section id="tab-candidate" class="tab">
    <div class="tbl-wrap">
      <table id="tbl-candidate" class="tbl">
        <thead>
          <tr>
            <th class="sortable" data-col="ã‚³ãƒ¼ãƒ‰" data-type="text">ã‚³ãƒ¼ãƒ‰<span class="arrow"></span></th>
            <th class="sortable" data-col="éŠ˜æŸ„å" data-type="text">éŠ˜æŸ„<span class="arrow"></span></th>
            <th data-col="å¸‚å ´">å¸‚å ´</th>
            <th>Yahoo</th>
            <th>X</th>
            <th class="num sortable" data-col="ç¾åœ¨å€¤" data-type="num">ç¾åœ¨å€¤<span class="arrow"></span></th>
            <th class="num sortable" data-col="å‰æ—¥çµ‚å€¤" data-type="num">å‰æ—¥çµ‚å€¤<span class="arrow"></span></th>
            <th class="num sortable" data-col="å‰æ—¥å††å·®" data-type="num">å‰æ—¥æ¯”(å††)<span class="arrow"></span></th>
            <th class="num sortable" data-col="å‰æ—¥çµ‚å€¤æ¯”ç‡" data-type="num">å‰æ—¥çµ‚å€¤æ¯”ç‡ï¼ˆï¼…ï¼‰<span class="arrow"></span></th>
            <th class="num sortable" data-col="å‡ºæ¥é«˜" data-type="num">å‡ºæ¥é«˜<span class="arrow"></span></th>
            <th class="num sortable" data-col="å£²è²·ä»£é‡‘(å„„)" data-type="num">å£²è²·ä»£é‡‘(å„„)<span class="arrow"></span></th>
            <th>è²¡å‹™</th>
<th class="num sortable" data-col="ã‚¹ã‚³ã‚¢" data-type="num">ã‚¹ã‚³ã‚¢<span class="arrow"></span></th>
<th class="num sortable" data-col="é€²æ—ç‡" data-type="num">é€²æ—ç‡<span class="arrow"></span></th>
            <th data-col="å¢—è³‡ãƒªã‚¹ã‚¯">å¢—è³‡ãƒªã‚¹ã‚¯</th>
            <th class="num sortable" data-col="å¢—è³‡ã‚¹ã‚³ã‚¢" data-type="num">å¢—è³‡ã‚¹ã‚³ã‚¢<span class="arrow"></span></th>
            <th class="reason-col" data-col="å¢—è³‡ç†ç”±">ç†ç”±</th>
            <th class="sortable" data-col="åˆå‹•ãƒ•ãƒ©ã‚°" data-type="text">åˆå‹•<span class="arrow"></span></th>
            <th class="sortable" data-col="åº•æ‰“ã¡ãƒ•ãƒ©ã‚°" data-type="text">åº•æ‰“ã¡<span class="arrow"></span></th>
            <th class="sortable" data-col="å³è‚©ä¸ŠãŒã‚Šãƒ•ãƒ©ã‚°" data-type="text">å³è‚©<span class="arrow"></span></th>
            <th class="sortable" data-col="å³è‚©æ—©æœŸãƒ•ãƒ©ã‚°" data-type="text">æ—©æœŸ<span class="arrow"></span></th>
            <th class="num sortable" data-col="å³è‚©æ—©æœŸã‚¹ã‚³ã‚¢" data-type="num">æ—©æœŸS<span class="arrow"></span></th>
            <th class="sortable" data-col="å³è‚©æ—©æœŸç¨®åˆ¥" data-type="text">å³è‚©æ—©æœŸç¨®åˆ¥<span class="arrow"></span></th>
            <th class="sortable" data-col="åˆ¤å®š" data-type="text">åˆ¤å®š<span class="arrow"></span></th>
            <th class="sortable reason-col" data-col="åˆ¤å®šç†ç”±" data-type="text">åˆ¤å®šç†ç”±<span class="arrow"></span></th>
            <th class="sortable" data-col="æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³" data-type="text">æ¨å¥¨<span class="arrow"></span></th>
            <th class="num sortable" data-col="æ¨å¥¨æ¯”ç‡" data-type="num">æ¨å¥¨æ¯”ç‡%<span class="arrow"></span></th>
            <th class="sortable" data-col="ã‚·ã‚°ãƒŠãƒ«æ›´æ–°æ—¥" data-type="date">æ›´æ–°<span class="arrow"></span></th>
          </tr>
        </thead>
        <tbody></tbody>
      </table>
    </div>
  </section>

  <section id="tab-tmr" class="tab hidden">
    <div class="tbl-wrap">
      <div id="tmr-label" style="margin:8px 0 4px;font-weight:800;font-size:16px;color:#0d3b66;"></div>
      <table id="tbl-tmr" class="tbl">
        <thead>
          <tr>
            <th class="sortable" data-col="ã‚³ãƒ¼ãƒ‰" data-type="text">ã‚³ãƒ¼ãƒ‰<span class="arrow"></span></th>
            <th class="sortable" data-col="éŠ˜æŸ„å" data-type="text">éŠ˜æŸ„<span class="arrow"></span></th>
            <th data-col="å¸‚å ´">å¸‚å ´</th>
            <th>Yahoo</th>
            <th>X</th>
            <th class="num sortable" data-col="ç¾åœ¨å€¤" data-type="num">ç¾åœ¨å€¤<span class="arrow"></span></th>
            <th class="num sortable" data-col="å‰æ—¥çµ‚å€¤æ¯”ç‡" data-type="num">å‰æ—¥çµ‚å€¤æ¯”ç‡ï¼ˆï¼…ï¼‰<span class="arrow"></span></th>
            <th class="num sortable" data-col="å£²è²·ä»£é‡‘(å„„)" data-type="num">å£²è²·ä»£é‡‘(å„„)<span class="arrow"></span></th>
            <th>è²¡å‹™</th>
            <th data-col="å¢—è³‡ãƒªã‚¹ã‚¯">å¢—è³‡ãƒªã‚¹ã‚¯</th>
            <th class="num sortable" data-col="å¢—è³‡ã‚¹ã‚³ã‚¢" data-type="num">å¢—è³‡ã‚¹ã‚³ã‚¢<span class="arrow"></span></th>
            <th class="reason-col" data-col="å¢—è³‡ç†ç”±">ç†ç”±</th>
            <th class="num sortable" data-col="å³è‚©æ—©æœŸã‚¹ã‚³ã‚¢" data-type="num">æ—©æœŸS<span class="arrow"></span></th>
            <th class="sortable" data-col="å³è‚©æ—©æœŸç¨®åˆ¥" data-type="text">å³è‚©æ—©æœŸç¨®åˆ¥<span class="arrow"></span></th>
            <th class="sortable" data-col="åˆ¤å®š" data-type="text">åˆ¤å®š<span class="arrow"></span></th>
            <th class="sortable" data-col="æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³" data-type="text">æ¨å¥¨<span class="arrow"></span></th>
          </tr>
        </thead>
        <tbody></tbody>
      </table>
    </div>
  </section>

  <section id="tab-all" class="tab hidden">
    <div class="tbl-wrap">
      <table id="tbl-allcols" class="tbl">
        <thead><tr id="all-head"></tr></thead>
        <tbody id="all-body"></tbody>
      </table>
    </div>
  </section>

  <section id="tab-earn" class="tab hidden">
    <div class="tbl-wrap">
      <table id="tbl-earn" class="tbl">
        <thead>
          <tr>
            <th>éŠ˜æŸ„</th>
            <th>ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ</th>
            <th>ã‚¿ã‚¤ãƒˆãƒ«</th>
            <th>æ™‚åˆ»</th>
          </tr>
        </thead>
        <tbody id="earn-body"></tbody>
      </table>
     </div>
   </section>

  <section id="tab-preearn" class="tab hidden">
     <div class="tbl-wrap">
       <table id="tbl-preearn" class="tbl">
         <thead>
           <tr>
             <th>éŠ˜æŸ„</th>
             <th class="num sortable" data-col="pre_score" data-type="num">pre_score<span class="arrow"></span></th>
             <th class="num sortable" data-col="edge_score" data-type="num">edge_score<span class="arrow"></span></th>
             <th class="num sortable" data-col="momentum_score" data-type="num">momentum_score<span class="arrow"></span></th>
             <th class="sortable reason-col" data-col="ã‚¹ã‚³ã‚¢ç†ç”±" data-type="text">ã‚¹ã‚³ã‚¢ç†ç”±<span class="arrow"></span></th>
             <th class="sortable" data-col="äºˆæ¸¬ãƒ’ãƒ³ãƒˆ" data-type="text">äºˆæ¸¬ãƒ’ãƒ³ãƒˆ<span class="arrow"></span></th>
             <th class="num sortable" data-col="æœŸå¾…æ ªä¾¡" data-type="num">æœŸå¾…æ ªä¾¡<span class="arrow"></span></th>
             <th class="sortable" data-col="ä¿®æ­£è¦‹é€šã—" data-type="text">ä¿®æ­£è¦‹é€šã—<span class="arrow"></span></th>
             <th class="sortable" data-col="éç†±åº¦" data-type="text">éç†±åº¦<span class="arrow"></span></th>
           </tr>
         </thead>
         <tbody id="preearn-body"></tbody>
       </table>
     </div>
  </section>

  {% if include_log %}
  <section id="tab-log" class="tab hidden">
    <div class="tbl-wrap">
      <table id="tbl-log" class="tbl">
        <thead>
          <tr>
            <th class="sortable" data-col="æ—¥æ™‚" data-type="date">æ—¥æ™‚<span class="arrow"></span></th>
            <th class="sortable" data-col="ã‚³ãƒ¼ãƒ‰" data-type="text">ã‚³ãƒ¼ãƒ‰<span class="arrow"></span></th>
            <th class="sortable" data-col="ç¨®åˆ¥" data-type="text">ç¨®åˆ¥<span class="arrow"></span></th>
            <th class="sortable" data-col="è©³ç´°" data-type="text">è©³ç´°<span class="arrow"></span></th>
          </tr>
        </thead>
        <tbody id="log-body"></tbody>
      </table>
    </div>
  </section>
  {% endif %}

</body>
</html>"""
# --- FUND settings ---
# fund script
FUND_SCRIPT = r"H:\desctop\æ ªæ”»ç•¥\1-ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°è‡ªå‹•åŒ–ãƒ—ãƒ­ã‚°ãƒ©ãƒ \æ ªæ¢ãƒ•ã‚¡ãƒ³ãƒ€.py"

# --- MARKER settings ---
# marker file
MARKER_FILE = Path(r"H:\desctop\æ ªæ”»ç•¥\1-ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°è‡ªå‹•åŒ–ãƒ—ãƒ­ã‚°ãƒ©ãƒ \screen_data\last_funda.txt")

# ---  settings ---
# â€œæ±ºç®—ç³»â€ã ã‘ã‚’æŠ½å‡ºã™ã‚‹ã‚†ã‚‹ã„ãƒ•ã‚£ãƒ«ã‚¿
_DECISION_PAT = re.compile(r"(æ±ºç®—çŸ­ä¿¡|å››åŠæœŸæ±ºç®—çŸ­ä¿¡|é€šæœŸæ±ºç®—|å››åŠæœŸå ±å‘Šæ›¸|æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸|æ¥­ç¸¾äºˆæƒ³|é…å½“äºˆæƒ³)")
# JSTï¼ˆæ—¥ä»˜åˆ¤å®šã‚’æ—¥æœ¬æ™‚é–“ã§è¡Œã†ï¼‰
_JST = dtm.timezone(dtm.timedelta(hours=9))
#  neg keys
_NEG_KEYS = [
    "ä¸‹æ–¹ä¿®æ­£", "ä¸‹æ–¹", "æ¸›é…", "ç‰¹åˆ¥æå¤±", "æ¥­ç¸¾äºˆæƒ³ã®ä¿®æ­£ï¼ˆæ¸›é¡ï¼‰",
    "é€šæœŸäºˆæƒ³ä¿®æ­£ï¼ˆæ¸›é¡ï¼‰", "é…å½“äºˆæƒ³ã®ä¿®æ­£ï¼ˆæ¸›é¡ï¼‰",
]
# ç°¡æ˜“ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆç”¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
_POS_KEYS = [
    "ä¸Šæ–¹ä¿®æ­£", "ä¸Šæ–¹", "å¢—é…", "è‡ªç¤¾æ ªè²·ã„", "å¾©é…", "ä¸ŠæœŸäºˆæƒ³ä¿®æ­£ï¼ˆå¢—é¡ï¼‰",
    "æ¥­ç¸¾äºˆæƒ³ã®ä¿®æ­£ï¼ˆå¢—é¡ï¼‰", "é€šæœŸäºˆæƒ³ä¿®æ­£ï¼ˆå¢—é¡ï¼‰", "é…å½“äºˆæƒ³ã®ä¿®æ­£ï¼ˆå¢—é¡ï¼‰",
]

try:
    from plyer import notification
except Exception:
    class _DummyNoti:
        @staticmethod
        def notify(title="", message="", timeout=3):
            print(f"[NOTIFY] {title} - {message}")
    notification = _DummyNoti()

try:
    import workdays
except Exception:
    class _WorkdaysShim:
        @staticmethod
        def networkdays(start: dtm.date, end: dtm.date, holidays=None):
            if holidays is None: holidays = []
            if start > end: start, end = end, start
            d, cnt = start, 0
            while d <= end:
                if d.weekday() < 5 and d not in holidays:
                    cnt += 1
                d += dtm.timedelta(days=1)
            return cnt
        @staticmethod
        def workday(start: dtm.date, days: int, holidays=None):
            if holidays is None: holidays = []
            step = 1 if days >= 0 else -1
            d, moved = start, 0
            while moved < abs(days):
                d += dtm.timedelta(days=step)
                if d.weekday() < 5 and d not in holidays:
                    moved += 1
            return d
    workdays = _WorkdaysShim()

# -*- coding: utf-8 -*-
"""
è‡ªå‹•ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°_å®Œå…¨çµ±åˆç‰ˆ + å³è‚©ä¸ŠãŒã‚Šï¼ˆTemplateç‰ˆ/ä¸¡ç«‹ãƒ•ã‚£ãƒ«ã‚¿/Gmail/ã‚ªãƒ•ãƒ©ã‚¤ãƒ³HTML/ç¥æ—¥å¯¾å¿œ/MIDDAYè‡ªå‹•ï¼‰

ä¿®æ­£ç‚¹ï¼ˆã“ã®ç‰ˆï¼‰
- HTMLå‡ºåŠ›ãƒ•ã‚§ãƒ¼ã‚ºã® JSON ç”Ÿæˆã§ã€DataFrame å†…ã® bytes / NaN / pandas.Timestamp / NumPy ã‚¹ã‚«ãƒ©ãƒ¼ã‚’
  å®‰å…¨ã«å¤‰æ›ã§ãã‚‹ã‚ˆã†ã«ä¿®æ­£ï¼ˆTypeError: bytes is not JSON serializable å¯¾ç­–ï¼‰

æ©Ÿèƒ½ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆ
- EOD/MIDDAY è‡ªå‹•åˆ¤å®šï¼ˆJST 11:30â€“12:30 ã¯ MIDDAY ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã€ãã‚Œä»¥å¤–ã¯ EODï¼‰
- ç¥æ—¥/åœŸæ—¥ã‚¹ã‚­ãƒƒãƒ—ï¼ˆjpholiday + è¿½åŠ ä¼‘å ´æ—¥ãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œï¼‰
- yahooquery ã§ quotes / history ã‚’ä¸€æ‹¬å–å¾—ï¼ˆåˆå›ã¯ 12moã€é€šå¸¸ã¯ 10dï¼‰
- åˆå‹•/åº•æ‰“ã¡/ä¸Šæ˜‡ä½™åœ°ã‚¹ã‚³ã‚¢/å³è‚©ä¸ŠãŒã‚Šã‚¹ã‚³ã‚¢ ã®åˆ¤å®šã¨ãƒ­ã‚°ï¼ˆsignals_logï¼‰
- å‰å–¶æ¥­æ—¥ã®ç¿Œæ—¥æ¤œè¨¼ï¼ˆåˆ¤å®šã¨CSVå‡ºåŠ›ï¼‰
- ã‚ªãƒ•ãƒ©ã‚¤ãƒ³1ãƒ•ã‚¡ã‚¤ãƒ«HTMLãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼ˆå€™è£œä¸€è¦§/æ¤œè¨¼/å…¨ã‚«ãƒ©ãƒ /price_history/signals_logï¼‰
- Gmail ã§ index.html ã‚’é€ä¿¡ï¼ˆä»»æ„ã€ZIPåŒæ¢±å¯ï¼‰

å‰æ: Python 3.11 / pip install yahooquery pandas jpholiday
"""

def run_karauri_script():
    """Node.js ã® puppeteer ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’èµ·å‹•ã—ã¦ã€ç©ºå£²ã‚Šç„¡ã—ãƒªã‚¹ãƒˆã‚’æ›´æ–°ã™ã‚‹"""
    if not os.path.exists(KARAURI_PY_PATH):
        print(f"[karauri]  ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {KARAURI_PY_PATH}")
        return

    try:
        print("[karauri] ç©ºå£²ã‚Šç„¡ã—ãƒªã‚¹ãƒˆæŠ½å‡ºã‚’é–‹å§‹...")
        # python å®Ÿè¡Œã€‚ã‚¹ã‚­ãƒƒãƒ—æ¡ä»¶ï¼ˆæ—¥ä»˜ãƒã‚§ãƒƒã‚¯ï¼‰ã¯ JS å´ã«çµ„ã¿è¾¼ã¿æ¸ˆã¿
        subprocess.run(["python", KARAURI_PY_PATH], check=True)
        print("[karauri] æŠ½å‡ºå‡¦ç† å®Œäº†")
    except subprocess.CalledProcessError as e:
        print(f"[karauri][WARN] ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    except Exception as e:
        print(f"[karauri][WARN] äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}")

# --- EDINET å–å¾—ã§ä½¿ã† ---

# =====================================

# é€Ÿåº¦ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
YQ_MAX_WORKERS = 16

# ===== ãƒ•ã‚§ã‚¤ãƒ«ã‚»ãƒ¼ãƒ• =====

warnings.simplefilter(action="ignore", category=FutureWarning)

# ===== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ =====
def ffloat(x, default=None):
    try:
        return default if pd.isna(x) else float(x)
    except Exception:
        try:
            return float(str(x))
        except Exception:
            return default

def fint(x, default=None):
    try:
        if pd.isna(x):
            return default
        if isinstance(x, (int,)) and not isinstance(x, bool):
            return int(x)
        if isinstance(x, float):
            return int(x)
        return int(float(str(x)))
    except Exception:
        return default

def today_str():
    return dtm.datetime.now().strftime("%Y-%m-%d")
    
# ================== è¡¨ç¤ºæ•´å½¢ãƒ˜ãƒ«ãƒ‘ ==================

def _safe_jsonable(val):
    """
    JSONã«å®‰å…¨ã«è½ã¨ã—è¾¼ã‚€ãŸã‚ã®å¤‰æ›ï¼ˆbytes, NaN, Timestamp ç­‰ã‚’å‡¦ç†ï¼‰
    """

    if val is None:
        return None
    if isinstance(val, (bytes, bytearray)):
        try:
            return val.decode("utf-8", errors="ignore")
        except Exception:
            return str(val)
    # pandas/NumPyã®æ¬ æ
    if (isinstance(val, float) and (math.isnan(val))) or (hasattr(pd, "isna") and pd.isna(val)):
        return None
    if isinstance(val, (np.floating, np.integer)):
        return val.item()
    # æ—¥ä»˜ãƒ»æ—¥æ™‚
    if isinstance(val, (pd.Timestamp, dtm.datetime, dtm.date, dtm.time)):
        return str(val)[:19]
    return val

# ===== ç¥æ—¥åˆ¤å®š =====
def _load_extra_closed(path: str):
    s = set()
    try:
        if os.path.isfile(path):
            with open(path, "r", encoding="utf-8") as f:
                for line in f:
                    line = line.strip()
                    if not line or line.startswith("#"):
                        continue
                    s.add(line[:10])
    except Exception:
        pass
    return s

def is_jp_market_holiday(d: dtm.date, extra_closed: set = None) -> bool:
    if d.weekday() >= 5:
        return True
    if (d.month == 12 and d.day == 31) or (d.month == 1 and d.day in (2, 3)):
        return True
    if extra_closed and d.strftime("%Y-%m-%d") in extra_closed:
        return True
    try:
        import jpholiday
        if jpholiday.is_holiday(d):
            return True
    except Exception:
        pass
    return False

def next_business_day_jp(d: dtm.date, extra_closed: set = None) -> dtm.date:
    cur = d
    while True:
        cur += dtm.timedelta(days=1)
        if not is_jp_market_holiday(cur, extra_closed):
            return cur

def prev_business_day_jp(d: dtm.date, extra_closed: set = None) -> dtm.date:
    cur = d
    while True:
        cur -= dtm.timedelta(days=1)
        if not is_jp_market_holiday(cur, extra_closed):
            return cur

# ===== DB =====
def open_conn(db_path: str):
    conn = sqlite3.connect(db_path)
    conn.execute("PRAGMA cache_size=-200000;")
    return conn

def add_column_if_missing(conn: sqlite3.Connection, table: str, col: str, decl: str):
    """Schema fixed: no-op."""
    return

def phase_csv_import(conn, csv_path=None, overwrite_registered_date=False):

    """
    CSV ã‹ã‚‰ã€Œã‚³ãƒ¼ãƒ‰ãƒ»éŠ˜æŸ„åãƒ»å¸‚å ´ãƒ»ç™»éŒ²æ—¥ã€ã®ã¿ã‚’å–ã‚Šè¾¼ã‚€å›ºå®šã‚¹ã‚­ãƒ¼ãƒå®Ÿè£…ã€‚
    - ã‚¹ã‚­ãƒ¼ãƒæ“ä½œï¼ˆPRAGMA/ALTER/CREATEï¼‰ã¯ä¸€åˆ‡è¡Œã‚ãªã„
    - overwrite_registered_date=False ã®å ´åˆã€æ—¢å­˜ç™»éŒ²æ—¥ãŒç©º/NULLã®ã¨ãã®ã¿ä¸Šæ›¸ã
    """
    path = csv_path or CSV_INPUT_PATH
    if not os.path.isfile(path):
        print("CSVãŒãªã„ã®ã§ã‚¹ã‚­ãƒƒãƒ—:", path)
        return

    df = pd.read_csv(path, encoding="utf8", sep=",", engine="python").astype(str)
    needed = ["ã‚³ãƒ¼ãƒ‰", "éŠ˜æŸ„å", "å¸‚å ´", "ç™»éŒ²æ—¥"]
    missing = [c for c in needed if c not in df.columns]
    if missing:
        raise ValueError(f"[csv-import] CSVã«å¿…é ˆåˆ—ãŒã‚ã‚Šã¾ã›ã‚“: {missing}")

    df = df[needed].copy()
    df["ã‚³ãƒ¼ãƒ‰"] = df["ã‚³ãƒ¼ãƒ‰"].astype(str).str.strip().str.zfill(4)
    df["éŠ˜æŸ„å"] = df["éŠ˜æŸ„å"].astype(str).str.strip()
    df["å¸‚å ´"]   = df["å¸‚å ´"].astype(str).str.strip()
    df["ç™»éŒ²æ—¥"] = df["ç™»éŒ²æ—¥"].where(df["ç™»éŒ²æ—¥"].notna() & (df["ç™»éŒ²æ—¥"].str.strip() != ""), None)

    cur = conn.cursor()
    if overwrite_registered_date:
        sql = """
        INSERT INTO screener(ã‚³ãƒ¼ãƒ‰, éŠ˜æŸ„å, å¸‚å ´, ç™»éŒ²æ—¥)
        VALUES (?, ?, ?, ?)
        ON CONFLICT(ã‚³ãƒ¼ãƒ‰) DO UPDATE SET
          éŠ˜æŸ„å = excluded.éŠ˜æŸ„å,
          å¸‚å ´   = excluded.å¸‚å ´,
          ç™»éŒ²æ—¥ = excluded.ç™»éŒ²æ—¥
        """
    else:
        sql = """
        INSERT INTO screener(ã‚³ãƒ¼ãƒ‰, éŠ˜æŸ„å, å¸‚å ´, ç™»éŒ²æ—¥)
        VALUES (?, ?, ?, ?)
        ON CONFLICT(ã‚³ãƒ¼ãƒ‰) DO UPDATE SET
          éŠ˜æŸ„å = excluded.éŠ˜æŸ„å,
          å¸‚å ´   = excluded.å¸‚å ´,
          ç™»éŒ²æ—¥ = CASE
                     WHEN screener.ç™»éŒ²æ—¥ IS NULL OR screener.ç™»éŒ²æ—¥ = '' THEN excluded.ç™»éŒ²æ—¥
                     ELSE screener.ç™»éŒ²æ—¥
                   END
        """
    rows = list(df.itertuples(index=False, name=None))
    cur.executemany(sql, rows)
    conn.commit()
    cur.close()

    print(f"[csv-import] å–ã‚Šè¾¼ã¿å®Œäº†: {len(rows)}ä»¶ï¼ˆã‚³ãƒ¼ãƒ‰/éŠ˜æŸ„å/å¸‚å ´/ç™»éŒ²æ—¥ã®ã¿åæ˜ , overwrite_registered_date={overwrite_registered_date})")
def phase_delist_cleanup(conn: sqlite3.Connection,
                         master_csv_path: str = MASTER_CODES_PATH,
                         also_clean_notes: bool = False) -> None:
    """
    ãƒã‚¹ã‚¿CSV(åˆ—å: ã‚³ãƒ¼ãƒ‰)ã«å­˜åœ¨ã—ãªã„éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã‚’ screener ã‹ã‚‰å‰Šé™¤ã™ã‚‹ã€‚
    also_clean_notes=True ã®å ´åˆã¯ finance_notes ã‚‚åŒæ§˜ã«å‰Šé™¤ã™ã‚‹ã€‚
    """

    if not os.path.isfile(master_csv_path):
        print("ä¸Šå ´å»ƒæ­¢ã®åŸºæº–CSVãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã‚¹ã‚­ãƒƒãƒ—:", master_csv_path)
        return

    def _norm(code) -> str | None:
        try:
            return f"{int(str(code).strip()):04d}"
        except Exception:
            return None

    # ãƒã‚¹ã‚¿å´ã®æœ‰åŠ¹ã‚³ãƒ¼ãƒ‰é›†åˆï¼ˆ4æ¡ã‚¼ãƒ­åŸ‹ã‚ã§æ­£è¦åŒ–ï¼‰
    master = pd.read_csv(master_csv_path, encoding="utf8", sep=",", engine="python")
    valid = {c for c in ( _norm(x) for x in master["ã‚³ãƒ¼ãƒ‰"] ) if c is not None}
    if not valid:
        print("ãƒã‚¹ã‚¿å´ã®æœ‰åŠ¹ã‚³ãƒ¼ãƒ‰ãŒ0ä»¶ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—:", master_csv_path)
        return

    cur = conn.cursor()

    # DBå†…ã‚³ãƒ¼ãƒ‰ã‚’å–å¾—ã—ã¦æ­£è¦åŒ–
    cur.execute("SELECT ã‚³ãƒ¼ãƒ‰ FROM screener")
    rows = cur.fetchall()
    targets = []
    for (db_code,) in rows:
        n = _norm(db_code)
        if n is None or n not in valid:
            targets.append((db_code,))

    if not targets:
        print("ä¸Šå ´å»ƒæ­¢ã«ã‚ˆã‚‹å‰Šé™¤å¯¾è±¡ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        cur.close()
        return

    # å‰Šé™¤ï¼ˆã¾ãšã¯ screenerï¼‰
    print(f"ä¸Šå ´å»ƒæ­¢ã«ã‚ˆã‚‹å‰Šé™¤: {len(targets)} ä»¶")
    cur.executemany("DELETE FROM screener WHERE ã‚³ãƒ¼ãƒ‰ = ?", targets)

    # ã‚ªãƒ—ã‚·ãƒ§ãƒ³: finance_notes ã‚‚æƒé™¤
    if also_clean_notes:
        cur.executemany("DELETE FROM finance_notes WHERE ã‚³ãƒ¼ãƒ‰ = ?", targets)

    conn.commit()
    cur.close()

# ===== ä»»æ„ï¼šç©ºå£²ã‚Šç„¡ã—åæ˜  =====
def phase_mark_karauri_nashi(conn: sqlite3.Connection):
    if not os.path.isfile(KARA_URI_NASHI_PATH):
        print("ç©ºå£²ã‚Šç„¡ã—ãƒªã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã‚¹ã‚­ãƒƒãƒ—:", KARA_URI_NASHI_PATH)
        return
    df = pd.read_csv(KARA_URI_NASHI_PATH, encoding="utf8", sep=",", engine="python")
    rows = [(getattr(row, 'ã‚³ãƒ¼ãƒ‰'),) for row in df.itertuples()]
    try:
        exec_many(conn, 'UPDATE screener SET ç©ºå£²ã‚Šæ©Ÿé–¢="ãªã—" WHERE ã‚³ãƒ¼ãƒ‰=?', rows, chunk=500)
    except NameError:
        import sqlite3
        _tmp_conn = sqlite3.connect(DB_PATH)
        try:
            exec_many(_tmp_conn, 'UPDATE screener SET ç©ºå£²ã‚Šæ©Ÿé–¢="ãªã—" WHERE ã‚³ãƒ¼ãƒ‰=?', rows, chunk=500)
        finally:
            _tmp_conn.close()

    # æ´¾ç”ŸæŒ‡æ¨™æ›´æ–°ã‚’å®Ÿè¡Œ
    phase_shortterm_enhancements(conn)
# å¿…è¦: pip install yfinance pandas

def _latest2_ok(conn: sqlite3.Connection, code: str) -> bool:
    """
    price_historyã‹ã‚‰ç›´è¿‘2è¡Œã‚’å–ã‚Šã€å‰æ—¥çµ‚å€¤ãŒæœ‰åŠ¹ãªã‚‰Trueã€‚
    - è¡Œæ•°ãŒ2æœªæº€ â†’ False
    - å‰æ—¥çµ‚å€¤ãŒNaN/0 â†’ False
    """
    df = pd.read_sql_query(
        "SELECT æ—¥ä»˜, çµ‚å€¤ FROM price_history WHERE ã‚³ãƒ¼ãƒ‰=? ORDER BY æ—¥ä»˜ DESC LIMIT 2",
        conn, params=(str(code),)
    )
    if df.shape[0] < 2:
        return False
    prev_close = df.iloc[1]["çµ‚å€¤"]
    try:
        return (prev_close is not None) and (not pd.isna(prev_close)) and float(prev_close) != 0.0
    except Exception:
        return False

def list_insufficient_codes(conn: sqlite3.Connection, universe_codes=None) -> list[str]:
    """
    ç›´è¿‘2å–¶æ¥­æ—¥ã®çµ‚å€¤ãŒæƒã£ã¦ã„ãªã„ï¼ˆ=å‰æ—¥çµ‚å€¤æ¯”ç‡ãŒè¨ˆç®—ã§ããªã„ï¼‰éŠ˜æŸ„ã‚’åˆ—æŒ™ã€‚
    universe_codes ã‚’çœç•¥ã™ã‚‹ã¨ screener å…¨ä»¶ã‚’å¯¾è±¡ã«ã™ã‚‹ã€‚
    """
    if universe_codes is None:
        cur = conn.cursor()
        cur.execute("SELECT ã‚³ãƒ¼ãƒ‰ FROM screener")
        universe_codes = [str(r[0]) for r in cur.fetchall()]
        cur.close()

    bad = []
    for c in universe_codes:
        if not _latest2_ok(conn, c):
            bad.append(str(c))
    return bad

def refresh_full_history_for_insufficient(conn: sqlite3.Connection, universe_codes=None, batch_size: int = 200) -> list[str]:
    """
    ã€Œãƒ‡ãƒ¼ã‚¿ä¸è¶³ï¼ˆç›´è¿‘2æ—¥ãã‚ã‚ãšï¼‰ã€ãªéŠ˜æŸ„ã ã‘ã‚’æŠ½å‡ºã—ã€åˆå›ã ã‘ 12ãƒ¶æœˆ ã‚’å–ã‚Šç›´ã—ã¦ upsertã€‚
    å‡¦ç†å¾Œã« _update_screener_from_history ã§å‰æ—¥çµ‚å€¤æ¯”ç‡ãªã©ã‚’å†è¨ˆç®—ã™ã‚‹ã€‚
    æˆ»ã‚Šå€¤: å†å–å¾—ã‚’è¡Œã£ãŸéŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆ
    """
    # 1) å¯¾è±¡æŠ½å‡º
    targets = list_insufficient_codes(conn, universe_codes)
    if not targets:
        print("[full-refresh] ä¸è¶³éŠ˜æŸ„ãªã—")
        return []

    print(f"[full-refresh] 12mo å–ã‚Šç›´ã—å¯¾è±¡: {len(targets)} ä»¶")
    total_added = 0

    # 2) yfinance ã§ 12mo ã‚’å–å¾—ã—ã¦ price_history ã« upsert
    for i in range(0, len(targets), batch_size):
        chunk = targets[i:i+batch_size]
        tickers_map = {c: f"{c}.T" for c in chunk}   # æ—¥æœ¬æ ªæƒ³å®š
        try:
            df_wide = yf.download(
                list(tickers_map.values()),
                period="12mo", interval="1d",
                group_by="ticker", threads=True, auto_adjust=False
            )
        except Exception as e:
            print(f"[full-refresh][WARN] downloadå¤±æ•—: {e}  chunkå…ˆé ­={chunk[0] if chunk else ''}")
            continue

        df_add = _to_long_history(df_wide, tickers_map)  # æ—¢å­˜ã®æ•´å½¢é–¢æ•°ã‚’æµç”¨:contentReference[oaicite:1]{index=1}
        added = _upsert_price_history(conn, df_add)      # æ—¢å­˜ã®upsertã‚’æµç”¨:contentReference[oaicite:2]{index=2}
        total_added += added
        print(f"[full-refresh] {i+len(chunk)}/{len(targets)} (+{added} rows)")

    # 3) screener ã® ç¾åœ¨å€¤/å‰æ—¥çµ‚å€¤æ¯”ç‡/å‡ºæ¥é«˜ ã‚’å†è¨ˆç®—ã—ã¦åæ˜ 
    _update_screener_from_history(conn, targets)         # æ—¢å­˜ã®æ›´æ–°é–¢æ•°ã‚’æµç”¨:contentReference[oaicite:3]{index=3}

    print(f"[full-refresh] è¿½è¨˜ {total_added} è¡Œ / å†å–å¾— {len(targets)} éŠ˜æŸ„")
    return targets

def _codes_with_data(conn):
    q = "SELECT DISTINCT ã‚³ãƒ¼ãƒ‰ FROM price_history"
    return {row[0] for row in conn.execute(q).fetchall()}

def _to_long_history(df_wide: pd.DataFrame, codes_map) -> pd.DataFrame:
    """
    yf.download ã®æˆ»ã‚Š(MultiIndexåˆ—)ã‚’ãƒ­ãƒ³ã‚°å½¢å¼ã«ã™ã‚‹ã€‚
    codes_map: { '7203': '7203.T', ... } é€†å¼•ãã«ä½¿ã†ã€‚
    """
    if df_wide is None or df_wide.empty:
        return pd.DataFrame(columns=["æ—¥ä»˜","ã‚³ãƒ¼ãƒ‰","å§‹å€¤","é«˜å€¤","å®‰å€¤","çµ‚å€¤","å‡ºæ¥é«˜"])
    # å˜ä¸€éŠ˜æŸ„ã®ã¨ãã¯åˆ—ãŒMultiIndexã§ã¯ãªã„å ´åˆãŒã‚ã‚‹
    if isinstance(df_wide.columns, pd.MultiIndex):
        df = df_wide.stack(level=0).reset_index()  # Date, Ticker, [Open,High,Low,Close,Adj Close,Volume]
        df.rename(columns={"level_1":"Ticker","Date":"æ—¥ä»˜"}, inplace=True)
        df["ã‚³ãƒ¼ãƒ‰"] = df["Ticker"].map({v:k for k,v in codes_map.items()})
    else:
        # 1éŠ˜æŸ„ã®ã¿
        df = df_wide.reset_index().copy()
        df["Ticker"] = list(codes_map.values())[0]
        code = list(codes_map.keys())[0]
        df["ã‚³ãƒ¼ãƒ‰"] = code
        df.rename(columns={"Date":"æ—¥ä»˜"}, inplace=True)

    df = df.rename(columns={
        "Open":"å§‹å€¤","High":"é«˜å€¤","Low":"å®‰å€¤","Close":"çµ‚å€¤","Volume":"å‡ºæ¥é«˜"
    })
    # æ¬²ã—ã„åˆ—ã ã‘ã€æ¬ æè¡Œã¯è½ã¨ã™
    cols = ["æ—¥ä»˜","ã‚³ãƒ¼ãƒ‰","å§‹å€¤","é«˜å€¤","å®‰å€¤","çµ‚å€¤","å‡ºæ¥é«˜"]
    df = df[cols].dropna(subset=["æ—¥ä»˜","çµ‚å€¤"])

    # æ—¥ä»˜â†’date
    df["æ—¥ä»˜"] = pd.to_datetime(df["æ—¥ä»˜"]).dt.date
    # é‡è¤‡é™¤å»ï¼ˆåŒä¸€æ—¥ãƒ»åŒä¸€ã‚³ãƒ¼ãƒ‰ï¼‰
    df = df.drop_duplicates(subset=["ã‚³ãƒ¼ãƒ‰","æ—¥ä»˜"], keep="last")
    return df.sort_values(["ã‚³ãƒ¼ãƒ‰","æ—¥ä»˜"])

def _upsert_price_history(conn, df_add: pd.DataFrame) -> int:
    if df_add is None or df_add.empty:
        return 0
    cur = conn.cursor()
    cur.executemany(
        "DELETE FROM price_history WHERE ã‚³ãƒ¼ãƒ‰=? AND æ—¥ä»˜=?",
        [(r["ã‚³ãƒ¼ãƒ‰"], r["æ—¥ä»˜"]) for _, r in df_add.iterrows()]
    )
    conn.commit()
    df_add.to_sql("price_history", conn, if_exists="append", index=False)
    return len(df_add)

def _update_screener_from_history(conn, codes):
    """
    price_history ã®ç›´è¿‘2æ—¥ã‹ã‚‰
    ç¾åœ¨å€¤ / å‰æ—¥çµ‚å€¤ / å‰æ—¥å††å·® / å‰æ—¥çµ‚å€¤æ¯”ç‡(ï¼…) / å‡ºæ¥é«˜ ã‚’æ›´æ–°ã™ã‚‹ã€‚
    ã™ã¹ã¦å°æ•°2æ¡ï¼ˆï¼…å«ã‚€ï¼‰ã§DBä¿å­˜ã™ã‚‹ã€‚
    """
    def _r2(x):
        try:
            return None if x is None else round(float(x), 2)
        except Exception:
            return None

    updated = []
    for code in codes:
        df = pd.read_sql_query(
            "SELECT æ—¥ä»˜, çµ‚å€¤, å‡ºæ¥é«˜ FROM price_history WHERE ã‚³ãƒ¼ãƒ‰=? ORDER BY æ—¥ä»˜ DESC LIMIT 2",
            conn, params=(str(code),)
        )
        if df.empty:
            continue
        today = df.iloc[0]
        close_t = today["çµ‚å€¤"]
        vol_t   = today["å‡ºæ¥é«˜"]

        prev = df.iloc[1]["çµ‚å€¤"] if len(df) >= 2 else None
        yen = pct = None
        if prev is not None and pd.notna(prev) and float(prev) != 0.0:
            yen = float(close_t) - float(prev)
            pct = yen / float(prev) * 100.0

        updated.append((
            _r2(close_t),                        # ç¾åœ¨å€¤ â†’ 2æ¡
            _r2(prev),                           # å‰æ—¥çµ‚å€¤ â†’ 2æ¡
            _r2(yen),                            # å‰æ—¥å††å·® â†’ 2æ¡
            _r2(pct),                            # å‰æ—¥çµ‚å€¤æ¯”ç‡(ï¼…) â†’ 2æ¡
            int(vol_t) if pd.notna(vol_t) else None,  # å‡ºæ¥é«˜
            dtm.datetime.today().strftime("%Y-%m-%d"),
            str(code),
        ))

    if updated:
        cur = conn.cursor()
        cur.executemany("""
            UPDATE screener
               SET ç¾åœ¨å€¤=?,
                   å‰æ—¥çµ‚å€¤=?,
                   å‰æ—¥å††å·®=?,
                   å‰æ—¥çµ‚å€¤æ¯”ç‡=?,
                   å‡ºæ¥é«˜=?,
                   ã‚·ã‚°ãƒŠãƒ«æ›´æ–°æ—¥=?
             WHERE ã‚³ãƒ¼ãƒ‰=?
        """, updated)
        conn.commit()

def phase_yahoo_bulk_refresh(conn, codes, batch_size=200):
    """
    é«˜é€Ÿç‰ˆ:
      - æ—¢å­˜éŠ˜æŸ„: period="2d", interval="1d" ã‚’ãƒãƒ«ã‚¯ã§å–å¾—ã—ã€å·®åˆ†ã ã‘ upsert
      - æœªåéŒ²éŠ˜æŸ„: period="12mo" ã‚’ãƒãƒ«ã‚¯ã§å–å¾—ã—ã¦åˆæœŸæŠ•å…¥
      - screener ã¯ price_history ã®ç›´è¿‘2æ—¥ã‹ã‚‰ å‰æ—¥çµ‚å€¤æ¯”ç‡/å‡ºæ¥é«˜/ç¾åœ¨å€¤ ã‚’æ›´æ–°
      - æ™‚ä¾¡ç·é¡ã¯é€Ÿåº¦å„ªå…ˆã§æ›´æ–°ã—ãªã„ï¼ˆå¿…è¦ãªã‚‰åˆ¥ãƒ•ã‚§ãƒ¼ã‚ºã§ï¼‰
    """
    codes = [str(c) for c in codes]
    have = _codes_with_data(conn)
    exist_codes = [c for c in codes if c in have]
    new_codes   = [c for c in codes if c not in have]

    total_added = 0

    # 1) æ—¢å­˜éŠ˜æŸ„: 2æ—¥åˆ†ã ã‘ä¸€æ‹¬å–å¾—ï¼ˆãƒãƒƒãƒåˆ†å‰²ï¼‰
    for i in range(0, len(exist_codes), batch_size):
        chunk = exist_codes[i:i+batch_size]
        tickers_map = {c: f"{c}.T" for c in chunk}  # æ—¥æœ¬æ ªå‰æ
        df_wide = yf.download(list(tickers_map.values()), period="2d", interval="1d", group_by="ticker", threads=True, auto_adjust=False)
        df_add = _to_long_history(df_wide, tickers_map)
        total_added += _upsert_price_history(conn, df_add)
        print(f"[refresh/exist] {i+len(chunk)}/{len(exist_codes)} (+{len(df_add)} rows)")

    # 2) æ–°è¦éŠ˜æŸ„: 12ãƒ¶æœˆã¶ã‚“ã‚’ä¸€æ‹¬å–å¾—ï¼ˆãƒãƒƒãƒåˆ†å‰²ï¼‰
    for i in range(0, len(new_codes), batch_size):
        chunk = new_codes[i:i+batch_size]
        tickers_map = {c: f"{c}.T" for c in chunk}
        df_wide = yf.download(list(tickers_map.values()), period="12mo", interval="1d", group_by="ticker", threads=True, auto_adjust=False)
        df_add = _to_long_history(df_wide, tickers_map)
        total_added += _upsert_price_history(conn, df_add)
        print(f"[refresh/new ] {i+len(chunk)}/{len(new_codes)} (+{len(df_add)} rows)")

    # 3) screener æ›´æ–°ï¼ˆprice_history ç”±æ¥ï¼‰
    _update_screener_from_history(conn, codes)
    apply_auto_metrics_eod(conn)
    apply_composite_score(conn)
    print(f"[refresh] è¿½è¨˜ {total_added} è¡Œ / éŠ˜æŸ„ {len(codes)} ä»¶ï¼ˆæ—¢å­˜{len(exist_codes)}ãƒ»æ–°è¦{len(new_codes)}ï¼‰")

# ==== æ™‚ä¾¡ç·é¡å–å¾—

# ===== å…¨éŠ˜æŸ„ã®æ™‚ä¾¡ç·é¡ã‚’ä¸€æ‹¬æ›´æ–° =====

def _to_symbol(c: str) -> str:
    s = str(c).strip()
    return s if "." in s else s + ".T"   # 4æ¡æ•°å­—ã‚³ãƒ¼ãƒ‰æƒ³å®šï¼š.T ä»˜ä¸

def _normalize_map(obj):
    """
    yahooquery.YQ(...).summary_detail / price ã®æˆ»ã‚Šã‚’
    {symbol: { ... }} å½¢å¼ã® dict ã«æ­£è¦åŒ–ã€‚æ–‡å­—åˆ—ã¯ã‚¹ã‚­ãƒƒãƒ—ã€‚
    """
    if isinstance(obj, dict):
        # ã¾ã‚Œã« '7203.T': 'Not Found' ã¿ãŸã„ãªæ–‡å­—åˆ—ãŒå…¥ã‚‹ã®ã§å¼¾ã
        return {k: v for k, v in obj.items() if not isinstance(v, str)}
    if isinstance(obj, pd.DataFrame):
        if 'symbol' in obj.columns:
            d = obj.set_index('symbol').to_dict(orient='index')
            # å€¤ãŒæ–‡å­—åˆ—ã®è¡Œã¯å¼¾ã
            return {k: v for k, v in d.items() if not isinstance(v, str)}
        try:
            d = obj.to_dict(orient='index')
            return {k: v for k, v in d.items() if not isinstance(v, str)}
        except Exception:
            return {}
    return {}

def _extract_mcap(entry):
    """
    entry ã‹ã‚‰ marketCap ã‚’ float ã«å–ã‚Šå‡ºã™ã€‚
    entry ãŒ dict/Series/list/str ãªã©ä½•ãŒæ¥ã¦ã‚‚å®‰å…¨ã« None è¿”ã—ã€‚
    """
    # dict ä»¥å¤–ã‚’å¯èƒ½ãªé™ã‚Š dict åŒ–ï¼ˆSeries, list[dict] ç­‰ï¼‰
    if isinstance(entry, pd.Series):
        entry = entry.to_dict()
    elif isinstance(entry, (list, tuple)):
        entry = entry[0] if entry and isinstance(entry[0], dict) else {}
    elif isinstance(entry, str) or entry is None:
        return None
    elif not isinstance(entry, dict):
        entry = {}

    v = entry.get('marketCap')
    if v is None:
        return None
    if isinstance(v, dict):           # {'raw': 123..., 'fmt': '...'} å½¢å¼
        v = v.get('raw') or v.get('fmt') or v.get('longFmt')
    try:
        return float(str(v).replace(',', ''))
    except Exception:
        return None

def update_market_cap_all(conn, batch_size=300, max_workers=8):
    """
    å…¨éŠ˜æŸ„ã®æ™‚ä¾¡ç·é¡ï¼ˆå„„å††ï¼‰ã‚’é«˜é€Ÿã«æ›´æ–°ã€‚
    - yahooqueryã§ã¾ã¨ã‚å–ã‚Šï¼ˆéåŒæœŸï¼‰
    - .T ã®æ—¥æœ¬æ ªã¯ JPYæƒ³å®š â†’ å„„å††ã«å¤‰æ› (mcap/1e8)
    """
    codes = [str(r[0]) for r in conn.execute("SELECT ã‚³ãƒ¼ãƒ‰ FROM screener").fetchall()]
    if not codes:
        print("[mcap] å¯¾è±¡ãªã—")
        return

    updated_total = 0
    try:
        for i in range(0, len(codes), batch_size):
            chunk = codes[i:i+batch_size]
            symbols = [_to_symbol(c) for c in chunk]

            tq = YQ(symbols, asynchronous=True, max_workers=max_workers)
            sd = _normalize_map(tq.summary_detail)
            pr = _normalize_map(tq.price)

            rows = []
            for sym in symbols:
                entry_sd = sd.get(sym)
                mcap = _extract_mcap(entry_sd)
                if mcap is None:
                    entry_pr = pr.get(sym)
                    mcap = _extract_mcap(entry_pr)
                if mcap is None:
                    continue
                mcap_oku = mcap / 1e8  # å††å»ºã¦æƒ³å®šï¼ˆ.Tï¼‰
                code = sym.split('.', 1)[0]
                rows.append((None if mcap_oku is None else round(mcap_oku, 2), code))
                
            if rows:
                cur = conn.cursor()
                cur.executemany("UPDATE screener SET æ™‚ä¾¡ç·é¡å„„å††=? WHERE ã‚³ãƒ¼ãƒ‰=?", rows)
                conn.commit(); cur.close()
                updated_total += len(rows)
            print(f"[mcap/all] {i+len(chunk)}/{len(codes)} æ›´æ–° {len(rows)} ä»¶")

        print(f"[mcap] åˆè¨ˆæ›´æ–° {updated_total} ä»¶ï¼ˆå…¨éŠ˜æŸ„ï¼‰")

    except ImportError:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆé…ã„ï¼‰ï¼šå¿…è¦æ™‚ã®ã¿
        print("[mcap] yahooqueryæœªå°å…¥ â†’ yfinance fast_info ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆé…ã„ï¼‰")
        rows = []
        for c in codes:
            try:
                fi = yf.YQ(_to_symbol(c)).fast_info
                mc = getattr(fi, "market_cap", None)
                if mc:
                    rows.append((float(mc)/1e8, c))
            except Exception:
                pass
        if rows:
            cur = conn.cursor()
            cur.executemany("UPDATE screener SET æ™‚ä¾¡ç·é¡å„„å††=? WHERE ã‚³ãƒ¼ãƒ‰=?", rows)
            conn.commit(); cur.close()
        print(f"[mcap/yf] æ›´æ–° {len(rows)} ä»¶ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰")

# ===== Yahooï¼ˆMIDDAY ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆï¼‰ =====

def r2(x):
    """å°æ•°ç‚¹2æ¡ã«ä¸¸ã‚ï¼ˆNoneå®‰å…¨ï¼‰"""
    try:
        return None if x is None else round(float(x), 2)
    except Exception:
        return None

def phase_yahoo_intraday_snapshot(conn: sqlite3.Connection):
    cur = conn.cursor()
    if MIDDAY_FILTER_BY_FLAGS:
        cur.execute("""
            SELECT ã‚³ãƒ¼ãƒ‰ FROM screener
               OR (æ™‚ä¾¡ç·é¡å„„å†† BETWEEN 50 AND 5000)
        """)
    else:
        cur.execute("SELECT ã‚³ãƒ¼ãƒ‰ FROM screener")
    codes = [str(r[0]) for r in cur.fetchall()]
    cur.close()

    if not codes:
        print("å¯¾è±¡ã‚³ãƒ¼ãƒ‰ãªã—ï¼šintradayã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚¹ã‚­ãƒƒãƒ—")
        return
    if TEST_MODE:
        codes = codes[:TEST_LIMIT]
        print(f"[TEST] {len(codes)}éŠ˜æŸ„(MIDDAY)ã«çµã£ã¦å®Ÿè¡Œ")

    symbols_all = [f"{c}.T" for c in codes]
    print(f"[MIDDAY] quoteså–å¾—: {len(symbols_all)}éŠ˜æŸ„")
    today = today_str()

    up_screener, up_hist = [], []
    batch = YQ_BATCH_MID
    for i in range(0, len(symbols_all), batch):
        symbols = symbols_all[i:i+batch]
        t = YQ(symbols, max_workers=YQ_MAX_WORKERS)
        quotes = t.quotes if isinstance(t.quotes, dict) else {}

        for sym in symbols:
            q = quotes.get(sym) or {}
            code = sym.replace(".T", "")

            last = ffloat(q.get("regularMarketPrice"), None)
            prev_api = ffloat(q.get("regularMarketPreviousClose"), None)

            # DBå„ªå…ˆã€ç„¡ã‘ã‚Œã°APIãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            prev = get_prev_close_db_first(conn, code, quotes_prev=prev_api)

            yen = pct = None
            if last is not None and prev is not None and prev != 0:
                yen = last - prev
                pct = yen / prev * 100.0

            vol  = fint(q.get("regularMarketVolume"), 0)
            mcap = ffloat(q.get("marketCap"), 0.0)
            zika_oku = None if not mcap else round(mcap / 100_000_000.0, 2)

            # â† tupleã®é †åºã‚’å¤‰æ›´ï¼šå‰æ—¥çµ‚å€¤ãƒ»å‰æ—¥å††å·®ãƒ»å‰æ—¥çµ‚å€¤æ¯”ç‡ã‚’å…¨éƒ¨å…¥ã‚Œã‚‹
            # ã“ã‚Œã«ç½®æ›
            up_screener.append((
                None if last is None else round(float(last), 2),   # ç¾åœ¨å€¤ 2æ¡
                None if prev is None else round(float(prev), 2),   # å‰æ—¥çµ‚å€¤ 2æ¡
                None if yen  is None else round(float(yen),  2),   # å‰æ—¥å††å·® 2æ¡
                None if pct  is None else round(float(pct),  2),   # å‰æ—¥çµ‚å€¤æ¯”ç‡(ï¼…) 2æ¡
                int(vol or 0),                                     # å‡ºæ¥é«˜
                zika_oku,                                          # æ™‚ä¾¡ç·é¡å„„å††ï¼ˆå…ƒå®Ÿè£…ã®ã¾ã¾ï¼‰
                today,
                code
            ))

            o1 = ffloat(q.get("regularMarketOpen"), None)
            h1 = ffloat(q.get("regularMarketDayHigh"), None)
            l1 = ffloat(q.get("regularMarketDayLow"), None)
            c1 = last
            # ã“ã‚Œã«ç½®æ›
            up_hist.append((
                code, today,
                None if o1 is None else round(float(o1), 2),
                None if h1 is None else round(float(h1), 2),
                None if l1 is None else round(float(l1), 2),
                None if c1 is None else round(float(c1), 2),
                int(vol or 0)
            ))

        time.sleep(YQ_SLEEP_MID)

    if up_screener:
        cur = conn.cursor()
        cur.executemany(
            "UPDATE screener SET "
            "ç¾åœ¨å€¤=ROUND(?,2), å‰æ—¥çµ‚å€¤=ROUND(?,2), å‰æ—¥å††å·®=ROUND(?,2), å‰æ—¥çµ‚å€¤æ¯”ç‡=ROUND(?,2), "
            "å‡ºæ¥é«˜=?, æ™‚ä¾¡ç·é¡å„„å††=?, æ›´æ–°æ—¥=? WHERE ã‚³ãƒ¼ãƒ‰=?",
            up_screener
        )

        conn.commit()
        cur.close()

    if up_hist:
        cur = conn.cursor()
        cur.executemany("""
            INSERT INTO price_history(ã‚³ãƒ¼ãƒ‰,æ—¥ä»˜,å§‹å€¤,é«˜å€¤,å®‰å€¤,çµ‚å€¤,å‡ºæ¥é«˜)
            VALUES(?,?,?,?,?,?,?)
            ON CONFLICT(ã‚³ãƒ¼ãƒ‰,æ—¥ä»˜) DO UPDATE SET
              å§‹å€¤=COALESCE(excluded.å§‹å€¤, å§‹å€¤),
              é«˜å€¤=COALESCE(excluded.é«˜å€¤, é«˜å€¤),
              å®‰å€¤=COALESCE(excluded.å®‰å€¤, å®‰å€¤),
              çµ‚å€¤=COALESCE(excluded.çµ‚å€¤, çµ‚å€¤),
              å‡ºæ¥é«˜=COALESCE(excluded.å‡ºæ¥é«˜, å‡ºæ¥é«˜)
        """, up_hist)
        conn.commit()
        apply_auto_metrics_midday(conn, use_time_progress=True)
        apply_composite_score(conn)
        cur.close()

# ===== æ´¾ç”ŸæŒ‡æ¨™ã®æ›´æ–° =====

def phase_snapshot_shodou_baseline(conn):
    """
    åˆå‹•ãƒ•ãƒ©ã‚°='å€™è£œ' ã§ã€ã¾ã åŸºæº–ãŒæœªè¨­å®š(åˆå‹•æ ªä¾¡/åˆå‹•å‡ºæ¥é«˜ ãŒ NULL)ã®éŠ˜æŸ„ã«å¯¾ã—ã¦ã€
    ãã®æ™‚ç‚¹ã® ç¾åœ¨å€¤/å‡ºæ¥é«˜ ã‚’ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã—ã¦åŸºæº–åŒ–ã™ã‚‹ã€‚
    ãƒ»CSVã¯ä¸€åˆ‡å‚ç…§ã—ãªã„
    ãƒ»å€ç‡ã¯ 1.0 ã§åˆæœŸåŒ–
    """
    cur = conn.cursor()
    # å€™è£œ ã‹ã¤ åŸºæº–ãŒæœªè¨­å®šã®ã‚‚ã®ã‚’æŠ½å‡º
    cur.execute("""
        SELECT ã‚³ãƒ¼ãƒ‰, ç¾åœ¨å€¤, å‡ºæ¥é«˜
        FROM screener
        WHERE åˆå‹•ãƒ•ãƒ©ã‚°='å€™è£œ'
          AND (åˆå‹•æ ªä¾¡ IS NULL OR åˆå‹•å‡ºæ¥é«˜ IS NULL)
          AND ç¾åœ¨å€¤ IS NOT NULL
    """)
    rows = cur.fetchall()

    updates = []
    for code, now_price, now_vol in rows:
        try:
            ip = float(now_price)
            iv = int(now_vol) if now_vol is not None else None
        except Exception:
            continue
        if ip is None:
            continue
        # å‡ºæ¥é«˜ãŒå–ã‚Œãªã„æ™‚ã¯ 0 æ‰±ã„ã§OKï¼ˆå€ç‡è¨ˆç®—æ™‚ã¯0é™¤ç®—ã‚’é¿ã‘ã‚‹ï¼‰
        iv = iv or 0
        updates.append((ip, 1.0, iv, 1.0, code))

    if updates:
        cur.executemany("""
            UPDATE screener
               SET åˆå‹•æ ªä¾¡=?,
                   åˆå‹•æ ªä¾¡å€ç‡=?,
                   åˆå‹•å‡ºæ¥é«˜=?,
                   åˆå‹•å‡ºæ¥é«˜å€ç‡=?
             WHERE ã‚³ãƒ¼ãƒ‰=?
        """, updates)
        conn.commit()
        print(f"[shodou-baseline] snapshotted {len(updates)} symbols")
    else:
        print("[shodou-baseline] no new baseline")
    cur.close()

def phase_update_shodou_multipliers(conn):
    """
    æ—¢ã«åŸºæº–(åˆå‹•æ ªä¾¡/åˆå‹•å‡ºæ¥é«˜)ãŒã‚ã‚‹éŠ˜æŸ„ã®å€ç‡ã‚’ã€æœ€æ–°ã® ç¾åœ¨å€¤/å‡ºæ¥é«˜ ã‹ã‚‰å†è¨ˆç®—ã—ã¦åæ˜ ã€‚
    """
    cur = conn.cursor()
    cur.execute("""
        SELECT ã‚³ãƒ¼ãƒ‰, ç¾åœ¨å€¤, å‡ºæ¥é«˜, åˆå‹•æ ªä¾¡, åˆå‹•å‡ºæ¥é«˜
        FROM screener
        WHERE åˆå‹•æ ªä¾¡ IS NOT NULL OR åˆå‹•å‡ºæ¥é«˜ IS NOT NULL
    """)
    rows = cur.fetchall()

    updates = []
    for code, now_price, now_vol, base_price, base_vol in rows:
        try:
            cp = float(now_price) if now_price is not None else None
            bp = float(base_price) if base_price is not None else None
            cv = int(now_vol) if now_vol is not None else None
            bv = int(base_vol) if base_vol is not None else None
        except Exception:
            continue

        # ä¾¡æ ¼å€ç‡
        mul_price = None
        if cp is not None and bp not in (None, 0):
            mul_price = cp / bp

        # å‡ºæ¥é«˜å€ç‡
        mul_vol = None
        if cv is not None and bv not in (None, 0):
            mul_vol = cv / bv

        if mul_price is not None or mul_vol is not None:
            updates.append((
                (mul_price if mul_price is not None else None),
                (mul_vol if mul_vol is not None else None),
                code
            ))

    if updates:
        cur.executemany("""
            UPDATE screener
               SET åˆå‹•æ ªä¾¡å€ç‡ = COALESCE(?, åˆå‹•æ ªä¾¡å€ç‡),
                   åˆå‹•å‡ºæ¥é«˜å€ç‡ = COALESCE(?, åˆå‹•å‡ºæ¥é«˜å€ç‡)
             WHERE ã‚³ãƒ¼ãƒ‰=?
        """, updates)
        conn.commit()
        print(f"[shodou-mults] updated {len(updates)} symbols")
    else:
        print("[shodou-mults] no updates")
    cur.close()

def phase_derive_update(conn: sqlite3.Connection):
    cur = conn.cursor()
    cur.execute("SELECT ã‚³ãƒ¼ãƒ‰, åˆå‹•æ ªä¾¡, ç¾åœ¨å€¤, UPç¶™ç¶šå›æ•°, DOWNç¶™ç¶šå›æ•°, ç™»éŒ²æ—¥, UPDOWN, å‡ºæ¥é«˜, æ™‚ä¾¡ç·é¡å„„å†† FROM screener")
    rows = cur.fetchall()
    d_today = today_str()
    cal_today = dtm.date.today()
    holidays = []

    for (code, initial_price, current_price, up_con, down_con, regist_date, db_updown, db_volume, zika_oku) in rows:
        up_con = int(up_con or 0)
        down_con = int(down_con or 0)

        cur2 = conn.cursor()
        cur2.execute("SELECT å‰æ—¥çµ‚å€¤æ¯”ç‡ FROM screener WHERE ã‚³ãƒ¼ãƒ‰=?", (code,))
        r = cur2.fetchone()
        cur2.close()
        db_zenhi = float(r[0]) if r and r[0] is not None else 0.0

        try:
            db_reg = date.fromisoformat(str(regist_date))
        except Exception:
            db_reg = cal_today
        last_date = workdays.workday(db_reg, 10, holidays)
        diff_days = max(0, (last_date - db_reg).days)
        eigyo_sabun = workdays.networkdays(db_reg, cal_today, holidays)

        updown = "åŒå€¤"
        if db_zenhi > 0:
            up_con += 1; down_con = 0
            if db_updown and db_updown.startswith("â†‘") and db_updown[1:].isdigit():
                updown = f"â†‘{int(db_updown[1:]) + 1}"
            elif db_updown == "â†‘":
                updown = "â†‘2"
            else:
                updown = "â†‘"
        elif db_zenhi < 0:
            down_con += 1; up_con = 0
            if db_updown and db_updown.startswith("â†“") and db_updown[1:].isdigit():
                updown = f"â†“{int(db_updown[1:]) + 1}"
            elif db_updown == "â†“":
                updown = "â†“2"
            else:
                updown = "â†“"

        try:
            z = float(zika_oku or 0)
        except Exception:
            z = 0.0
        if z >= 100:
            maru = f"çµ„å…¥æ¸ˆ?:{int(z)}"
        elif 90 < z < 100:
            maru = f"çµ„å…¥æœŸå¾…:{int(z)}"
        else:
            maru = f"çµ„å…¥å‰?:{int(z)}"

        cur2 = conn.cursor()
        cur2.execute(
            "UPDATE screener SET æ©Ÿé–¢çµ„å…¥æ™‚ä¾¡ç·é¡=?, æ®‹æ—¥=?, çµŒéæ—¥æ•°=?, UPDOWN=?, UPç¶™ç¶šå›æ•°=?, DOWNç¶™ç¶šå›æ•°=?, æ›´æ–°æ—¥=? WHERE ã‚³ãƒ¼ãƒ‰=?",
            (maru, diff_days, eigyo_sabun, updown, up_con, down_con, d_today, code),
        )
        conn.commit()
        cur2.close()

        try:
            ip = float(initial_price) if initial_price is not None else None
            cp = float(current_price) if current_price is not None else None
            if ip is not None and cp is not None and eigyo_sabun is not None:
                if cp < ip and eigyo_sabun > 14:
                    cur2 = conn.cursor()
                    cur2.execute(
                        'UPDATE screener SET åˆå‹•æ¤œçŸ¥æˆåŠŸ=?, åˆå‹•æ ªä¾¡=NULL, åˆå‹•æ ªä¾¡å€ç‡=NULL, åˆå‹•å‡ºæ¥é«˜=NULL, åˆå‹•å‡ºæ¥é«˜å€ç‡=NULL, UPç¶™ç¶šå›æ•°=0 WHERE ã‚³ãƒ¼ãƒ‰=?',
                        ("å¤±æ•—ã¾ãŸã¯æœªæ¤œçŸ¥", code),
                    )
                    conn.commit()
                    cur2.close()
        except Exception:
            pass
    cur.close()

# ===== ã‚·ã‚°ãƒŠãƒ«åˆ¤å®šï¼ˆåˆå‹•/åº•æ‰“ã¡/ä¸Šæ˜‡ä½™åœ°/Migikataï¼‰ =====

def _pivot_ratio_higher_lows(high: pd.Series, low: pd.Series, win=5):
    """5æ—¥çª“ãªã©ã§è°·(å®‰å€¤)ã®ãƒ”ãƒœãƒƒãƒˆã‚’å–ã‚Šã€é€£ç¶šã—ã¦åˆ‡ã‚Šä¸Šã’ã¦ã„ã‚‹æ¯”ç‡ã‚’è¿”ã™"""
    n = len(low)
    if n < win*2+1: return 0.0
    is_trough = []
    for i in range(win, n-win):
        if low.iloc[i] == low.iloc[i-win:i+win+1].min():
            is_trough.append(i)
    if len(is_trough) < 2: return 0.0
    cnt = 0
    for a,b in zip(is_trough, is_trough[1:]):
        if low.iloc[b] > low.iloc[a]: cnt += 1
    return cnt / max(1, (len(is_trough)-1))

def _trend_metrics_df(g: pd.DataFrame):
    """å¿…è¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ã¾ã¨ã‚ã¦è¨ˆç®—"""
    px = g["çµ‚å€¤"].astype(float).copy()
    hi = (g["é«˜å€¤"] if "é«˜å€¤" in g else g["çµ‚å€¤"]).astype(float)
    lo = (g["å®‰å€¤"] if "å®‰å€¤" in g else g["çµ‚å€¤"]).astype(float)

    # 1) å›å¸°ï¼ˆlogçµ‚å€¤ ~ æ—¥æ•°ï¼‰
    y = np.log(px.values)
    x = np.arange(len(px), dtype=float)
    b1, b0 = np.polyfit(x, y, 1)
    y_hat = b0 + b1*x
    ss_res = np.sum((y - y_hat)**2)
    ss_tot = np.sum((y - np.mean(y))**2)
    r2 = 1 - (ss_res/ss_tot) if ss_tot > 0 else 0.0
    slope_ann = np.exp(b1*252) - 1.0  # å¹´ç‡æ›ç®—

    # 2) MAs
    s20  = px.rolling(20,  min_periods=20).mean()
    s50  = px.rolling(50,  min_periods=50).mean()
    s100 = px.rolling(100, min_periods=100).mean()

    # ç›´è¿‘RIBBON_KEEP_DAYSã§ 20>50>100 ã‚’ç¶­æŒã—ãŸæ—¥ã®æ¯”ç‡
    ribbon_days = min(RIBBON_KEEP_DAYS, len(px))
    rib_ok = 0
    for i in range(len(px)-ribbon_days, len(px)):
        if i >= 100 and s20.iloc[i] > s50.iloc[i] > s100.iloc[i]:
            rib_ok += 1
    ribbon_ratio = rib_ok / max(1, ribbon_days)

    # SMA50ã®ä¸Šã«ã„ãŸæ—¥æ¯”ç‡ï¼ˆçª“å†…å…¨ä½“ï¼‰
    above50_ratio = float((px > s50).sum()) / max(1, (~s50.isna()).sum())

    # 3) é€±æ¬¡ã®ä¸Šæ˜‡ç¶™ç¶šï¼ˆâ€œä¸Šæ˜‡é€±â€ã®å‰²åˆï¼‰
    w = g.set_index("æ—¥ä»˜")["çµ‚å€¤"].resample("W-FRI").last().dropna()
    wk_ratio = float((w.diff() > 0).sum()) / max(1, (w.diff().dropna().shape[0]))

    # 4) æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³
    cummax = px.cummax()
    mdd = float((px/cummax - 1.0).min()) * -1.0  # æ­£ã®å€¤

    # 5) å®‰å€¤ã®åˆ‡ã‚Šä¸Šã’æ¯”ç‡ï¼ˆãƒ”ãƒœãƒƒãƒˆï¼‰
    hl_ratio = _pivot_ratio_higher_lows(hi, lo, win=HL_WIN)

    return dict(
        slope_ann=float(slope_ann), r2=float(max(0,min(1,r2))),
        ribbon_ratio=float(ribbon_ratio), above50_ratio=float(above50_ratio),
        week_up_ratio=float(wk_ratio), mdd=float(mdd), hl_ratio=float(hl_ratio)
    )

def compute_right_up_persistent(conn, as_of=None):
    """ã€ãšãƒ¼ãƒ¼ã£ã¨å³è‚©ä¸ŠãŒã‚Šã€ã‚’ã‚¹ã‚³ã‚¢åŒ–ã—ã¦ screener ã‚’æ›´æ–°"""
    # å¯¾è±¡æ—¥
    dmax = pd.read_sql_query("SELECT MAX(æ—¥ä»˜) d FROM price_history", conn, parse_dates=["d"])
    if dmax.empty or pd.isna(dmax.loc[0,"d"]): 
        print("[å³è‚©ä¸ŠãŒã‚Š] price_historyç©º"); return
    today = pd.to_datetime(as_of) if as_of is not None else dmax.loc[0,"d"]

    start = (today - pd.Timedelta(days=int(LOOKBACK*1.6))).strftime("%Y-%m-%d")
    ph = pd.read_sql_query(
        f"SELECT æ—¥ä»˜, ã‚³ãƒ¼ãƒ‰, çµ‚å€¤, é«˜å€¤, å®‰å€¤ FROM price_history WHERE æ—¥ä»˜>=date('{start}') ORDER BY ã‚³ãƒ¼ãƒ‰, æ—¥ä»˜",
        conn, parse_dates=["æ—¥ä»˜"]
    )
    ph = add_price_features(ph)  # v10: unify price feature calc
    if ph.empty: 
        print("[å³è‚©ä¸ŠãŒã‚Š] ãƒ‡ãƒ¼ã‚¿ç„¡ã—"); return

    outs = []
    for code, g0 in ph.groupby("ã‚³ãƒ¼ãƒ‰", sort=False):
        g = g0[g0["æ—¥ä»˜"]<=today].tail(LOOKBACK).copy()
        if len(g) < MIN_DAYS: 
            continue
        met = _trend_metrics_df(g)

        # ---- ã‚¹ã‚³ã‚¢ï¼ˆ0-100ï¼‰ ----
        # å›å¸°å‚¾ãï¼ˆ0â†’40ç‚¹ï¼‰ï¼š12%/å¹´ã§0ç‚¹ã€50%/å¹´ã§æº€ç‚¹
        slope = met["slope_ann"]
        slope_score = 0.0 if slope <= SLOPE_MIN_ANN else min(1.0, (slope - SLOPE_MIN_ANN)/0.38)*40.0

        # R^2ï¼ˆ0â†’15ç‚¹ï¼‰
        r2_score = met["r2"]*15.0

        # ãƒªãƒœãƒ³ç¶­æŒï¼ˆ0â†’20ç‚¹ï¼‰: ç›´è¿‘ã§ã©ã‚Œã ã‘20>50>100ã‚’ç¶­æŒ
        ribbon_score = min(1.0, met["ribbon_ratio"]/0.8)*20.0  # 80%ç¶­æŒã§æº€ç‚¹

        # é€±è¶³ã®ä¸Šæ˜‡æ¯”ç‡ï¼ˆ0â†’10ç‚¹ï¼‰
        week_score = 0.0 if met["week_up_ratio"] <= WEEK_UP_MIN else min(1.0,(met["week_up_ratio"]-WEEK_UP_MIN)/(0.9-WEEK_UP_MIN))*10.0

        # SMA50ä¸Šå›ã‚Šæ¯”ç‡ï¼ˆ0â†’10ç‚¹ï¼‰
        above50_score = min(1.0, max(0.0, (met["above50_ratio"]-0.6)/(0.9-0.6)))*10.0

        # å®‰å€¤ã®åˆ‡ã‚Šä¸Šã’ï¼ˆ0â†’10ç‚¹ï¼‰
        hl_score = min(1.0, met["hl_ratio"]/0.7)*10.0  # 70%ãŒHLãªã‚‰æº€ç‚¹

        # DDãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆï½-15ç‚¹ï¼‰
        dd_pen = 0.0
        if met["mdd"] > MDD_MAX:
            dd_pen = min(1.0, (met["mdd"]-MDD_MAX)/0.2)*15.0  # 30%è¶…â†’æ¸›ç‚¹ã€50%ã§æœ€å¤§

        score = max(0.0, slope_score + r2_score + ribbon_score + week_score + above50_score + hl_score - dd_pen)

        # æœ€ä½é™ã®åŸºç¤æ¡ä»¶
        base_ok = (slope > 0) and (met["r2"] >= R2_MIN)
        flag = "å€™è£œ" if (base_ok and score >= THRESH_SCORE) else ""

        outs.append((round(score,1), flag, str(code)))

    if not outs:
        print("[å³è‚©ä¸ŠãŒã‚Š] è©²å½“ãªã—"); return

    cur = conn.cursor()
    cur.execute("UPDATE screener SET å³è‚©ä¸ŠãŒã‚Šãƒ•ãƒ©ã‚°='', å³è‚©ä¸ŠãŒã‚Šã‚¹ã‚³ã‚¢=NULL")
    cur.executemany("""
        UPDATE screener SET å³è‚©ä¸ŠãŒã‚Šã‚¹ã‚³ã‚¢=?, å³è‚©ä¸ŠãŒã‚Šãƒ•ãƒ©ã‚°=? WHERE ã‚³ãƒ¼ãƒ‰=?
    """, outs)
    conn.commit(); cur.close()
    print(f"[å³è‚©ä¸ŠãŒã‚Š] æŒç¶šãƒˆãƒ¬ãƒ³ãƒ‰ç‰ˆ {len(outs)} éŠ˜æŸ„ã‚’æ›´æ–° / é–¾å€¤={THRESH_SCORE}")

# ========================= å³è‚©ä¸ŠãŒã‚Šãƒ»æ—©æœŸãƒˆãƒªã‚¬ãƒ¼ï¼ˆå®Œå…¨ç‰ˆï¼šç½®æ›ç”¨ï¼‰ =========================

# ---- ã—ãã„å€¤ï¼ˆå¥½ã¿ã«å¿œã˜ã¦èª¿æ•´ã—ã¦ãã ã•ã„ï¼‰----
HH_N = 60                   # ãƒ–ãƒ¬ã‚¤ã‚¯åˆ¤å®šã®éå»é«˜å€¤æœŸé–“
POCKET_WIN = 10             # ãƒã‚±ãƒƒãƒˆãƒ”ãƒœãƒƒãƒˆã®å‚ç…§æ—¥æ•°
REB_WIN = 10                # 20MAå‰²ã‚Œâ†’å¥ªå›ã‚’æ¢ã™ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
RECLAIM_WIN = 10            # 200MAä¸ŠæŠœã‘ã®æ¢ç´¢ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
SCORE_TH = 70               # æ—©æœŸãƒ•ãƒ©ã‚°ã®ã‚¹ã‚³ã‚¢é–¾å€¤ï¼ˆã“ã‚Œä»¥ä¸Šã§å€™è£œï¼‰
PIVOT_EPS = 0.002           # ãƒ–ãƒ¬ã‚¤ã‚¯ä½™ç™½(+0.2%)
VOL_BOOST = 1.5             # ãƒ–ãƒ¬ã‚¤ã‚¯æ™‚ã®å‡ºæ¥é«˜ãƒ–ãƒ¼ã‚¹ãƒˆ(Ã—20æ—¥å¹³å‡)
EXT_20_MAX = 0.05           # 20MAã‹ã‚‰ã®ä¹–é›¢ä¸Šé™(=+5%)
EXT_50_MAX = 0.10           # 50MAã‹ã‚‰ã®ä¹–é›¢ä¸Šé™(=+10%)

# ---- ã‚¹ã‚­ãƒ¼ãƒç¢ºä¿ï¼ˆscreener ã®åˆ—/ signals_log ã®æœ€å°åˆ—ï¼‰----
def _ma(s, n):  return s.rolling(n, min_periods=n).mean()
def _avg_vol(v, n=20): return v.rolling(n, min_periods=n).mean()

def _atr(df, n=20):
    c = df["çµ‚å€¤"].astype(float)
    h = (df["é«˜å€¤"] if "é«˜å€¤" in df else df["çµ‚å€¤"]).astype(float)
    l = (df["å®‰å€¤"] if "å®‰å€¤" in df else df["çµ‚å€¤"]).astype(float)
    pc = c.shift(1)
    tr = pd.concat([(h-l).abs(), (h-pc).abs(), (l-pc).abs()], axis=1).max(axis=1)
    return tr.rolling(n, min_periods=n).mean()

# ---- 1éŠ˜æŸ„ã®â€œä»Šæ—¥â€ã®ãƒ™ã‚¹ãƒˆã‚·ã‚°ãƒŠãƒ«ã‚’è¿”ã™ ----
def _best_signal_today(g: pd.DataFrame):
    """
    g: 1éŠ˜æŸ„åˆ†ã® DataFrameï¼ˆæ˜‡é †ï¼‰ã€‚çµ‚å€¤/é«˜å€¤/å®‰å€¤/å‡ºæ¥é«˜ å¿…é ˆã€‚
    æˆ»ã‚Š: (score:float, tag:str, details:str) or (0,'','')
    """
    g = g.sort_values("æ—¥ä»˜").copy()
    px = g["çµ‚å€¤"].astype(float)
    hi = (g["é«˜å€¤"] if "é«˜å€¤" in g else g["çµ‚å€¤"]).astype(float)
    lo = (g["å®‰å€¤"] if "å®‰å€¤" in g else g["çµ‚å€¤"]).astype(float)
    vol = g["å‡ºæ¥é«˜"].astype(float)

    # æŒ‡æ¨™
    s10  = _ma(px, 10)
    s20  = _ma(px, 20)
    s50  = _ma(px, 50)
    s100 = _ma(px, 100)
    s200 = _ma(px, 200)
    v20  = _avg_vol(vol, 20)
    atr20 = _atr(g, 20)  # äºˆå‚™ï¼ˆæœªä½¿ç”¨ï¼‰
    hh60 = hi.shift(1).rolling(HH_N, min_periods=HH_N).max()  # å½“æ—¥ã‚’é™¤ã60æ—¥é«˜å€¤

    # å½“æ—¥ï¼ˆæœ«è¡Œï¼‰
    if len(g) < max(60, 50):
        return 0.0, "", ""
    close_t = float(px.iloc[-1])
    vol_t   = float(vol.iloc[-1])

    s10_t  = s10.iloc[-1]  if len(s10)  else np.nan
    s20_t  = s20.iloc[-1]  if len(s20)  else np.nan
    s50_t  = s50.iloc[-1]  if len(s50)  else np.nan
    s100_t = s100.iloc[-1] if len(s100) else np.nan
    s200_t = s200.iloc[-1] if len(s200) else np.nan

    if pd.isna(s20_t) or pd.isna(s50_t):
        return 0.0, "", ""

    ext20 = (close_t - s20_t) / s20_t if s20_t > 0 else 0.0
    ext50 = (close_t - s50_t) / s50_t if s50_t > 0 else 0.0

    sigs = []

    # A) 60æ—¥é«˜å€¤ãƒ–ãƒ¬ã‚¤ã‚¯
    if not pd.isna(hh60.iloc[-1]):
        cond_break = (close_t >= hh60.iloc[-1] * (1.0 + PIVOT_EPS))
        cond_vol   = (not pd.isna(v20.iloc[-1]) and vol_t >= v20.iloc[-1] * VOL_BOOST)
        cond_ma    = (s20_t > s50_t) and (len(s50) >= 2 and not pd.isna(s50.iloc[-2]) and s50.iloc[-1] > s50.iloc[-2])
        cond_ext   = (ext20 <= EXT_20_MAX) and (ext50 <= EXT_50_MAX)
        if cond_break and cond_ma and cond_ext:
            near = max(0.0, 1.0 - (close_t / hh60.iloc[-1] - 1.0) / 0.05)  # 5%ä¸ŠæŠœãã§0ç‚¹
            vol_score = 0.0 if pd.isna(v20.iloc[-1]) else min(1.0, (vol_t / max(1.0, v20.iloc[-1])) / 2.5)
            ma_gap = min(1.0, (s20_t/s50_t - 1.0) / 0.05) if s50_t > 0 else 0.0
            score = 55*near + 25*vol_score + 20*ma_gap
            sigs.append((score, "ãƒ–ãƒ¬ã‚¤ã‚¯", f"HH{HH_N}+{PIVOT_EPS*100:.1f}%, volâ‰¥{VOL_BOOST}x, 20>50"))

    # B) ãƒã‚±ãƒƒãƒˆãƒ”ãƒœãƒƒãƒˆ
    if not pd.isna(s10_t) and not pd.isna(hh60.iloc[-1]):
        down_mask = px.diff() < 0
        down_vol_max = vol.where(down_mask).tail(POCKET_WIN).max()
        near_pivot = (close_t / hh60.iloc[-1] - 1.0)
        cond_pp = (close_t > s10_t) and (not pd.isna(down_vol_max)) and (vol_t > down_vol_max)
        cond_near = (-0.03 <= near_pivot <= 0.02)
        if cond_pp and cond_near:
            tight = px.tail(10).pct_change().dropna().std()
            tight_score = max(0.0, 1.0 - (tight / 0.025)) if pd.notna(tight) else 0.0
            vol_score = min(1.0, vol_t / max(1.0, down_vol_max) / 2.0)
            score = 35 + 35*vol_score + 30*tight_score
            sigs.append((score, "ãƒã‚±ãƒƒãƒˆ", f">10MA, vol>{POCKET_WIN}dDownMax, near HH{HH_N}"))

    # C) 20MAãƒªãƒã‚¦ãƒ³ãƒ‰ï¼ˆNaNå®‰å…¨åŒ–ï¼‰
    # 20MAãŒå­˜åœ¨ã™ã‚‹æ—¥ã®ã¿ã§ below20 ã‚’ä½œã‚‹ â†’ ãƒ–ãƒ¼ãƒ«dtypeç¶­æŒ
    below20 = (px < s20) & s20.notna()
    # ç›´å‰ã¯20MAã®ä¸‹ãƒ»ç¾åœ¨ã¯ä¸Šï¼ˆ=ãƒªãƒã‚¦ãƒ³ãƒ‰ï¼‰ã‚’ REB_WIN å†…ã«å«ã‚€ã‹
    cross_up = (below20.shift(1, fill_value=False) & (~below20)).tail(REB_WIN).any()
    cond_c = (cross_up
              and close_t >= s20_t
              and (not pd.isna(s50_t)) and close_t >= s50_t
              and (not pd.isna(v20.iloc[-1])) and vol_t >= v20.iloc[-1])
    if cond_c:
        near20 = max(0.0, 1.0 - abs(ext20)/0.04)  # Â±4%ã§0ç‚¹
        score = 30 + 40*near20 + 30*min(1.0, vol_t/max(1.0, v20.iloc[-1]))
        sigs.append((score, "20MAãƒªãƒ", "20MA reclaim & volâ‰¥Avg20 & â‰¥50MA"))

    # D) 200MAãƒªã‚¯ãƒ¬ã‚¤ãƒ ï¼ˆNaNå®‰å…¨åŒ–ï¼ã“ã“ãŒã‚¨ãƒ©ãƒ¼ã ã£ãŸç®‡æ‰€ï¼‰
    if not pd.isna(s200_t):
        # 200MAãŒå­˜åœ¨ã™ã‚‹æ—¥ã®ã¿è©•ä¾¡ï¼ˆTrue/Falseã®ã¿ã®Seriesã«ãªã‚‹ï¼‰
        above200 = (px >= s200) & s200.notna()
        crossed  = ((~above200.shift(1, fill_value=False)) & above200).tail(RECLAIM_WIN).any()
        stay3    = above200.tail(3).all()
        slope50_up   = (len(s50.dropna())  >= 6 and s50.iloc[-1]  > s50.iloc[-5])
        slope100_ok  = (len(s100.dropna()) >= 6 and s100.iloc[-1] >= s100.iloc[-5])
        cond_d = crossed and stay3 and slope50_up and slope100_ok
        if cond_d:
            ext200 = (close_t - s200_t)/s200_t if s200_t > 0 else 0.0
            near200   = max(0.0, 1.0 - abs(ext200)/0.06)  # Â±6%ã§0ç‚¹
            vol_score = 0.0 if pd.isna(v20.iloc[-1]) else min(1.0, vol_t/max(1.0, v20.iloc[-1]))
            score = 25 + 45*near200 + 30*vol_score
            sigs.append((score, "200MAãƒªã‚¯ãƒ¬ã‚¤ãƒ ", "cross&stay3d, 50MAâ†‘,100MAâ†”â†‘"))

    if not sigs:
        return 0.0, "", ""
    sigs.sort(key=lambda x: x[0], reverse=True)
    return sigs[0]  # (score, tag, detail)

# ---- ãƒ¡ã‚¤ãƒ³ï¼šæ—©æœŸãƒˆãƒªã‚¬ãƒ¼è¨ˆç®—ãƒ»DBæ›´æ–°ãƒ»ãƒ­ã‚°è¨˜éŒ²ï¼ˆæ—¥æ™‚ã§è¨˜éŒ²ï¼‰----
def compute_right_up_early_triggers(conn, as_of=None, log_datetime=None):
    """
    å³è‚©ä¸ŠãŒã‚Šã®â€œæ—©ã‚ã«ä»•æ›ã‘ã‚‹â€4ã‚·ã‚°ãƒŠãƒ«ï¼ˆãƒ–ãƒ¬ã‚¤ã‚¯/ãƒã‚±ãƒƒãƒˆ/20MAãƒªãƒ/200MAãƒªã‚¯ãƒ¬ã‚¤ãƒ ï¼‰ã‚’åˆ¤å®šã€‚
    - price_history ã®æ—¥è¶³ã®ã¿ã§åˆ¤å®š
    - screener: å³è‚©æ—©æœŸãƒ•ãƒ©ã‚°/ç¨®åˆ¥/ã‚¹ã‚³ã‚¢ ã‚’æ›´æ–°
    - signals_log: æ—¥æ™‚ã§è¨˜éŒ²ï¼ˆå‰å ´/å¾Œå ´ãªã©1æ—¥è¤‡æ•°å›ã®å®Ÿè¡Œã«å¯¾å¿œï¼‰
    å¼•æ•°:
      as_of        â€¦ åˆ¤å®šã™ã‚‹â€œæ—¥ä»˜â€ï¼ˆä¾‹ '2025-08-22'ï¼‰ã€‚æœªæŒ‡å®šãªã‚‰ price_history ã® MAX(æ—¥ä»˜)
      log_datetime â€¦ ãƒ­ã‚°ã«æ›¸ãâ€œæ—¥æ™‚â€ï¼ˆä¾‹ '2025-08-22 09:01:00'ï¼‰ã€‚æœªæŒ‡å®šãªã‚‰ now()
    """
    # åˆ¤å®šå¯¾è±¡æ—¥ï¼ˆprice_history ã®æœ€çµ‚å–¶æ¥­æ—¥ã«åˆã‚ã›ã‚‹ï¼‰
    dmax = pd.read_sql_query("SELECT MAX(æ—¥ä»˜) d FROM price_history", conn, parse_dates=["d"])
    if dmax.empty or pd.isna(dmax.loc[0,"d"]):
        print("[å³è‚©æ—©æœŸ] price_history ãŒç©ºã§ã™"); return
    as_of_date = pd.to_datetime(as_of).date() if as_of is not None else pd.to_datetime(dmax.loc[0,"d"]).date()

    # ãƒ­ã‚°ç”¨ã®æ—¥æ™‚ï¼ˆå‰å ´/å¾Œå ´ã§åŒºåˆ¥ã—ãŸã„æ™‚ã¯ã“ã“ã‚’æŒ‡å®šï¼‰
    dt_log = pd.to_datetime(log_datetime) if log_datetime is not None else pd.Timestamp.now()
    dt_str = dt_log.strftime("%Y-%m-%d %H:%M:%S")

    # å¿…è¦æœŸé–“ã ã‘æŠ½å‡ºï¼ˆ200MAã¾ã§ä½¿ã†ã®ã§ä½™è£•ã‚’æŒã£ã¦ï¼‰
    start = (pd.Timestamp(as_of_date) - pd.Timedelta(days=320)).strftime("%Y-%m-%d")
    ph = pd.read_sql_query(
        "SELECT æ—¥ä»˜, ã‚³ãƒ¼ãƒ‰, çµ‚å€¤, é«˜å€¤, å®‰å€¤, å‡ºæ¥é«˜ "
        "FROM price_history WHERE æ—¥ä»˜ >= date(?) AND æ—¥ä»˜ <= date(?) "
        "ORDER BY ã‚³ãƒ¼ãƒ‰, æ—¥ä»˜",
        conn, params=(start, as_of_date)
    )
    if ph.empty:
        print("[å³è‚©æ—©æœŸ] ãƒ‡ãƒ¼ã‚¿ãªã—"); return
    ph["æ—¥ä»˜"] = pd.to_datetime(ph["æ—¥ä»˜"])

    results, logs = [], []
    cnt_flag = 0

    for code, g in ph.groupby("ã‚³ãƒ¼ãƒ‰", sort=False):
        if len(g) < 60:
            continue
        score, tag, detail = _best_signal_today(g)
        flag = "å€™è£œ" if score >= SCORE_TH and tag else ""
        results.append((
            None if score==0 else round(float(score),1),
            (tag if tag else None),
            (flag if flag else ""),
            str(code)
        ))
        if flag:
            cnt_flag += 1
            logs.append((dt_str, str(code), "å³è‚©ä¸ŠãŒã‚Š-æ—©æœŸ", f"{tag} | score={round(float(score),1)} | {detail}"))

    # screener ã‚’åˆæœŸåŒ– â†’ æ›´æ–°
    cur = conn.cursor()
    cur.execute("UPDATE screener SET å³è‚©æ—©æœŸãƒ•ãƒ©ã‚°='', å³è‚©æ—©æœŸç¨®åˆ¥=NULL, å³è‚©æ—©æœŸã‚¹ã‚³ã‚¢=NULL")
    if results:
        cur.executemany("""
            UPDATE screener
               SET å³è‚©æ—©æœŸã‚¹ã‚³ã‚¢=?,
                   å³è‚©æ—©æœŸç¨®åˆ¥=?,
                   å³è‚©æ—©æœŸãƒ•ãƒ©ã‚°=?
             WHERE ã‚³ãƒ¼ãƒ‰=?
        """, results)
    conn.commit(); cur.close()

    # signals_log ã¸æ›¸ãè¾¼ã¿ï¼ˆæ—¥æ™‚ã®ã¿ã€åŒä¸€(ã‚³ãƒ¼ãƒ‰,æ—¥æ™‚,ç¨®åˆ¥)ã¯ä¸Šæ›¸ãï¼‰
    if logs:
        cur = conn.cursor()
        try:
            cur.executemany("""
                INSERT INTO signals_log(æ—¥æ™‚, ã‚³ãƒ¼ãƒ‰, ç¨®åˆ¥, è©³ç´°)
                VALUES(?,?,?,?)
                ON CONFLICT(ã‚³ãƒ¼ãƒ‰, æ—¥æ™‚, ç¨®åˆ¥) DO UPDATE SET
                  è©³ç´° = excluded.è©³ç´°
            """, logs)
        except Exception:
            # äº’æ›ç”¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆä¸»ã‚­ãƒ¼ãªã—ç­‰ã®å¤ã„ã‚¹ã‚­ãƒ¼ãƒï¼‰
            cur.executemany("INSERT INTO signals_log(æ—¥æ™‚, ã‚³ãƒ¼ãƒ‰, ç¨®åˆ¥, è©³ç´°) VALUES(?,?,?,?)", logs)
        conn.commit(); cur.close()

    print(f"[å³è‚©æ—©æœŸ] å€™è£œ {cnt_flag} ä»¶ / ç·{len(results)}ä»¶  as_of={as_of_date}  é–¾å€¤{SCORE_TH}  dt={dt_str}")
# ========================= /å³è‚©ä¸ŠãŒã‚Šãƒ»æ—©æœŸãƒˆãƒªã‚¬ãƒ¼ï¼ˆå®Œå…¨ç‰ˆï¼šç½®æ›ç”¨ï¼‰ =========================

# ===== ã‚·ã‚°ãƒŠãƒ«åˆ¤å®šï¼ˆåˆå‹•/åº•æ‰“ã¡/ä¸Šæ˜‡ä½™åœ°ï¼‰ =====
def phase_signal_detection(conn: sqlite3.Connection):
    cur = conn.cursor()
    cur.execute("SELECT DISTINCT ã‚³ãƒ¼ãƒ‰ FROM price_history")
    codes = [r[0] for r in cur.fetchall()]
    cur.close()
    if not codes:
        return

    today = today_str()
    upd_rows, log_rows = [], []
    start_cut = (dtm.date.today() - dtm.timedelta(days=SIGNAL_LOOKBACK_DAYS)).strftime("%Y-%m-%d")

    for i in range(0, len(codes), 500):
        part = codes[i:i+500]
        qmarks = ",".join("?" * len(part))
        df = pd.read_sql_query(f"""
            SELECT ã‚³ãƒ¼ãƒ‰, æ—¥ä»˜, çµ‚å€¤, é«˜å€¤, å®‰å€¤, å‡ºæ¥é«˜
            FROM price_history
            WHERE æ—¥ä»˜ >= ? AND ã‚³ãƒ¼ãƒ‰ IN ({qmarks})
            ORDER BY ã‚³ãƒ¼ãƒ‰, æ—¥ä»˜
        """, conn, params=[start_cut, *part])

        if df.empty:
            continue

        df = add_price_features(df)
        for code, g in df.groupby("ã‚³ãƒ¼ãƒ‰", sort=False):

            diff = g["çµ‚å€¤"].diff()
            up = diff.clip(lower=0).rolling(14).mean()
            down = (-diff.clip(upper=0)).rolling(14).mean()
            rs = up / (down.replace(0, 1e-9))
            g["RSI14"] = 100 - (100 / (1 + rs))

            last = g.iloc[-1]
            if len(g) < 21 or pd.isna(last["çµ‚å€¤_ma5"]) or pd.isna(last["çµ‚å€¤_ma20"]) or pd.isna(last["å‡ºæ¥é«˜_ma5"]):
                continue

            prev_close = g["çµ‚å€¤"].iloc[-2] if len(g) >= 2 else last["çµ‚å€¤"]
            zenhi = (last["çµ‚å€¤"] - prev_close)

            # --- åˆå‹• ---
            vol_bai = (last["å‡ºæ¥é«˜"] / last["å‡ºæ¥é«˜_ma5"]) if last["å‡ºæ¥é«˜_ma5"] else 0
            price_ma5_ratio = last["çµ‚å€¤"] / last["çµ‚å€¤_ma5"] if last["çµ‚å€¤_ma5"] else 0
            shodou = "å€™è£œ" if (vol_bai >= 2 and price_ma5_ratio >= 1.03 and zenhi > 0) else None

            # --- åº•æ‰“ã¡ ---
            range_ok = False
            if ffloat(last["é«˜å€¤"], None) is not None and ffloat(last["å®‰å€¤"], None) is not None and last["é«˜å€¤"] > last["å®‰å€¤"]:
                pos = (last["çµ‚å€¤"] - last["å®‰å€¤"]) / (last["é«˜å€¤"] - last["å®‰å€¤"])
                range_ok = pos >= 0.6
            bottom = "å€™è£œ" if (ffloat(last["RSI14"], 100) <= 30 and zenhi > 0 and range_ok) else None

            # --- ä¸Šæ˜‡ä½™åœ°ã‚¹ã‚³ã‚¢ ---
            c2 = conn.cursor()
            c2.execute("SELECT æ™‚ä¾¡ç·é¡å„„å†† FROM screener WHERE ã‚³ãƒ¼ãƒ‰=?", (code,))
            r = c2.fetchone()
            c2.close()
            try:
                zika_oku = float(r[0]) if r and r[0] is not None else 0.0
            except Exception:
                zika_oku = 0.0

            score_cap   = max(0, min(40, (100 - zika_oku) / 100 * 40))
            score_trend = max(0, min(40, (last["çµ‚å€¤"] / last["çµ‚å€¤_ma20"] - 1) * 200))
            score_vol   = max(0, min(20, (vol_bai - 1) * 20))
            potential_score = round(score_cap + score_trend + score_vol, 1)

            # --- å³è‚©ä¸ŠãŒã‚Šãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ã‚¹ã‚³ã‚¢ ---
            # 52é€±é«˜å€¤ï¼ˆãƒ‡ãƒ¼ã‚¿ä¸è¶³æ™‚ã¯æœŸé–“å†…é«˜å€¤ï¼‰
            try:
                high_52 = g["çµ‚å€¤"].rolling(252, min_periods=20).max().iloc[-1]
            except Exception:
                high_52 = g["çµ‚å€¤"].max()
            near_high = (high_52 and last["çµ‚å€¤"] and (last["çµ‚å€¤"] / high_52 >= 0.95))

            slope13 = (g["MA13"].iloc[-1] / g["MA13"].iloc[-13] - 1) if len(g) >= 26 and not pd.isna(g["MA13"].iloc[-13]) else 0
            slope26 = (g["MA26"].iloc[-1] / g["MA26"].iloc[-26] - 1) if len(g) >= 52 and not pd.isna(g["MA26"].iloc[-26]) else 0

            above_ma20_ratio = (g["çµ‚å€¤"].tail(60) > g["çµ‚å€¤_ma20"].tail(60)).mean() if len(g) >= 60 else 0
            vol_contraction = (last["ATR20"] / last["çµ‚å€¤"] <= 0.03) if (last["çµ‚å€¤"] and not pd.isna(last["ATR20"])) else False

            vol20 = g["å‡ºæ¥é«˜"].rolling(20).mean().iloc[-1] if len(g) >= 20 else None
            vol60 = g["å‡ºæ¥é«˜"].rolling(60).mean().iloc[-1] if len(g) >= 60 else None
            dryup = (vol20 is not None and vol60 is not None and vol20 < vol60 * 0.8)

            rumor_spike = (vol20 is not None and last["å‡ºæ¥é«˜"] is not None and last["å‡ºæ¥é«˜"] >= vol20 * 1.5 and zenhi > 0)

            tob_score = 0
            tob_score += 20 if near_high else 0
            tob_score += 15 if slope13 > 0 else 0
            tob_score += 15 if slope26 > 0 else 0
            tob_score += 20 if above_ma20_ratio >= 0.80 else 0
            tob_score += 15 if vol_contraction else 0
            tob_score += 10 if dryup else 0
            tob_score += 5  if rumor_spike else 0
            tob_flag = "å€™è£œ" if tob_score >= 60 else None

            upd_rows.append((shodou, bottom, potential_score, today, code))

            # signals_log ã¸
            def _append_log(kind, score_value):
                log_rows.append((
                    code, today, kind,
                    last['çµ‚å€¤'], last['é«˜å€¤'], last['å®‰å€¤'],
                    fint(last['å‡ºæ¥é«˜'], 0),
                    score_value,
                    0,
                    None, None, None, None,
                    None, None, None,
                    None, None
                ))

            if shodou: _append_log('åˆå‹•', potential_score or None)
            if bottom: _append_log('åº•æ‰“ã¡', potential_score or None)
            if potential_score is not None and potential_score >= 60: _append_log('ä¸Šæ˜‡ä½™åœ°', potential_score)
            if tob_flag: _append_log('å³è‚©ä¸ŠãŒã‚Š', float(tob_score))

    if upd_rows:
        cur = conn.cursor()
        cur.executemany("""
            UPDATE screener
               SET åˆå‹•ãƒ•ãƒ©ã‚°=?,
                   åº•æ‰“ã¡ãƒ•ãƒ©ã‚°=?,
                   ä¸Šæ˜‡ä½™åœ°ã‚¹ã‚³ã‚¢=?,
                   ã‚·ã‚°ãƒŠãƒ«æ›´æ–°æ—¥=?
             WHERE ã‚³ãƒ¼ãƒ‰=?
        """, upd_rows)
        conn.commit()
        cur.close()

    if log_rows:
        cur = conn.cursor()
        cur.executemany("""
            INSERT OR IGNORE INTO signals_log
              (ã‚³ãƒ¼ãƒ‰,æ—¥æ™‚,ç¨®åˆ¥,çµ‚å€¤,é«˜å€¤,å®‰å€¤,å‡ºæ¥é«˜,ã‚¹ã‚³ã‚¢,æ¤œè¨¼æ¸ˆã¿,
               æ¬¡æ—¥å§‹å€¤,æ¬¡æ—¥çµ‚å€¤,æ¬¡æ—¥é«˜å€¤,æ¬¡æ—¥å®‰å€¤,
               ãƒªã‚¿ãƒ¼ãƒ³çµ‚å€¤pct,ãƒ•ã‚©ãƒ­ãƒ¼é«˜å€¤pct,æœ€å¤§é€†è¡Œpct,åˆ¤å®š,ç†ç”±)
            VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)
        """, log_rows)
        conn.commit()
        cur.close()

# ===== ç¿Œå–¶æ¥­æ—¥æ¤œè¨¼ =====
def phase_validate_prev_business_day(conn: sqlite3.Connection):
    extra_closed = _load_extra_closed(EXTRA_CLOSED_PATH)
    today = dtm.date.today()
    d0 = prev_business_day_jp(today, extra_closed)
    d1 = next_business_day_jp(d0,    extra_closed)
    d0s, d1s = d0.strftime("%Y-%m-%d"), d1.strftime("%Y-%m-%d")

    cur = conn.cursor()
    cur.execute("""
        SELECT ã‚³ãƒ¼ãƒ‰, ç¨®åˆ¥, çµ‚å€¤, é«˜å€¤, å®‰å€¤, ã‚¹ã‚³ã‚¢
        FROM signals_log
        WHERE æ—¥æ™‚=? AND (æ¤œè¨¼æ¸ˆã¿ IS NULL OR æ¤œè¨¼æ¸ˆã¿=0)
    """, (d0s,))
    sigs = cur.fetchall()
    cur.close()
    if not sigs:
        print(f"å‰å–¶æ¥­æ—¥({d0s})ã®æœªæ¤œè¨¼ã‚·ã‚°ãƒŠãƒ«ãªã—")
        return

    codes = sorted(set([s[0] for s in sigs]))
    qmarks = ",".join("?"*len(codes))
    df1 = pd.read_sql_query(f"""
        SELECT ã‚³ãƒ¼ãƒ‰, æ—¥ä»˜, å§‹å€¤, é«˜å€¤, å®‰å€¤, çµ‚å€¤
        FROM price_history
        WHERE æ—¥ä»˜ IN (?, ?) AND ã‚³ãƒ¼ãƒ‰ IN ({qmarks})
        ORDER BY ã‚³ãƒ¼ãƒ‰, æ—¥ä»˜
    """, conn, params=[d0s, d1s, *codes])

    if df1.empty:
        
        return

    rows = {(r["ã‚³ãƒ¼ãƒ‰"], r["æ—¥ä»˜"]): r for _, r in df1.iterrows()}
    updates = []
    for code, kind, base_close, base_high, base_low, score in sigs:
        r_next = rows.get((code, d1s))
        if not r_next:
            continue
        o1 = ffloat(r_next["å§‹å€¤"], None)
        h1 = ffloat(r_next["é«˜å€¤"], None)
        l1 = ffloat(r_next["å®‰å€¤"], None)
        c1 = ffloat(r_next["çµ‚å€¤"], None)

        if not base_close or base_close == 0 or c1 is None or h1 is None or l1 is None:
            ret_close = None; follow_high = None; mae = None
        else:
            ret_close = (c1 / base_close - 1) * 100
            follow_high = (h1 / base_close - 1) * 100
            mae = (l1 / base_close - 1) * 100

        verdict, reason = "è¦‹é€ã‚Š", ""
        if kind == "åˆå‹•":
            if (follow_high is not None and follow_high >= 2.0) or (ret_close is not None and ret_close > 0):
                verdict = "çš„ä¸­"
            reason = f"follow_high={follow_high:.2f}% close_ret={ret_close:.2f}%" if (follow_high is not None and ret_close is not None) else "insufficient data"
        elif kind == "åº•æ‰“ã¡":
            pos = (c1 - l1) / (h1 - l1) if (c1 is not None and h1 is not None and l1 is not None and h1 > l1) else 0
            if (ret_close is not None and ret_close > 0) and pos >= 0.5:
                verdict = "çš„ä¸­"
            reason = f"close_ret={ret_close:.2f}% pos={pos:.2f}"
        elif kind == "ä¸Šæ˜‡ä½™åœ°":
            need = 1.0
            if score is not None:
                s = float(score)
                if s >= 90: need = 3.0
                elif s >= 80: need = 2.0
                elif s >= 60: need = 1.0
            if (follow_high is not None and follow_high >= need) or (ret_close is not None and ret_close > 0):
                verdict = "çš„ä¸­"
            reason = f"need={need:.1f}% follow_high={follow_high:.2f}% close_ret={ret_close:.2f}%"
        elif kind == "å³è‚©ä¸ŠãŒã‚Š":
            if (follow_high is not None and follow_high >= 1.0) or (ret_close is not None and ret_close >= 0):
                verdict = "å‚¾å‘ç¶­æŒ"
            reason = f"follow_high={follow_high:.2f}% close_ret={ret_close:.2f}%"
        else:
            reason = "unknown kind"

        updates.append((1, o1, c1, h1, l1,
                        None if ret_close is None else round(ret_close, 2),
                        None if follow_high is None else round(follow_high, 2),
                        None if mae is None else round(mae, 2),
                        verdict, reason, code, d0s, kind))

    if updates:
        cur = conn.cursor()
        cur.executemany("""
            UPDATE signals_log
            SET æ¤œè¨¼æ¸ˆã¿=?,
                æ¬¡æ—¥å§‹å€¤=?, æ¬¡æ—¥çµ‚å€¤=?, æ¬¡æ—¥é«˜å€¤=?, æ¬¡æ—¥å®‰å€¤=?,
                ãƒªã‚¿ãƒ¼ãƒ³çµ‚å€¤pct=?, ãƒ•ã‚©ãƒ­ãƒ¼é«˜å€¤pct=?, æœ€å¤§é€†è¡Œpct=?,
                åˆ¤å®š=?, ç†ç”±=?
            WHERE ã‚³ãƒ¼ãƒ‰=? AND æ—¥æ™‚=? AND ç¨®åˆ¥=?
        """, updates)
        conn.commit()
        cur.close()

    out = os.path.join(OUTPUT_DIR, f"validate_{d0s}_vs_{d1s}.csv")
    cur = conn.cursor()
    cur.execute("""
        SELECT ã‚³ãƒ¼ãƒ‰, ç¨®åˆ¥, æ—¥æ™‚, çµ‚å€¤, æ¬¡æ—¥å§‹å€¤, æ¬¡æ—¥çµ‚å€¤, æ¬¡æ—¥é«˜å€¤, æ¬¡æ—¥å®‰å€¤,
               ãƒªã‚¿ãƒ¼ãƒ³çµ‚å€¤pct, ãƒ•ã‚©ãƒ­ãƒ¼é«˜å€¤pct, æœ€å¤§é€†è¡Œpct, åˆ¤å®š, ç†ç”±, ã‚¹ã‚³ã‚¢
        FROM signals_log
        WHERE æ—¥æ™‚=? AND æ¤œè¨¼æ¸ˆã¿=1
        ORDER BY åˆ¤å®š DESC, ãƒ•ã‚©ãƒ­ãƒ¼é«˜å€¤pct DESC
    """, (d0s,))
    rows = cur.fetchall()
    cur.close()

    if rows:
        with open(out, "w", encoding="utf-8", newline="") as f:
            f.write("ã‚³ãƒ¼ãƒ‰,ç¨®åˆ¥,æ—¥æ™‚,çµ‚å€¤,æ¬¡æ—¥å§‹å€¤,æ¬¡æ—¥çµ‚å€¤,æ¬¡æ—¥é«˜å€¤,æ¬¡æ—¥å®‰å€¤,ãƒªã‚¿ãƒ¼ãƒ³çµ‚å€¤pct,ãƒ•ã‚©ãƒ­ãƒ¼é«˜å€¤pct,æœ€å¤§é€†è¡Œpct,åˆ¤å®š,ç†ç”±,ã‚¹ã‚³ã‚¢\n")
            for r in rows:
                f.write(",".join([str(x if x is not None else "") for x in r]) + "\n")
        try:
            notification.notify(title="ç¿Œæ—¥æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆ", message=f"{d0s}â†’{d1s} æ¤œè¨¼å®Œäº†: {len(rows)}ä»¶", timeout=5)
        except Exception:
            pass

# ===== HTMLï¼ˆã‚ªãƒ•ãƒ©ã‚¤ãƒ³/5ã‚¿ãƒ–/å„è¡¨ã«ãƒªãƒ³ã‚¯åˆ—/Migikataãƒ•ã‚£ãƒ«ã‚¿è¿½åŠ ï¼‰ =====

# ========== Template exporterï¼ˆCDNãªã—ãƒ»JSONç›´åŸ‹ã‚ãƒ»ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¼·åŒ–ãƒ»å®Œå…¨ç½®æ›ï¼‰ ==========

# ã—ãã„å€¤ï¼ˆãƒ˜ãƒ«ãƒ—è¡¨ç¤ºç”¨ï¼šæœªä½¿ç”¨ã§ã‚‚æ®‹ã™ï¼‰
HH_N        = globals().get('HH_N', 60)
PIVOT_EPS   = globals().get('PIVOT_EPS', 0.002)
VOL_BOOST   = globals().get('VOL_BOOST', 1.5)
EXT_20_MAX  = globals().get('EXT_20_MAX', 0.05)
EXT_50_MAX  = globals().get('EXT_50_MAX', 0.10)
POCKET_WIN  = globals().get('POCKET_WIN', 10)
REB_WIN     = globals().get('REB_WIN', 10)
RECLAIM_WIN = globals().get('RECLAIM_WIN', 10)
SCORE_TH    = globals().get('SCORE_TH', 70)

# ---------- å®‰å…¨æ•´å½¢ ----------
def _to_float(v):
    if v is None: return None
    try:
        s = str(v).replace(',', '').replace('ï¼…','').replace('%','').strip()
        if s == '': return None
        x = float(s)
        return x if math.isfinite(x) else None
    except Exception:
        return None

def _fmt_cell(v):
    """HTMLæ··åœ¨ãƒ»æ•°å€¤ã‚’å®‰å…¨ã«æ•´å½¢ã—ã¦è¿”ã™ã€‚<span>/<br>/<div> ã‚’å«ã‚€å ´åˆã¯ safe å‡ºåŠ›ã€‚"""
    try:
        if v is None or (isinstance(v,float) and math.isnan(v)): 
            return ""
        s = str(v)
        if ("<span" in s) or ("<br" in s) or ("<div" in s):
            return Markup(s)
        if isinstance(v,int): 
            return f"{v:,}"
        if isinstance(v,float):
            if abs(v-round(v))<1e-9: 
                return f"{int(round(v)):,}"
            return f"{v:.2f}"
        fv = _to_float(v)
        if fv is not None: 
            return _fmt_cell(fv)
        return escape(s)
    except Exception:
        return escape(str(v)) if v is not None else ""

def _noshor_from_agency(val) -> str:
    if val is None: return "1"
    s = str(val).strip()
    return "1" if s=="" or s in ("ãªã—","-","0","NaN","nan","None") else "0"

def _op_ratio_flag(d):
    """å–¶åˆ©å¯¾æ™‚ä¾¡(=å–¶æ¥­åˆ©ç›Š / æ™‚ä¾¡ç·é¡) >= 10% ã‚’ç–‘ä¼¼åˆ¤å®šï¼ˆDBåˆ—ã«ä¾å­˜ã—ãªã„Aæ¡ˆï¼‰"""
    e = _to_float(d.get("å–¶æ¥­åˆ©ç›Š"))
    z = _to_float(d.get("æ™‚ä¾¡ç·é¡å„„å††"))
    if e is None or z is None or z == 0: 
        return "0"
    # å–¶æ¥­åˆ©ç›Šã¯å„„å††ç›¸å½“ã‚’æƒ³å®šã€‚ä¿å®ˆçš„ã« 10% ã‚’é–¾å€¤ã¨ã™ã‚‹
    try:
        ratio = (e / z) * 100.0
        return "1" if ratio >= 10.0 else "0"
    except Exception:
        return "0"

def _bucket_turn(v):
    if v is None: return "å£²è²·:<ä¸æ˜>"
    v=float(v);  return "å£²è²·:<5" if v<5 else ("å£²è²·:5-10" if v<10 else ("å£²è²·:10-50" if v<50 else ("å£²è²·:50-100" if v<100 else "å£²è²·:100+")))
def _bucket_rvol(v):
    if v is None: return "RVOL:<ä¸æ˜>"
    v=float(v);  return "RVOL:<1" if v<1 else ("RVOL:1-2" if v<2 else ("RVOL:2-3" if v<3 else ("RVOL:3-5" if v<5 else "RVOL:5+")))
def _bucket_vol(v):
    if v is None: return "å‡ºæ¥:<ä¸æ˜>"
    v=float(v);  return "å‡ºæ¥:<10ä¸‡" if v<1e5 else ("å‡ºæ¥:10-100ä¸‡" if v<1e6 else ("å‡ºæ¥:100-500ä¸‡" if v<5e6 else ("å‡ºæ¥:500-1000ä¸‡" if v<1e7 else "å‡ºæ¥:1000ä¸‡+")))
def _bucket_atr(v):
    if v is None: return "ATR:<ä¸æ˜>"
    v=float(v);  return "ATR:<4" if v<4 else ("ATR:4-6" if v<6 else ("ATR:6-10" if v<10 else "ATR:10+"))
def _bucket_mcap(v):
    if v is None: return "æ™‚ä¾¡:<ä¸æ˜>"
    v=float(v);  return "æ™‚ä¾¡:<300" if v<300 else ("æ™‚ä¾¡:300-1000" if v<1000 else ("æ™‚ä¾¡:1000-5000" if v<5000 else ("æ™‚ä¾¡:5000-20000" if v<20000 else "æ™‚ä¾¡:20000+")))
def _bucket_comp(v):
    if v is None: return "åˆæˆS:<ä¸æ˜>"
    v=float(v);  return "åˆæˆS:<70" if v<70 else ("åˆæˆS:70-80" if v<80 else ("åˆæˆS:80-90" if v<90 else "åˆæˆS:90+"))
def _bucket_rate(v):
    if v is None: return "ä¸Šæ˜‡ç‡:ä¸æ˜"
    v=float(v);  return "ä¸Šæ˜‡ç‡:0-1" if v<1 else ("ä¸Šæ˜‡ç‡:1-3" if v<3 else ("ä¸Šæ˜‡ç‡:3-5" if v<5 else "ä¸Šæ˜‡ç‡:5+"))

def _build_reason(d):
    tags = []
    tags.append(_bucket_rate(_to_float(d.get("å‰æ—¥çµ‚å€¤æ¯”ç‡"))))
    tags.append(_bucket_turn(_to_float(d.get("å£²è²·ä»£é‡‘(å„„)"))))
    tags.append(_bucket_rvol(_to_float(d.get("RVOLä»£é‡‘"))))
    tags.append(_bucket_vol(_to_float(d.get("å‡ºæ¥é«˜"))))
    tags.append(_bucket_atr(_to_float(d.get("ATR14%"))))
    tags.append(_bucket_mcap(_to_float(d.get("æ™‚ä¾¡ç·é¡å„„å††"))))
    tags.append(_bucket_comp(_to_float(d.get("åˆæˆã‚¹ã‚³ã‚¢"))))
    etype = (d.get("å³è‚©æ—©æœŸç¨®åˆ¥") or "").strip()
    if etype: tags.append(f"æ—©æœŸ:{etype}")
    if (d.get("åˆå‹•ãƒ•ãƒ©ã‚°") or "") == "å€™è£œ": tags.append("åˆå‹•")
    if (d.get("åº•æ‰“ã¡ãƒ•ãƒ©ã‚°") or "") == "å€™è£œ": tags.append("åº•æ‰“ã¡")
    if (d.get("å³è‚©ä¸ŠãŒã‚Šãƒ•ãƒ©ã‚°") or "") == "å€™è£œ": tags.append("å³è‚©")
    if (d.get("å³è‚©æ—©æœŸãƒ•ãƒ©ã‚°") or "") == "å€™è£œ": tags.append("æ—©æœŸ")
    if _op_ratio_flag(d) == "1": tags.append("å‰²å®‰")
    if d.get("ç©ºå£²ã‚Šæ©Ÿé–¢ãªã—_flag","0") == "1": tags.append("æ©Ÿé–¢:ãªã—")
    return " / ".join(tags)

# === æ¨å¥¨ï¼æ¯”ç‡ãƒ»å–¶åˆ©å¯¾æ™‚ä¾¡ã®è‡ªå‹•ç®—å‡ºï¼ˆDBéä¾å­˜ï¼‰========================

# === helperï¼ˆç„¡ã‘ã‚Œã°è¿½è¨˜ï¼‰ ===
def _clamp(x, lo, hi):
    try:
        x = float(x)
    except Exception:
        return lo
    return max(lo, min(hi, x))

def _to_float_safe(d, key, default=None):
    try:
        v = d.get(key, None)
        if v is None or (isinstance(v, str) and not v.strip()):
            return default
        return float(str(v).replace('%',''))
    except Exception:
        return default

# === æ¨å¥¨ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆç½®æ›ï¼‰ ===
def _derive_recommendation(d: dict):
    """
    é€£ç¶šæ¯”ç‡ï¼ˆ0ã€œ1ï¼‰ã‚’ä½œã‚Šã€UI/é‹ç”¨ã¯é›¢æ•£ãƒãƒ³ãƒ‰ï¼ˆ1.0/0.75/0.5/0.25/â€”ï¼‰ã§å®‰å®šåŒ–ã€‚
    ãƒ»æ¯”ç‡ã¯ compï¼ˆåˆæˆã‚¹ã‚³ã‚¢ï¼‰ã‚’ä¸­æ ¸ã«ã€æµå‹•æ€§ã¨ä¸Šæ˜‡ç‡ã§è£œæ­£
    ãƒ»å¢ƒç•Œä»˜è¿‘ã¯ãƒ’ã‚¹ãƒ†ãƒªã‚·ã‚¹ï¼ˆÂ±0.02ï¼‰ã§ãƒ•ãƒªãƒƒãƒ—æŠ‘åˆ¶
    è¿”ã‚Šå€¤: (label:str or "", ratio_band:float or None, ratio_raw:float or None)
    """
    # å‚ç…§å€¤ã®å–å¾—
    comp = _to_float_safe(d, "åˆæˆã‚¹ã‚³ã‚¢", None)           # 0ã€œ100æƒ³å®š
    rvol = _to_float_safe(d, "RVOL_å£²è²·ä»£é‡‘", None)        # â‰¥2ãŒç›®å®‰
    turn = _to_float_safe(d, "å£²è²·ä»£é‡‘(å„„)", None)         # â‰¥5ãŒç›®å®‰
    rate = _to_float_safe(d, "å‰æ—¥çµ‚å€¤æ¯”ç‡ï¼ˆï¼…ï¼‰", None)    # ä¸Šæ˜‡ç‡ï¼ˆï¼…ï¼‰

    # å€™è£œãƒ•ãƒ©ã‚°ï¼ˆã©ã‚Œã‹ä¸€ã¤ã§ã‚‚ã€Œå€™è£œã€ï¼‰
    flags = [
        str(d.get("å³è‚©æ—©æœŸãƒ•ãƒ©ã‚°", "") or "").strip(),
        str(d.get("å³è‚©ä¸ŠãŒã‚Šãƒ•ãƒ©ã‚°", "") or "").strip(),
        str(d.get("åˆå‹•ãƒ•ãƒ©ã‚°", "") or "").strip(),
    ]
    is_setup = any(f == "å€™è£œ" for f in flags)

    # é€£ç¶šåŒ–ï¼šåˆæˆS=65â†’0.0, 100â†’1.0ï¼ˆä¸‹é§„ãƒ»ä¸Šé™ä»˜ãï¼‰
    if comp is None:
        return ("", None, None)
    ratio = _clamp((comp - 65.0) / 35.0, 0.0, 1.0)

    # æµå‹•æ€§è£œæ­£ï¼ˆæº€ãŸãªã„å ´åˆã¯æ¸›ç‚¹æ–¹å¼ï¼‰
    if rvol is not None and rvol < 2.0:
        ratio *= 0.7
    if turn is not None and turn < 5.0:
        ratio *= 0.8

    # ä¸Šæ˜‡ç‡ãƒ¬ãƒ³ã‚¸è£œæ­£ï¼ˆå°å£ãƒ¬ãƒ³ã‚¸å¤–ã¯æ¸›ç‚¹ã€æœ‰åŠ›ãƒ¬ãƒ³ã‚¸ã¯å¾®åŠ ç‚¹ï¼‰
    if rate is not None:
        if 0.0 <= rate <= 2.0:
            ratio = min(1.0, ratio * 1.10)   # æœ‰åŠ›ãƒ¬ãƒ³ã‚¸å¾®ãƒ–ãƒ¼ã‚¹ãƒˆ
        elif -2.0 <= rate <= 3.0:
            pass                              # å°å£ãƒ¬ãƒ³ã‚¸ï¼è£œæ­£ãªã—
        else:
            ratio *= 0.6                      # ãƒ¬ãƒ³ã‚¸å¤–ã¯æ¸›ç‚¹

    # å€™è£œã§ãªã„å ´åˆã¯å¼±ã‚æ‰±ã„ï¼ˆå®Œå…¨ã«ã‚¼ãƒ­ã«ã›ãšã€ã‚ãšã‹ã«æ®‹ã™é¸æŠã‚‚å¯èƒ½ï¼‰
    if not is_setup:
        ratio *= 0.5

    ratio = _clamp(ratio, 0.0, 1.0)
    ratio_raw = ratio  # ç”Ÿå€¤ã‚’ä¿æŒ

    # ===== ãƒãƒ³ãƒ‰åˆ†ã‘ï¼ˆUI/é‹ç”¨å‘ã‘ï¼‰ï¼‹ãƒ’ã‚¹ãƒ†ãƒªã‚·ã‚¹ =====
    # ç›´è¿‘ã® raw ãŒ dict ã«ã‚ã‚Œã°å–å¾—ï¼ˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰å´ã§å‰å›å€¤ã‚’å…¥ã‚Œã¦ãã‚Œã¦ã„ã‚Œã°ç²˜ã‚ŠãŒåŠ¹ãï¼‰
    prev_raw = _to_float_safe(d, "æ¨å¥¨æ¯”ç‡_raw", None)

    # ãƒãƒ³ãƒ‰ï¼ˆä¸‹é™ã—ãã„å€¤, ãƒ©ãƒ™ãƒ«, è¡¨ç¤ºå€ç‡ï¼‰
    BANDS = [
        (0.88, "ã‚¨ãƒ³ãƒˆãƒªãƒ¼æœ‰åŠ›", 1.00),
        (0.63, "ä¸­å¼·åº¦",        0.75),
        (0.38, "å°å£ææ¡ˆ",      0.50),
        (0.13, "å¾®å°å£",        0.25),
    ]
    EPS = 0.02  # ãƒ’ã‚¹ãƒ†ãƒªã‚·ã‚¹å¹…

    def _band_index(val):
        for i, (thr, _, _) in enumerate(BANDS):
            if val >= thr:
                return i
        return None

    cand_idx = _band_index(ratio)
    prev_idx = _band_index(prev_raw) if prev_raw is not None else None

    # ãƒ’ã‚¹ãƒ†ãƒªã‚·ã‚¹ï¼šå¢ƒç•ŒÂ±EPSã§å‰å›ãƒãƒ³ãƒ‰ã‚’ç¶­æŒ
    if prev_idx is not None and cand_idx is not None:
        # ä¸Šæ–¹å‘é·ç§»ã®ã¨ãã¯ â€œthr + EPSâ€ ã¾ã§åˆ°é”ã—ãªã„é™ã‚Šæ®ãˆç½®ã
        if cand_idx < prev_idx:
            thr_up = BANDS[cand_idx][0]
            if ratio < (thr_up + EPS):
                cand_idx = prev_idx
        # ä¸‹æ–¹å‘é·ç§»ã®ã¨ãã¯ â€œprev_thr - EPSâ€ ã‚’å‰²ã‚‹ã¾ã§æ®ãˆç½®ã
        elif cand_idx > prev_idx:
            prev_thr = BANDS[prev_idx][0]
            if ratio >= (prev_thr - EPS):
                cand_idx = prev_idx

    # ãƒãƒ³ãƒ‰æ±ºå®š
    if cand_idx is None:
        # ã—ãã„å€¤æœªæº€ã¯ã€Œç©ºæ¬„ã€
        return ("", None, ratio_raw)
    label, ratio_band = BANDS[cand_idx][1], BANDS[cand_idx][2]

    return (label, ratio_band, ratio_raw)

def _derive_opratio_flag(d, threshold_pct: float = 10.0) -> str:
    """
    å–¶æ¥­åˆ©ç›Š / æ™‚ä¾¡ç·é¡(å„„å††) * 100 >= threshold_pct ãªã‚‰ "1"ã€ãã‚Œä»¥å¤–ã¯ "0"
    â€»ã©ã¡ã‚‰ã‹æ¬ æ/0 ã®ã¨ãã‚‚ "0"
    """
    op   = _to_float(d.get("å–¶æ¥­åˆ©ç›Š"))
    mcap = _to_float(d.get("æ™‚ä¾¡ç·é¡å„„å††"))
    if op is None or mcap in (None, 0):
        return "0"
    ratio_pct = (op / mcap) * 100.0
    return "1" if ratio_pct >= threshold_pct else "0"
# =======================================================================

# ---------- è¡Œæ•´å½¢ï¼ˆæ¬ æå®‰å…¨ & å¤–éƒ¨åˆ—ã«ä¾å­˜ã—ãªã„ï¼‰ ----------
def _prepare_rows(df: pd.DataFrame):
    rows = []
    for _, r in df.iterrows():
        d = {k: (None if (isinstance(r.get(k), float) and math.isnan(r.get(k))) else r.get(k)) for k in df.columns}

        # ã‚³ãƒ¼ãƒ‰/éŠ˜æŸ„
        if "ã‚³ãƒ¼ãƒ‰" in d: d["ã‚³ãƒ¼ãƒ‰"] = str(d.get("ã‚³ãƒ¼ãƒ‰") or "").zfill(4)
        if "éŠ˜æŸ„å" in d: d["éŠ˜æŸ„å"] = str(d.get("éŠ˜æŸ„å") or "")

        # Yahoo / X
        code4 = (d.get("ã‚³ãƒ¼ãƒ‰") or "").zfill(4)
        d["yahoo_url"] = f"https://finance.yahoo.co.jp/quote/{code4}.T" if code4 else ""
        d["x_url"]  = f"https://x.com/search?q={_q(d.get('éŠ˜æŸ„å') or '')}" if d.get("éŠ˜æŸ„å") else ""

        # å£²è²·ä»£é‡‘(å„„) è£œå®Œ
        if d.get("å£²è²·ä»£é‡‘(å„„)") is None:
            fv=_to_float(d.get("ç¾åœ¨å€¤")); fvol=_to_float(d.get("å‡ºæ¥é«˜"))
            if fv is not None and fvol is not None:
                d["å£²è²·ä»£é‡‘(å„„)"] = fv * fvol / 1e8

        # RVOLä»£é‡‘ è£œå®Œ
        fturn=_to_float(d.get("å£²è²·ä»£é‡‘(å„„)"))
        favg20=_to_float(d.get("å£²è²·ä»£é‡‘20æ—¥å¹³å‡å„„"))
        if d.get("RVOLä»£é‡‘") is None and (fturn is not None) and (favg20 and favg20!=0):
            d["RVOLä»£é‡‘"] = fturn / favg20

        # å‰æ—¥æ¯” è£œå®Œ
        now_=_to_float(d.get("ç¾åœ¨å€¤")); prev_=_to_float(d.get("å‰æ—¥çµ‚å€¤"))
        if d.get("å‰æ—¥å††å·®") is None and (now_ is not None and prev_ is not None):
            d["å‰æ—¥å††å·®"] = now_ - prev_
        if d.get("å‰æ—¥çµ‚å€¤æ¯”ç‡") is None and (now_ is not None and prev_ not in (None,0)):
            d["å‰æ—¥çµ‚å€¤æ¯”ç‡"] = (now_/prev_ - 1.0) * 100.0

        # ç¾åœ¨å€¤ raw
        cv = _to_float(d.get("ç¾åœ¨å€¤"))
        d["ç¾åœ¨å€¤_raw"] = cv if cv is not None else ""

        # å‰æ—¥çµ‚å€¤æ¯”ç‡ rawï¼ˆã€Œå‰æ—¥çµ‚å€¤æ¯”ç‡ï¼ˆï¼…ï¼‰ã€ã¨ã„ã†åˆ—åã®æºã‚Œã«ã‚‚å¯¾å¿œï¼‰
        pct_val = d.get("å‰æ—¥çµ‚å€¤æ¯”ç‡")
        if pct_val is None:
            pct_val = d.get("å‰æ—¥çµ‚å€¤æ¯”ç‡ï¼ˆï¼…ï¼‰")
        pctf = _to_float(pct_val)
        d["å‰æ—¥çµ‚å€¤æ¯”ç‡_raw"] = pctf if pctf is not None else ""

        # è¡¨ç¤ºã¯ï¼…æ–‡å­—åˆ—ã«çµ±ä¸€ï¼ˆrawã¯æ•°å€¤ã®ã¾ã¾æ®‹ã™ï¼‰
        if pctf is not None:
            d["å‰æ—¥çµ‚å€¤æ¯”ç‡"] = f"{round(float(pctf), 2)}%"

        # ä»˜åŠ ãƒ•ãƒ©ã‚°
        d["ç©ºå£²ã‚Šæ©Ÿé–¢ãªã—_flag"] = _noshor_from_agency(d.get("ç©ºå£²ã‚Šæ©Ÿé–¢"))
        d["å–¶åˆ©å¯¾æ™‚ä¾¡_flag"]     = _op_ratio_flag(d)  # â† ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ç”¨ï¼ˆå‰²å®‰ï¼‰

        # åˆ¤å®š/ç†ç”±
        pct = _to_float(d.get("å‰æ—¥çµ‚å€¤æ¯”ç‡"))
        d["åˆ¤å®š"] = "å½“ãŸã‚Šï¼" if (pct is not None and pct > 0) else ""
        d["åˆ¤å®šç†ç”±"] = _build_reason(d)
        
        # --- æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼æ¨å¥¨æ¯”ç‡ï¼ˆé€£ç¶šï¼†ãƒãƒ³ãƒ‰ï¼‰ ---
        rec, ratio_band, ratio_raw = _derive_recommendation(d)

        # è¡¨ç¤ºåˆ—ï¼šï¼…ã¯è¦‹ãŸç›®ã€raw ã¯å¾Œç¶šã®ãƒ’ã‚¹ãƒ†ãƒªã‚·ã‚¹ç¶­æŒã«ä½¿ãˆã‚‹
        if rec:
            d["æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"] = rec
        else:
            d["æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"] = d.get("æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³", "") or ""

        d["æ¨å¥¨æ¯”ç‡_raw"] = ratio_raw if ratio_raw is not None else d.get("æ¨å¥¨æ¯”ç‡_raw", "")

        # UIè¡¨ç¤ºã¯ãƒãƒ³ãƒ‰å€¤ã‚’ï¼…ã«ï¼ˆNone ã¯ç©ºç™½ï¼‰
        if ratio_band is None:
            d["æ¨å¥¨æ¯”ç‡"] = ""
        else:
            d["æ¨å¥¨æ¯”ç‡"] = f"{int(round(float(ratio_band)*100))}%"

        # --- å–¶åˆ©å¯¾æ™‚ä¾¡_flagï¼ˆDBåˆ—ãŒç„¡ã„/ç©ºãªã‚‰å°å‡ºï¼‰ ---
        if not (d.get("å–¶åˆ©å¯¾æ™‚ä¾¡_flag") or "").strip():
            d["å–¶åˆ©å¯¾æ™‚ä¾¡_flag"] = _derive_opratio_flag(d)

        # å¿µã®ãŸã‚ï¼šç©ºå£²ã‚Šæ©Ÿé–¢ãªã—_flag ã‚’ç¶­æŒ
        d["ç©ºå£²ã‚Šæ©Ÿé–¢ãªã—_flag"] = _noshor_from_agency(d.get("ç©ºå£²ã‚Šæ©Ÿé–¢"))

        rows.append(d)
    return rows

# =================== HTMLãƒ†ãƒ³ãƒ—ãƒ¬ ===================

# =================== HTMLãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ä¿å­˜ ===================
def _ensure_template_file(template_dir: str, overwrite=True):
    os.makedirs(template_dir, exist_ok=True)
    path = os.path.join(template_dir, "dashboard.html")
    if overwrite or not os.path.exists(path):
        with open(path, "w", encoding="utf-8") as f:
            f.write(DASH_TEMPLATE_STR)
    return path

# =================== ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ›¸ãå‡ºã—ï¼ˆå®Œå…¨ç‰ˆï¼‰ ===================
def _load_offering_codes_from_db(conn, days=400):
    """
    offerings_events ã‹ã‚‰ç›´è¿‘ days æ—¥ã®å¢—è³‡/è¡Œä½¿/å£²å‡º/CB/EB ãªã©ã®å±¥æ­´ãŒã‚ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’é›†åˆã§è¿”ã™ã€‚
    ç„¡ã‘ã‚Œã°ç©ºé›†åˆã€‚
    """
    try:
        cur = conn.cursor()
        cur.execute(
            "SELECT DISTINCT printf('%04d', CAST(ã‚³ãƒ¼ãƒ‰ AS INTEGER)) "
            "FROM offerings_events WHERE date(æå‡ºæ™‚åˆ») >= date('now', ?)",
            (f"-{days} day",)
        )
        return {r[0] for r in cur.fetchall() if r and r[0]}
    except Exception:
        return set()

def phase_export_html_dashboard_offline(conn, html_path, template_dir="templates",
                                        include_log: bool=False, log_limit: int=2000):
    """
    ãƒ»å€™è£œ/å…¨ã‚«ãƒ©ãƒ /ï¼ˆä»»æ„ï¼‰signals_log ã‚’ 1ãƒ•ã‚¡ã‚¤ãƒ«HTMLã§å‡ºåŠ›
    ãƒ»è¡¨æç”»ã¯ãƒ•ãƒ­ãƒ³ãƒˆå´JSã€‚ã“ã“ã§ã¯ â€œJSONã‚’ __DATA__ ã«ç›´åŸ‹ã‚â€ ã™ã‚‹
    ãƒ»DBã«å­˜åœ¨ã—ãªã„åˆ—ï¼ˆæ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç­‰ï¼‰ã¯å‚ç…§ã—ãªã„ã®ã§ã€DBå·®ç•°ã§ã‚‚è½ã¡ãªã„
    """

    # ---------- 1) DBã‹ã‚‰å€™è£œç”¨ã®å¿…è¦æœ€å°åˆ—ã ã‘å–å¾—ï¼ˆå­˜åœ¨ã—ãªã„åˆ—ã¯è§¦ã‚‰ãªã„ï¼‰ ----------
    df_cand = pd.read_sql_query("""
      SELECT
        ã‚³ãƒ¼ãƒ‰, éŠ˜æŸ„å,å¸‚å ´,
        ç¾åœ¨å€¤,
        "å‰æ—¥çµ‚å€¤" AS å‰æ—¥çµ‚å€¤,
        "å‰æ—¥å††å·®" AS "å‰æ—¥å††å·®",
        å‰æ—¥çµ‚å€¤æ¯”ç‡,
        å‡ºæ¥é«˜, æ™‚ä¾¡ç·é¡å„„å††,
        COALESCE(
          å£²è²·ä»£é‡‘å„„,
          CASE WHEN ç¾åœ¨å€¤ IS NOT NULL AND å‡ºæ¥é«˜ IS NOT NULL
               THEN (ç¾åœ¨å€¤ * å‡ºæ¥é«˜) / 100000000.0 END
        ) AS "å£²è²·ä»£é‡‘(å„„)",
        å£²è²·ä»£é‡‘20æ—¥å¹³å‡å„„,
        RVOLä»£é‡‘,
        åˆæˆã‚¹ã‚³ã‚¢,
        ATR14_PCT AS "ATR14%",
        åˆå‹•ãƒ•ãƒ©ã‚°, åˆå‹•é–‹å§‹æ—¥,
        åº•æ‰“ã¡ãƒ•ãƒ©ã‚°, åº•æ‰“ã¡é–‹å§‹æ—¥,
        å³è‚©ä¸ŠãŒã‚Šãƒ•ãƒ©ã‚°, å³è‚©é–‹å§‹æ—¥,
        å³è‚©æ—©æœŸãƒ•ãƒ©ã‚°, å³è‚©æ—©æœŸé–‹å§‹æ—¥,
        å³è‚©æ—©æœŸç¨®åˆ¥, å³è‚©æ—©æœŸç¨®åˆ¥é–‹å§‹æ—¥, å³è‚©æ—©æœŸå‰å›ç¨®åˆ¥,
        å³è‚©æ—©æœŸã‚¹ã‚³ã‚¢,
        ç©ºå£²ã‚Šæ©Ÿé–¢,
        ã‚·ã‚°ãƒŠãƒ«æ›´æ–°æ—¥,
        å–¶æ¥­åˆ©ç›Š,
        å¢—è³‡ãƒªã‚¹ã‚¯, å¢—è³‡ã‚¹ã‚³ã‚¢, å¢—è³‡ç†ç”±,è²¡å‹™ã‚³ãƒ¡ãƒ³ãƒˆ
      FROM screener
      ORDER BY COALESCE(æ™‚ä¾¡ç·é¡å„„å††,0) DESC, COALESCE(å‡ºæ¥é«˜,0) DESC, ã‚³ãƒ¼ãƒ‰
    """, conn)

    # å…¨ã‚«ãƒ©ãƒ ã‚¿ãƒ–ã¯ç´ ç›´ã«å…¨ä»¶ï¼ˆDBå·®ç•°ã‚’å¸åã—ãŸã„ã®ã§ * ã§OKï¼‰
    df_all = pd.read_sql_query("""
      SELECT * FROM screener
      ORDER BY COALESCE(æ™‚ä¾¡ç·é¡å„„å††,0) DESC, COALESCE(å‡ºæ¥é«˜,0) DESC, ã‚³ãƒ¼ãƒ‰
    """, conn)
    
    
    # === å°æ•°ç‚¹ç¬¬2ä½ã§æ•°å€¤å‹ã®ã¾ã¾çµ±ä¸€ï¼ˆå€™è£œä¸€è¦§ / æ˜æ—¥ç”¨ / å…¨ã‚«ãƒ©ãƒ ï¼‰===
    def _round2_inplace(df):
        if df is None or df.empty:
            return

        # 2æ¡ä¸¸ã‚å¯¾è±¡ã®ã‚«ãƒ©ãƒ é›†åˆï¼ˆå­˜åœ¨ã™ã‚‹ã‚‚ã®ã ã‘å‡¦ç†ï¼‰
        percent_cols = [
            "å‰æ—¥çµ‚å€¤æ¯”ç‡", "å‰æ—¥çµ‚å€¤æ¯”ç‡ï¼ˆï¼…ï¼‰",
            "ãƒ•ã‚©ãƒ­ãƒ¼é«˜å€¤pct", "æœ€å¤§é€†è¡Œpct", "ãƒªã‚¿ãƒ¼ãƒ³çµ‚å€¤pct",
            "æ¨å¥¨æ¯”ç‡", "ATR14%"
        ]
        money_cols = [
            "å£²è²·ä»£é‡‘(å„„)", "å£²è²·ä»£é‡‘å„„",          # ãƒ†ãƒ³ãƒ—ãƒ¬ç”¨ã®åˆ¥å/DBå®Ÿä½“ã®ä¸¡å¯¾å¿œ
            "å£²è²·ä»£é‡‘20æ—¥å¹³å‡å„„", "RVOLä»£é‡‘",
            "æ™‚ä¾¡ç·é¡å„„å††"
        ]
        price_cols = [
            "ç¾åœ¨å€¤", "å‰æ—¥çµ‚å€¤", "å‰æ—¥å††å·®",      # Yahooç”±æ¥ã§ãƒ–ãƒ¬ã‚„ã™ã„
            # å…¨ã‚«ãƒ©ãƒ ã‚¿ãƒ–ã«æ··ã–ã‚‹å¯èƒ½æ€§ã‚’è€ƒæ…®ï¼ˆå­˜åœ¨ã™ã‚Œã°ä¸¸ã‚ã‚‹ï¼‰
            "å§‹å€¤", "é«˜å€¤", "å®‰å€¤", "çµ‚å€¤"
        ]
        score_cols = [
            "å³è‚©æ—©æœŸã‚¹ã‚³ã‚¢", "åˆæˆã‚¹ã‚³ã‚¢"
        ]

        # ãƒ©ã‚¦ãƒ³ãƒ‰å¯¾è±¡ã‚’ä¸€æ‹¬ã§2æ¡ã«çµ±ä¸€
        targets = percent_cols + money_cols + price_cols + score_cols
        for col in targets:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors="coerce").round(2)

    _round2_inplace(df_cand)
    _round2_inplace(df_all)

    # ãƒ­ã‚°ï¼ˆä»»æ„ï¼‰
    if include_log:
        try:
            df_log = pd.read_sql_query(
                f"SELECT æ—¥æ™‚, ã‚³ãƒ¼ãƒ‰, ç¨®åˆ¥, è©³ç´° FROM signals_log ORDER BY æ—¥æ™‚ DESC, ã‚³ãƒ¼ãƒ‰ LIMIT {int(log_limit)}",
                conn
            )
        except Exception:
            df_log = pd.DataFrame(columns=["æ—¥æ™‚","ã‚³ãƒ¼ãƒ‰","ç¨®åˆ¥","è©³ç´°"])
    else:
        df_log = pd.DataFrame(columns=["æ—¥æ™‚","ã‚³ãƒ¼ãƒ‰","ç¨®åˆ¥","è©³ç´°"])

    # ---------- 2) å€™è£œä¸€è¦§ã®ã‚»ãƒ«å†…è£œè¶³ï¼ˆâ€œåˆ—ã‚’å¢—ã‚„ã•ãšâ€ ãƒ•ãƒ©ã‚°ã«æ—¥ä»˜ãªã©å°ã•ãè¿½è¨˜ï¼‰ ----------
    def _mini(text):
        if not text:
            return ""
        # æ”¹è¡Œ(<br>)ã¯ã‚„ã‚ã¦åŒä¸€è¡Œã«å°ã•ãè¿½è¨˜
        return f"&nbsp;<span class='mini'>{text}</span>"

    def _flag_with_since(flag, since):
        flag = (flag or "").strip()
        if flag == "å€™è£œ" and since:
            return f"{flag}{_mini(f'{since}ã€œ')}"
        return flag

    def _early_kind_mini(since_kind, prev_kind):
        extras = []
        if since_kind:
            extras.append(f"{since_kind}ã€œ")
        if prev_kind:
            extras.append(f"prev: {prev_kind}")
        return _mini(" / ".join(extras)) if extras else ""

    if not df_cand.empty:
        df_cand["åˆå‹•ãƒ•ãƒ©ã‚°"]       = df_cand.apply(lambda r: _flag_with_since(r.get("åˆå‹•ãƒ•ãƒ©ã‚°"), r.get("åˆå‹•é–‹å§‹æ—¥")), axis=1)
        df_cand["åº•æ‰“ã¡ãƒ•ãƒ©ã‚°"]     = df_cand.apply(lambda r: _flag_with_since(r.get("åº•æ‰“ã¡ãƒ•ãƒ©ã‚°"), r.get("åº•æ‰“ã¡é–‹å§‹æ—¥")), axis=1)
        df_cand["å³è‚©ä¸ŠãŒã‚Šãƒ•ãƒ©ã‚°"] = df_cand.apply(lambda r: _flag_with_since(r.get("å³è‚©ä¸ŠãŒã‚Šãƒ•ãƒ©ã‚°"), r.get("å³è‚©é–‹å§‹æ—¥")), axis=1)
        df_cand["å³è‚©æ—©æœŸãƒ•ãƒ©ã‚°"]   = df_cand.apply(lambda r: _flag_with_since(r.get("å³è‚©æ—©æœŸãƒ•ãƒ©ã‚°"), r.get("å³è‚©æ—©æœŸé–‹å§‹æ—¥")), axis=1)
        # æ—©æœŸç¨®åˆ¥ã‚»ãƒ«ã®ä¸‹æ®µè£œè¶³ï¼ˆæœ¬ä½“ã®ç¨®åˆ¥æ–‡å­—åˆ—ã¯ãã®ã¾ã¾ï¼‰
        df_cand["å³è‚©æ—©æœŸç¨®åˆ¥_mini"] = df_cand.apply(
            lambda r: _early_kind_mini(r.get("å³è‚©æ—©æœŸç¨®åˆ¥é–‹å§‹æ—¥"), r.get("å³è‚©æ—©æœŸå‰å›ç¨®åˆ¥"))
                      if (r.get("å³è‚©æ—©æœŸç¨®åˆ¥") or "").strip() else "",
            axis=1
        )
        # è£œåŠ©åˆ—ã¯å€™è£œãƒ†ãƒ¼ãƒ–ãƒ«ã«ã¯å‡ºã•ãªã„
        for c in ["åˆå‹•é–‹å§‹æ—¥","åº•æ‰“ã¡é–‹å§‹æ—¥","å³è‚©é–‹å§‹æ—¥","å³è‚©æ—©æœŸé–‹å§‹æ—¥","å³è‚©æ—©æœŸç¨®åˆ¥é–‹å§‹æ—¥","å³è‚©æ—©æœŸå‰å›ç¨®åˆ¥"]:
            if c in df_cand.columns:
                df_cand.drop(columns=[c], inplace=True)

    # ---------- 3) Pythonè¾æ›¸åŒ–ï¼ˆNaN/npå‹/æ—¥ä»˜ãªã©ã¯ _safe_jsonable ã§ä¸¸ã‚ã‚‹ï¼‰ ----------
    def _records_safe(df: pd.DataFrame):
        out = []
        for rec in df.to_dict("records"):
            out.append({k: _safe_jsonable(v) for k, v in rec.items()})
        return out

    # URLåˆ—ãªã©ã®è£œå®Œã¯ _prepare_rows ã«ä»»ã›ã‚‹ï¼ˆåˆ¤å®šãƒ»ç†ç”±ãƒ»Yahoo/Xç­‰ã®ç”Ÿæˆã‚‚å«ã‚€ï¼‰
    cand_rows = _prepare_rows(df_cand) if not df_cand.empty else []
    n_strong = sum(1 for r in cand_rows if r.get("æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³") == "ã‚¨ãƒ³ãƒˆãƒªãƒ¼æœ‰åŠ›")
    n_small  = sum(1 for r in cand_rows if r.get("æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³") == "å°å£ææ¡ˆ")
    print(f"[recommend] æœ‰åŠ›:{n_strong} / å°å£:{n_small}")

    all_rows  = _prepare_rows(df_all)  if not df_all.empty  else []
    log_rows  = df_log.to_dict("records") if include_log else []

    # ãã®ã¾ã¾ã ã¨ numpy ã‚¹ã‚«ãƒ©ãƒ¼ãŒæ··ã˜ã‚‹ã®ã§å†åº¦ safe åŒ–
    cand_rows = _records_safe(pd.DataFrame(cand_rows)) if cand_rows else []
    all_rows  = _records_safe(pd.DataFrame(all_rows))  if all_rows  else []
    log_rows  = _records_safe(pd.DataFrame(log_rows))  if log_rows  else []

    # --- meta: DBã®æœ€æ–°ã‚·ã‚°ãƒŠãƒ«æ›´æ–°æ—¥ã‹ã‚‰ç¿Œå–¶æ¥­æ—¥ã‚’ä½œã‚‹ï¼ˆç¥æ—¥/åœŸæ—¥è£œæ­£ï¼‰ ---

    def _to_date10(s):
        s = str(s or '')[:10]
        try:
            return dtm.datetime.strptime(s, "%Y-%m-%d").date()
        except Exception:
            return None

    # cand_rows ã¯ç›´å‰ã§ _records_safe æ¸ˆã¿ã® list[dict]
    _base = None
    if cand_rows:
        try:
            dates = [_to_date10(r.get("ã‚·ã‚°ãƒŠãƒ«æ›´æ–°æ—¥")) for r in cand_rows]
            dates = [d for d in dates if d]
            _base = max(dates) if dates else None
        except Exception:
            _base = None

    meta = {"base_day": None, "next_business_day": None}
    if _base:
        meta["base_day"] = _base.strftime("%Y-%m-%d")
        # æ—¢å­˜ã®ç¥æ—¥/ä¼‘å ´ãƒ­ã‚¸ãƒƒã‚¯ã‚’åˆ©ç”¨
        _next = next_business_day_jp(_base)
        meta["next_business_day"] = _next.strftime("%Y-%m-%d")

    # ---------- 4) JSON ã‚’ __DATA__ ã«ç›´åŸ‹ã‚ ----------
    # --- ç¥æ—¥/åœŸæ—¥è£œæ­£ï¼šç¿Œå–¶æ¥­æ—¥ã‚’ JSON(meta) ã«åŸ‹ã‚è¾¼ã‚€ ---

    try:
        import jpholiday
        def _is_holiday(d: dtm.date) -> bool:
            return (d.weekday() >= 5) or jpholiday.is_holiday(d)
    except Exception:
        # jpholiday ãŒç„¡ã„ç’°å¢ƒã§ã¯åœŸæ—¥ã®ã¿è£œæ­£
        def _is_holiday(d: dtm.date) -> bool:
            return d.weekday() >= 5

    def _to_date(s) -> dtm.date | None:
        if not s:
            return None
        s = str(s)[:10]  # "YYYY-MM-DD ..." å½¢å¼ã«ã‚‚å¯¾å¿œ
        try:
            return dtm.datetime.strptime(s, "%Y-%m-%d").date()
        except ValueError:
            return None

    def _latest_update_day(rows) -> dtm.date | None:
        try:
            if hasattr(rows, "iterrows"):  # pandas.DataFrame
                dates = [_to_date(r.get("ã‚·ã‚°ãƒŠãƒ«æ›´æ–°æ—¥")) for _, r in rows.iterrows()]
            else:                           # list[dict]
                dates = [_to_date(r.get("ã‚·ã‚°ãƒŠãƒ«æ›´æ–°æ—¥")) for r in rows]
            dates = [d for d in dates if d]
            return max(dates) if dates else None
        except Exception:
            return None

    def _next_business_day(d: dtm.date) -> dtm.date:
        d = d + dtm.timedelta(days=1)
        while _is_holiday(d):
            d += dtm.timedelta(days=1)
        return d

    _base = _latest_update_day(cand_rows)  # â† cand_rows ã¯æ—¢å­˜ã®å€™è£œãƒªã‚¹ãƒˆ/DF
    meta = {"base_day": None, "next_business_day": None}
    if _base:
        _next = _next_business_day(_base)
        meta["base_day"] = _base.strftime("%Y-%m-%d")
        meta["next_business_day"] = _next.strftime("%Y-%m-%d")

    # ---------- 4) JSON ã‚’ __DATA__ ã«ç›´åŸ‹ã‚ ----------
    
    # ç›´è¿‘30å–¶æ¥­æ—¥ã®ã€Œã‚³ãƒ¼ãƒ‰ãƒ»æ—¥ä»˜ãƒ»åˆ¤å®šã€ã‚’ hist ã¨ã—ã¦ä»˜ä¸ï¼ˆç„¡ã‘ã‚Œã°ç©ºã§OKï¼‰
    # signals_bg ã‹ã‚‰ç›´è¿‘ã®éŠ˜æŸ„åˆ¥ãƒ»æ—¥æ¬¡åˆ¤å®šã‚’å–ã‚‹ç‰ˆ
    def _build_hist_rows():

        # cand ã®éŠ˜æŸ„ã¨æœ€çµ‚æ—¥ã‚’åŸºæº–ã«æœŸé–“ã‚’æ±ºã‚ã‚‹
        codes = sorted({ r.get("ã‚³ãƒ¼ãƒ‰") for r in cand_rows if r.get("ã‚³ãƒ¼ãƒ‰") })
        if not codes:
            return []

        try:
            last_day = max(pd.to_datetime([r.get("ã‚·ã‚°ãƒŠãƒ«æ›´æ–°æ—¥") for r in cand_rows
                                           if r.get("ã‚·ã‚°ãƒŠãƒ«æ›´æ–°æ—¥")])).normalize()
        except Exception:
            last_day = pd.Timestamp.today().normalize()
        start_day = last_day - pd.tseries.offsets.BDay(60)  # ç›´è¿‘60å–¶æ¥­æ—¥ã¶ã‚“

        # --- ã“ã“ã‹ã‚‰ä¿®æ­£ï¼šIN (:codes) ã‚’ qmarks ã«å±•é–‹ã—ã¦æ¸¡ã™ ---
        # â€» codes ãŒå¤šã™ãã‚‹ã¨ SQLite ã®å¤‰æ•°ä¸Šé™ï¼ˆæ—¢å®š 999ï¼‰ã«è§¦ã‚Œã‚‹ã®ã§å®‰å…¨å´ã§åˆ†å‰²
        def _fetch_chunk(chunk):
            qmarks = ",".join("?" * len(chunk))
            sql = f"""
                SELECT
                  ã‚³ãƒ¼ãƒ‰,
                  DATE(æ—¥æ™‚) AS ã‚·ã‚°ãƒŠãƒ«æ›´æ–°æ—¥,
                  åˆ¤å®š,
                  ãƒ•ã‚©ãƒ­ãƒ¼é«˜å€¤pct,
                  æœ€å¤§é€†è¡Œpct,
                  ãƒªã‚¿ãƒ¼ãƒ³çµ‚å€¤pct
                FROM signals_log
                WHERE DATE(æ—¥æ™‚) BETWEEN ? AND ?
                  AND ã‚³ãƒ¼ãƒ‰ IN ({qmarks})
            """
            params = [str(start_day.date()), str(last_day.date()), *chunk]
            return pd.read_sql_query(sql, conn, params=params)

        dfs = []
        MAX_VARS = 900  # ä½™è£•ã‚’è¦‹ã¦ 900
        for i in range(0, len(codes), MAX_VARS):
            dfs.append(_fetch_chunk(codes[i:i+MAX_VARS]))
        df = pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame(columns=["ã‚³ãƒ¼ãƒ‰","ã‚·ã‚°ãƒŠãƒ«æ›´æ–°æ—¥","åˆ¤å®š"])

        if df.empty:
            return []

        # åˆ¤å®š æ­£è¦åŒ–
        def _norm_hit(row):
            s = str(row.get("åˆ¤å®š") or "").strip()
            if "å½“ãŸã‚Š" in s: return "å½“ãŸã‚Šï¼"
            if "å¤–ã‚Œ" in s:   return "å¤–ã‚Œï¼"
            try:
                return "å½“ãŸã‚Šï¼" if float(row.get("ãƒ•ã‚©ãƒ­ãƒ¼é«˜å€¤pct") or 0) > 0 else "å¤–ã‚Œï¼"
            except Exception:
                return "å¤–ã‚Œï¼"

        df["åˆ¤å®š"] = df.apply(_norm_hit, axis=1)
        df["ã‚·ã‚°ãƒŠãƒ«æ›´æ–°æ—¥"] = pd.to_datetime(df["ã‚·ã‚°ãƒŠãƒ«æ›´æ–°æ—¥"]).dt.strftime("%Y-%m-%d")

        hist = df[["ã‚³ãƒ¼ãƒ‰", "ã‚·ã‚°ãƒŠãƒ«æ›´æ–°æ—¥", "åˆ¤å®š"]].dropna().drop_duplicates()
        return hist.sort_values(["ã‚³ãƒ¼ãƒ‰", "ã‚·ã‚°ãƒŠãƒ«æ›´æ–°æ—¥"]).to_dict("records")

    hist_rows = _build_hist_rows()

    # ---- data_obj ã‚’ä½œã‚‹ç›´å‰ï¼ˆã“ã®å¡Šã§OKï¼‰----
    # å®Ÿç¸¾ï¼ˆæ±ºç®—ï¼‰
    try:
        earnings_rows = load_recent_earnings_from_db(DB_PATH, days=7, limit=300)
    except Exception as e:
        print(f"[earnings][WARN] failed to load: {e}")
        earnings_rows = []

    # ---- äºˆæ¸¬ã‚¿ãƒ–ã®è¡Œã‚’çµ„ã¿ç«‹ã¦ï¼ˆ5åˆ—ã‚’è¿½åŠ ã—ã¦JSONåŒ–ï¼‰ ----
    try:
        with open_conn(DB_PATH) as _c:
            tbl = build_earnings_tables(_c)  # (ev_df, pre_df) or {"ev":..., "pre":...} ã©ã¡ã‚‰ã§ã‚‚å¯

            # pre_df ã‚’å–ã‚Šå‡ºã—
            if isinstance(tbl, tuple):
                _, pre_df = tbl
            elif isinstance(tbl, dict):
                pre_df = tbl.get("pre")
            else:
                pre_df = None

            if pre_df is not None and not pre_df.empty:
                # æœ€æ–°çµ‚å€¤ã‚’å–å¾—ï¼ˆscreenerã‹ã‚‰ï¼‰
                px = pd.read_sql_query("SELECT ã‚³ãƒ¼ãƒ‰, ç¾åœ¨å€¤ FROM screener", _c)

                # æœŸå¾…æ ªä¾¡/ä¿®æ­£è¦‹é€šã—/éç†±åº¦/ã‚¹ã‚³ã‚¢ç†ç”±/äºˆæ¸¬ãƒ’ãƒ³ãƒˆã‚’ä½œã‚‹
                df = pre_df.merge(px, on="ã‚³ãƒ¼ãƒ‰", how="left")
                def _row_apply(r):
                    code = str(r.get("ã‚³ãƒ¼ãƒ‰") or "")
                    last = float(r.get("ç¾åœ¨å€¤") or np.nan)
                    mom  = float(r.get("momentum_score") or 0.0)
                    edge = float(r.get("edge_score") or 0.0)
                    return pd.Series({
                        "æœŸå¾…æ ªä¾¡":   calc_expected_price(_c, code, last, mom, edge),
                        "ä¿®æ­£è¦‹é€šã—": classify_revision_bias(edge, mom),
                        "éç†±åº¦":     judge_overheat(_c, code, mom),
                        "ã‚¹ã‚³ã‚¢ç†ç”±": _mk_score_reason(r.to_dict()),
                        "äºˆæ¸¬ãƒ’ãƒ³ãƒˆ": _mk_hint(r.to_dict())
                    })
                extra = df.apply(_row_apply, axis=1)
                df = pd.concat([df, extra], axis=1)
                # --- æ¬ æã®åŸ‹ã‚ï¼†å‹æ•´å½¢ï¼ˆç©ºæ¬„ã«ãªã‚ŠãŒã¡ãªåˆ—ã‚’å¼·åˆ¶çš„ã«åŸ‹ã‚ã‚‹ï¼‰ ---
                df["ã‚¹ã‚³ã‚¢ç†ç”±"] = df["ã‚¹ã‚³ã‚¢ç†ç”±"].fillna("æ ¹æ‹ è–„ã‚ï¼ˆæš«å®šï¼‰")
                df["äºˆæ¸¬ãƒ’ãƒ³ãƒˆ"] = df["äºˆæ¸¬ãƒ’ãƒ³ãƒˆ"].fillna("ï¼ˆæº–å‚™ä¸­ï¼‰")
                df["ä¿®æ­£è¦‹é€šã—"] = df["ä¿®æ­£è¦‹é€šã—"].fillna("ä¸­ç«‹")
                df["éç†±åº¦"]     = df["éç†±åº¦"].fillna("ä¸­ç«‹")
                df["æœŸå¾…æ ªä¾¡"]   = pd.to_numeric(df["æœŸå¾…æ ªä¾¡"], errors="coerce")
                # æœŸå¾…æ ªä¾¡ãŒ NaN ã®ã¨ãã¯ç¾åœ¨å€¤ã§ä»£ç”¨ï¼ˆç©ºæ¬„å›é¿ï¼‰
                if "ç¾åœ¨å€¤" in df.columns:
                    df.loc[df["æœŸå¾…æ ªä¾¡"].isna(), "æœŸå¾…æ ªä¾¡"] = pd.to_numeric(df["ç¾åœ¨å€¤"], errors="coerce")

                # ãƒ•ãƒ­ãƒ³ãƒˆäº’æ›ã®éŠ˜æŸ„å
                if "éŠ˜æŸ„" not in df.columns:
                    names = pd.read_sql_query("SELECT ã‚³ãƒ¼ãƒ‰, éŠ˜æŸ„å FROM screener", _c)
                    df = df.merge(names, on="ã‚³ãƒ¼ãƒ‰", how="left")
                    df["éŠ˜æŸ„"] = df["éŠ˜æŸ„å"].fillna(df["ã‚³ãƒ¼ãƒ‰"])

                # JSONåŒ–
                preearn_rows = [{k: _safe_jsonable(v) for k, v in rec.items()}
                                for rec in df.to_dict("records")]
            else:
                preearn_rows = []
    except Exception as e:
        print(f"[preearn][WARN] failed to build pre-earnings: {e}")
        preearn_rows = []

    
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šç©ºãªã‚‰ screener ã‹ã‚‰æš«å®šãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ç”Ÿæˆ
    if not preearn_rows:
        try:
            preearn_rows = _build_preearn_fallback(_c)
            print(f"[preearn][fallback] generated rows: {len(preearn_rows)}")
        except Exception as _e:
            print(f"[preearn][fallback][WARN] {_e}")
    
    # ---- data_obj æ§‹ç¯‰ ----
    offer_codes = sorted(list(_load_offering_codes_from_db(conn, days=400)))
    data_obj = {
        "cand": cand_rows,
        "all":  all_rows,
        "logs": log_rows,
        "hist": hist_rows,
        "meta": meta,
        "earnings": earnings_rows,
        "preearn": preearn_rows,
        "offer_codes": offer_codes
}
    data_json = json.dumps(data_obj, ensure_ascii=False, default=str, separators=(",", ":"))

    # ---------- 5) ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæç”» ----------
    template_dir = r"H:\desctop\æ ªæ”»ç•¥\1-ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°è‡ªå‹•åŒ–ãƒ—ãƒ­ã‚°ãƒ©ãƒ \templates"
    _ensure_template_file(template_dir, overwrite=True)
    env = Environment(loader=FileSystemLoader(template_dir, encoding="utf-8"),
                      autoescape=select_autoescape(["html"]))
    env.filters["fmt_cell"] = _fmt_cell

    try:
        _tz = ZoneInfo("Asia/Tokyo")
        build_id = dtm.datetime.now(_tz).strftime("%Y-%m-%d %H:%M:%S")
    except Exception:
        # tzãƒ‡ãƒ¼ã‚¿ãŒç„¡ã„ç’°å¢ƒã§ã‚‚å‹•ãã‚ˆã†ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        build_id = dtm.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    tpl = env.get_template("dashboard.html")
    html = tpl.render(
        include_log=include_log,
        data_json=data_json,                         # â† JSãŒèª­ã‚€JSON
        generated_at=build_id,                       # æ—¢å­˜ã®generated_atã‚‚æ›´æ–°æ™‚åˆ»ã§OK
        build_id=build_id                            # â˜… ã“ã‚Œã‚’ãƒ†ãƒ³ãƒ—ãƒ¬ã«æ¸¡ã™
    )

    # ---------- 6) æ›¸ãå‡ºã— ----------
    os.makedirs(os.path.dirname(html_path), exist_ok=True)
    with open(html_path, "w", encoding="utf-8", newline="") as f:
        f.write(html)
    print(f"[export] HTMLæ›¸ãå‡ºã—: {html_path} (logs={'ON' if include_log else 'OFF'}) | build: {build_id}")

# ========== /Template exporter ==========

# ========= å–¶æ¥­åˆ©ç›Š 

def update_operating_income_and_ratio(conn, batch_size=300, max_workers=12, use_quarterly=False):
    """
    æ—¢å­˜ã‚«ãƒ©ãƒ ã«åˆã‚ã›ã¦ä¿å­˜ï¼š
      - å–¶æ¥­åˆ©ç›Šï¼ˆæ•´æ•°ãƒ»å˜ä½=å„„å††ï¼‰
      - å–¶åˆ©å¯¾æ™‚ä¾¡ï¼ˆå°æ•°2æ¡ãƒ»å˜ä½=%ï¼‰
    yahooqueryã®income_statementã‹ã‚‰æœ€æ–°ï¼ˆå¹´æ¬¡/å››åŠæœŸï¼‰ã‚’å–å¾—ã€‚
    """
    try:
        pass
    except ImportError:
        print("[oper] yahooquery ãŒæœªå°å…¥ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
        return

    codes = [str(r[0]) for r in conn.execute("SELECT ã‚³ãƒ¼ãƒ‰ FROM screener").fetchall()]
    if not codes:
        print("[oper] å¯¾è±¡ã‚³ãƒ¼ãƒ‰ãªã—")
        return

    freq = "quarterly" if use_quarterly else "annual"
    total_updated = 0

    for i in range(0, len(codes), batch_size):
        chunk = codes[i:i+batch_size]
        symbols = [f"{c}.T" for c in chunk]

        tq = YQ(symbols, asynchronous=True, max_workers=max_workers)

        # income_statement ã‚’ "æœ€æ–° asOfDate" ã§1è¡Œã«æ­£è¦åŒ–
        latest = {}
        try:
            is_resp = tq.income_statement(freq)
            if hasattr(is_resp, "reset_index"):  # DataFrameãƒ‘ã‚¿ãƒ¼ãƒ³
                df = is_resp.reset_index()
                # ['symbol','asOfDate','OperatingIncome'(ã¾ãŸã¯ OperatingIncomeLoss), ...]
                for sym, g in df.groupby("symbol"):
                    g = g.dropna(subset=["asOfDate"]).sort_values("asOfDate")
                    if len(g):
                        latest[sym] = g.iloc[-1].to_dict()
            else:  # dictãƒ‘ã‚¿ãƒ¼ãƒ³
                for sym, rows in (is_resp or {}).items():
                    if isinstance(rows, list):
                        rows = [r for r in rows if isinstance(r, dict) and r.get("asOfDate")]
                        rows.sort(key=lambda r: r.get("asOfDate"))
                        if rows:
                            latest[sym] = rows[-1]
        except Exception:
            pass

        updates = []  # (å–¶æ¥­åˆ©ç›Š_å„„å††_int, å–¶åˆ©å¯¾æ™‚ä¾¡_pct_2f, ã‚³ãƒ¼ãƒ‰)
        for sym in symbols:
            ent = latest.get(sym) or {}
            op = ent.get("OperatingIncome", ent.get("OperatingIncomeLoss"))
            if op is None:
                continue
            try:
                # yahooqueryã¯æ•°å€¤/æ–‡å­—/è¾æ›¸æ··åœ¨ã®ã“ã¨ãŒã‚ã‚‹
                if isinstance(op, dict):
                    op = op.get("raw", op.get("fmt"))
                op = float(str(op).replace(",", ""))
            except Exception:
                continue

# ===== Gmailé€ä¿¡ =====
def send_index_html_via_gmail(attach_path: str) -> bool:
    try:
        pass
    except Exception as e:
        print("[SEND][Gmail] importå¤±æ•—:", e); return False

    path_to_send = attach_path
    maintype, subtype = "text", "html"
    filename = os.path.basename(attach_path)

    if SEND_HTML_AS_ZIP:
        zip_path = os.path.splitext(attach_path)[0] + ".zip"
        try:
            with zipfile.ZipFile(zip_path, "w", compression=zipfile.ZIP_DEFLATED) as z:
                z.write(attach_path, arcname=os.path.basename(attach_path))
            path_to_send = zip_path; maintype, subtype = "application", "zip"; filename = os.path.basename(zip_path)
            print(f"[SEND][Gmail] HTMLã‚’ZIPåŒ–: {zip_path}")
        except Exception as e:
            print("[SEND][Gmail] ZIPä½œæˆå¤±æ•—:", e); return False

    try:
        msg = EmailMessage()
        msg["Subject"] = GMAIL_SUBJ; msg["From"] = GMAIL_USER; msg["To"] = GMAIL_TO
        msg.set_content(GMAIL_BODY)
        with open(path_to_send, "rb") as f: data = f.read()
        msg.add_attachment(data, maintype=maintype, subtype=subtype, filename=filename)
        context = ssl.create_default_context()
        with smtplib.SMTP_SSL("smtp.gmail.com", 465, context=context) as smtp:
            smtp.login(GMAIL_USER, GMAIL_APP_PASSWORD); smtp.send_message(msg)
        print(f"[SEND][Gmail] é€ä¿¡ -> {GMAIL_TO} ({filename})"); return True
    except Exception as e:
        print("[SEND][Gmail] é€ä¿¡å¤±æ•—:", e); return False

# --- ã“ã“ã‹ã‚‰: å‰æ—¥çµ‚å€¤ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ï¼ˆå±¥æ­´ãƒ™ãƒ¼ã‚¹ï¼å”¯ä¸€ã®å®šç¾©ï¼‰ ---
# ---- å‰æ—¥çµ‚å€¤æ¯”ç‡(%)ï¼‹ç¾åœ¨å€¤ã‹ã‚‰å‰æ—¥çµ‚å€¤ã‚’é€†ç®—ã—ã¦DBæ›´æ–° ----

def ensure_prevclose_columns(conn):
    """Schema fixed: no-op."""
    return

def _to_raw(v):
    if isinstance(v, dict):
        return v.get("raw", v.get("fmt"))
    return v

# ==== _to_raw ãŒç„¡ã‘ã‚Œã°ä¿é™ºã§å®šç¾©ï¼ˆæ—¢ã«ã‚ã‚Œã°ä¸è¦ï¼‰====
try:
    _to_raw
except NameError:
    def _to_raw(val):
        """yahooqueryãŒè¿”ã™ {'raw':x,'fmt':y} ã‚„æ–‡å­—åˆ—ãªã©ã‚’æ•°å€¤ã«å¯„ã›ã‚‹."""
        if isinstance(val, dict):
            val = val.get("raw", val.get("fmt"))
        if val is None:
            return None
        try:
            return float(str(val).replace(",", ""))
        except Exception:
            return None

def get_prev_close_db_first(conn: sqlite3.Connection, code: str, quotes_prev: float | None = None) -> float | None:
    """
    å„ªå…ˆ: price_history ç›´è¿‘2å–¶æ¥­æ—¥ã®ã€å‰æ—¥çµ‚å€¤ã€
    ä»£æ›¿: quotes.regularMarketPreviousCloseï¼ˆä¸ãˆã‚‰ã‚Œã¦ã„ã‚Œã°ï¼‰
    """
    df = pd.read_sql_query(
        "SELECT æ—¥ä»˜, çµ‚å€¤ FROM price_history WHERE ã‚³ãƒ¼ãƒ‰=? ORDER BY æ—¥ä»˜ DESC LIMIT 2",
        conn, params=(str(code),)
    )
    if df.shape[0] >= 2:
        prev = df.iloc[1]["çµ‚å€¤"]
        if pd.notna(prev) and float(prev) != 0.0:
            return float(prev)
    if quotes_prev is not None and quotes_prev not in (0,):
        try:
            return float(quotes_prev)
        except Exception:
            pass
    return None

# ===== RVOL/å£²è²·ä»£é‡‘ è‡ªå‹•æ›´æ–°ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ =====

def _ensure_turnover_cols(conn: sqlite3.Connection):
    """Schema fixed: no-op."""
    return

def _jp_session_progress(dt: dtm.datetime | None = None) -> float:
    """å ´ä¸­ã®é€²æ—ç‡(0.0ã€œ1.0)ã€‚æ±è¨¼ 9:00â€“11:30 / 12:30â€“15:00 ã‚’300åˆ†=1.0ã§æ›ç®—ã€‚"""
    if dt is None:
        dt = dtm.datetime.utcnow().replace(tzinfo=dtm.timezone.utc) + dtm.timedelta(hours=9)  # JST
    m = dt.hour * 60 + dt.minute
    s1, e1, s2, e2 = 9*60, 11*60+30, 12*60+30, 15*60
    if m < s1: return 0.0
    if s1 <= m <= e1: return (m - s1) / 300.0
    if e1 < m < s2:  return 150 / 300.0
    if s2 <= m <= e2: return (150 + (m - s2)) / 300.0
    return 1.0

def apply_auto_metrics_midday(conn: sqlite3.Connection,
                              use_time_progress: bool = True,
                              denom_floor: float = 1.0,       # åˆ†æ¯ã®åºŠï¼ˆ20æ—¥å¹³å‡ãŒå°ã•ã™ãã‚‹ã¨ãã®ä¸‹é™ï¼‰
                              progress_floor: float = 0.33):   # é€²æ—ã®ä¸‹é™ï¼ˆå¯„ã‚Šç›´å¾Œã®èª¤å·®æŠ‘åˆ¶ï¼‰
    """
    ç¾åœ¨å€¤Ã—å‡ºæ¥é«˜â†’ã€å£²è²·ä»£é‡‘å„„ã€ã€ãã“ã‹ã‚‰ã€RVOLä»£é‡‘ã€ã‚’æ›´æ–°ã™ã‚‹ã€‚
    ã™ã¹ã¦ DB ä¿å­˜æ™‚ç‚¹ã§å°æ•° 2 æ¡ã«ä¸¸ã‚ã‚‹ã€‚
      - å£²è²·ä»£é‡‘å„„            : ROUND((ç¾åœ¨å€¤ * å‡ºæ¥é«˜) / 1e8, 2)
      - RVOLä»£é‡‘              : å½“æ—¥ä»£é‡‘ / max(20æ—¥å¹³å‡ä»£é‡‘, denom_floor) / progress(ä»»æ„) ã‚’ ROUND(..., 2)
    """
    cur = conn.cursor()

    # å£²è²·ä»£é‡‘ï¼ˆå„„ï¼‰= ç¾åœ¨å€¤Ã—å‡ºæ¥é«˜/1e8 â†’ 2æ¡ã§ä¿å­˜ï¼ˆå‡ºæ¥é«˜>0 ã®ã¨ãã ã‘è¨ˆç®—ï¼‰
    cur.execute("""
        UPDATE screener
        SET å£²è²·ä»£é‡‘å„„ =
          CASE
            WHEN ç¾åœ¨å€¤ IS NOT NULL AND å‡ºæ¥é«˜ IS NOT NULL AND å‡ºæ¥é«˜ > 0
            THEN ROUND((ç¾åœ¨å€¤ * å‡ºæ¥é«˜) / 100000000.0, 2)
          END
    """)

    # RVOL = å½“æ—¥ä»£é‡‘ / max(20æ—¥å¹³å‡ä»£é‡‘, denom_floor) / progress
    if use_time_progress:
        f = max(_jp_session_progress(), progress_floor)  # é€²æ—ï¼ˆä¸‹é™ã§ã‚¯ãƒ©ãƒ³ãƒ—ï¼‰
        cur.execute("""
            WITH p AS (SELECT ? AS f, ? AS dmin)
            UPDATE screener
            SET RVOLä»£é‡‘ =
              CASE
                WHEN å£²è²·ä»£é‡‘å„„ IS NOT NULL
                 AND å£²è²·ä»£é‡‘20æ—¥å¹³å‡å„„ IS NOT NULL
                THEN ROUND(
                  å£²è²·ä»£é‡‘å„„ /
                  (
                    (CASE
                       WHEN å£²è²·ä»£é‡‘20æ—¥å¹³å‡å„„ < (SELECT dmin FROM p)
                       THEN (SELECT dmin FROM p)
                       ELSE å£²è²·ä»£é‡‘20æ—¥å¹³å‡å„„
                     END) * (SELECT f FROM p)
                  ),
                  2
                )
              END
        """, (f, denom_floor))
    else:
        # é€²æ—è£œæ­£ã‚’ä½¿ã‚ãªã„å ´åˆã‚‚ 2æ¡ã§ä¿å­˜
        cur.execute("""
            WITH p AS (SELECT ? AS dmin)
            UPDATE screener
            SET RVOLä»£é‡‘ =
              CASE
                WHEN å£²è²·ä»£é‡‘å„„ IS NOT NULL
                 AND å£²è²·ä»£é‡‘20æ—¥å¹³å‡å„„ IS NOT NULL
                THEN ROUND(
                  å£²è²·ä»£é‡‘å„„ /
                  (CASE
                     WHEN å£²è²·ä»£é‡‘20æ—¥å¹³å‡å„„ < (SELECT dmin FROM p)
                     THEN (SELECT dmin FROM p)
                     ELSE å£²è²·ä»£é‡‘20æ—¥å¹³å‡å„„
                   END),
                  2
                )
              END
        """, (denom_floor,))

    conn.commit()
    cur.close()

def apply_auto_metrics_eod(conn: sqlite3.Connection,
                           denom_floor: float = 1.0):
    """
    çµ‚å€¤Ã—å‡ºæ¥é«˜ã§å½“æ—¥ä»£é‡‘ï¼ˆå„„ï¼‰ã‚’ç¢ºå®š â†’ 20æ—¥å¹³å‡ï¼ˆå„„ï¼‰ã‚’æ›´æ–° â†’ RVOLä»£é‡‘ã‚’æ›´æ–°ã€‚
    ã™ã¹ã¦ DB ä¿å­˜æ™‚ç‚¹ã§å°æ•° 2 æ¡ã«ä¸¸ã‚ã‚‹ã€‚
      - å£²è²·ä»£é‡‘å„„            : ROUND( (çµ‚å€¤*å‡ºæ¥é«˜)/1e8 , 2 )
      - å£²è²·ä»£é‡‘20æ—¥å¹³å‡å„„    : ç›´è¿‘20æœ¬ã®å¹³å‡ã‚’ ROUND(..., 2)
      - RVOLä»£é‡‘              : å½“æ—¥ä»£é‡‘ / max(20æ—¥å¹³å‡ä»£é‡‘, denom_floor) ã‚’ ROUND(..., 2)
    """
    cur = conn.cursor()

    # -- å½“æ—¥ç¢ºå®š ä»£é‡‘ï¼ˆå„„ï¼‰: 2æ¡ã§ä¿å­˜
    cur.execute("""
        UPDATE screener AS s
        SET å£²è²·ä»£é‡‘å„„ = (
          SELECT ROUND( (ph.çµ‚å€¤ * COALESCE(ph.å‡ºæ¥é«˜, 0)) / 100000000.0, 2 )
          FROM price_history ph
          WHERE ph.ã‚³ãƒ¼ãƒ‰ = s.ã‚³ãƒ¼ãƒ‰
          ORDER BY ph.æ—¥ä»˜ DESC
          LIMIT 1
        )
    """)

    # -- 20æ—¥å¹³å‡ï¼ˆç›´è¿‘20æœ¬ã®å˜ç´”å¹³å‡ï¼‰: 2æ¡ã§ä¿å­˜
    cur.execute("""
        WITH lastdate AS (
          SELECT ã‚³ãƒ¼ãƒ‰, MAX(æ—¥ä»˜) AS mx
          FROM price_history
          GROUP BY ã‚³ãƒ¼ãƒ‰
        ),
        hist AS (
          SELECT
            ph.ã‚³ãƒ¼ãƒ‰,
            (ph.çµ‚å€¤ * COALESCE(ph.å‡ºæ¥é«˜, 0)) / 100000000.0 AS ä»£é‡‘å„„_raw,
            ROW_NUMBER() OVER (PARTITION BY ph.ã‚³ãƒ¼ãƒ‰ ORDER BY ph.æ—¥ä»˜ DESC) AS rn
          FROM price_history ph
          JOIN lastdate ld
            ON ph.ã‚³ãƒ¼ãƒ‰ = ld.ã‚³ãƒ¼ãƒ‰
           AND ph.æ—¥ä»˜ <= ld.mx
        ),
        avg20 AS (
          SELECT ã‚³ãƒ¼ãƒ‰, ROUND(AVG(ä»£é‡‘å„„_raw), 2) AS avg20
          FROM hist
          WHERE rn <= 20
          GROUP BY ã‚³ãƒ¼ãƒ‰
        )
        UPDATE screener
        SET å£²è²·ä»£é‡‘20æ—¥å¹³å‡å„„ = (SELECT avg20 FROM avg20 WHERE avg20.ã‚³ãƒ¼ãƒ‰ = screener.ã‚³ãƒ¼ãƒ‰)
    """)

    # -- RVOLä»£é‡‘ï¼ˆåˆ†æ¯ã«åºŠï¼‰: 2æ¡ã§ä¿å­˜
    cur.execute("""
        WITH p AS (SELECT ? AS dmin)
        UPDATE screener
        SET RVOLä»£é‡‘ =
          CASE
            WHEN å£²è²·ä»£é‡‘å„„ IS NOT NULL
             AND å£²è²·ä»£é‡‘20æ—¥å¹³å‡å„„ IS NOT NULL
            THEN ROUND(
              å£²è²·ä»£é‡‘å„„ /
              (CASE
                 WHEN å£²è²·ä»£é‡‘20æ—¥å¹³å‡å„„ < (SELECT dmin FROM p)
                 THEN (SELECT dmin FROM p)
                 ELSE å£²è²·ä»£é‡‘20æ—¥å¹³å‡å„„
               END),
              2
            )
          END
    """, (denom_floor,))

    conn.commit()
    cur.close()

# ===== /RVOL/å£²è²·ä»£é‡‘ è‡ªå‹•æ›´æ–°ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ =====

def open_html_locally(html_path: str, wait_sec: float = 0.0, cool_min: int = 0, force: bool = False) -> bool:
    """
    ãƒ­ãƒ¼ã‚«ãƒ«HTMLã‚’æ—¢å®šãƒ–ãƒ©ã‚¦ã‚¶ã§é–‹ãï¼ˆWindowsã¯ os.startfile ã‚’å„ªå…ˆï¼‰ã€‚
    - cool_min > 0 ãªã‚‰ã€ç›´è¿‘ã‚ªãƒ¼ãƒ—ãƒ³ã‹ã‚‰ãã®åˆ†(åˆ†)ã¯å†ã‚ªãƒ¼ãƒ—ãƒ³ã—ãªã„
    - force=True ã§ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ç„¡è¦–
    æˆ»ã‚Šå€¤: é–‹ã‘ãŸã‚‰ True
    """
    p = Path(html_path).resolve()
    if not p.exists():
        raise FileNotFoundError(f"not found: {p}")

    stamp = p.with_suffix(p.suffix + ".opened")
    if not force and cool_min > 0 and stamp.exists():
        if time.time() - stamp.stat().st_mtime < cool_min * 60:
            return False  # ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ä¸­

    if wait_sec > 0:
        dtm.time.sleep(wait_sec)

    opened = False

    # 1) Windowsã¯æœ€ã‚‚ç¢ºå®Ÿãª ShellExecute ç›¸å½“ã§é–‹ã
    if os.name == "nt":
        try:
            os.startfile(str(p))  # æ—¢å®šãƒ–ãƒ©ã‚¦ã‚¶ã§é–‹ã
            opened = True
        except Exception:
            opened = False

    # 2) ã†ã¾ãã„ã‹ãªã‘ã‚Œã° webbrowser ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    if not opened:
        url = p.as_uri()  # file:///H:/... ã«å¤‰æ›
        try:
            opened = webbrowser.open(url) or webbrowser.open_new_tab(url)
        except Exception:
            opened = False

    # 3) æˆåŠŸã—ãŸã‚‰ã‚¹ã‚¿ãƒ³ãƒ—ä½œæˆ
    if opened:
        try:
            stamp.touch()
        except Exception:
            pass

    return opened

def apply_composite_score(conn: sqlite3.Connection,
                          w_rate=0.4, w_rvol=0.4, w_turn=0.2):
    """
    åˆæˆã‚¹ã‚³ã‚¢ = 0.4*rank(å‰æ—¥çµ‚å€¤æ¯”ç‡) + 0.4*rank(RVOLä»£é‡‘) + 0.2*rank(å£²è²·ä»£é‡‘å„„)
    ï¼ˆrankã¯ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«0-100ã€å°æ•°1æ¡ï¼‰
    """
    df = pd.read_sql_query("""
        SELECT ã‚³ãƒ¼ãƒ‰, å‰æ—¥çµ‚å€¤æ¯”ç‡, RVOLä»£é‡‘, å£²è²·ä»£é‡‘å„„
        FROM screener
    """, conn)

    for c in ["å‰æ—¥çµ‚å€¤æ¯”ç‡", "RVOLä»£é‡‘", "å£²è²·ä»£é‡‘å„„"]:
        df[c] = pd.to_numeric(df[c], errors="coerce")

    # ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ï¼ˆNaNã¯0æ‰±ã„ï¼‰
    pct = lambda s: (s.rank(pct=True) * 100.0)
    r_rate = pct(df["å‰æ—¥çµ‚å€¤æ¯”ç‡"].fillna(-1e18))
    r_rvol = pct(df["RVOLä»£é‡‘"].fillna(0))
    r_turn = pct(df["å£²è²·ä»£é‡‘å„„"].fillna(0))

    score = (w_rate*r_rate + w_rvol*r_rvol + w_turn*r_turn).round(1)
    up = list(zip(score.fillna(0).tolist(), df["ã‚³ãƒ¼ãƒ‰"].astype(str).tolist()))

    cur = conn.cursor()
    # ï¼ˆåˆ—ãŒç„¡ã‘ã‚Œã°æ—¢ã«ã‚ãªãŸã® _ensure_* ç³»ã§è¿½åŠ æ¸ˆã¿ã€‚äºŒé‡ALTERã«ãªã‚‰ãªã„ã‚ˆã†æ³¨æ„ï¼‰
    cur.executemany("UPDATE screener SET åˆæˆã‚¹ã‚³ã‚¢=? WHERE ã‚³ãƒ¼ãƒ‰=?", up)
    conn.commit()
    cur.close()

def apply_atr14_pct(conn: sqlite3.Connection) -> int:
    """
    price_history ã‹ã‚‰ TRâ†’ATR14â†’ATR14% ã‚’ç®—å‡ºã—ã€screener.ATR14_PCT ã‚’æ›´æ–°ã™ã‚‹ã€‚
      TR  = max(é«˜å€¤-å®‰å€¤, |é«˜å€¤-å‰æ—¥çµ‚å€¤|, |å®‰å€¤-å‰æ—¥çµ‚å€¤|)
      ATR14% = ATR14 / ç›´è¿‘çµ‚å€¤ * 100
    æˆ»ã‚Šå€¤: æ›´æ–°å¯¾è±¡ã«ãªã£ãŸéŠ˜æŸ„æ•°ï¼ˆç›®å®‰å€¤ï¼‰
    """
    # 1) ã‚«ãƒ©ãƒ ãŒç„¡ã‘ã‚Œã°è¿½åŠ 
    cur = conn.cursor()
    if "ATR14_PCT" not in cols:
        cur.execute("ALTER TABLE screener ADD COLUMN ATR14_PCT REAL")
        conn.commit()

    # 2) ã¾ãšã¯SQLï¼ˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦é–¢æ•°ï¼‰ã§ä¸€æ‹¬æ›´æ–°ã‚’è©¦ã™
    try:
        cur.execute("""
            WITH ph AS (
              SELECT
                ã‚³ãƒ¼ãƒ‰, æ—¥ä»˜, å§‹å€¤, é«˜å€¤, å®‰å€¤, çµ‚å€¤,
                LAG(çµ‚å€¤) OVER (PARTITION BY ã‚³ãƒ¼ãƒ‰ ORDER BY æ—¥ä»˜) AS prevC
              FROM price_history
            ),
            tr AS (
              SELECT
                ã‚³ãƒ¼ãƒ‰, æ—¥ä»˜,
                MAX(
                  é«˜å€¤ - å®‰å€¤,
                  ABS(é«˜å€¤ - prevC),
                  ABS(å®‰å€¤ - prevC)
                ) AS TR
              FROM ph
            ),
            atr AS (
              SELECT
                ã‚³ãƒ¼ãƒ‰, æ—¥ä»˜,
                AVG(TR) OVER (
                  PARTITION BY ã‚³ãƒ¼ãƒ‰
                  ORDER BY æ—¥ä»˜
                  ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
                ) AS ATR14
              FROM tr
            ),
            last_row AS (
              SELECT a.ã‚³ãƒ¼ãƒ‰, a.ATR14, p.çµ‚å€¤
              FROM atr a
              JOIN (
                SELECT ã‚³ãƒ¼ãƒ‰, MAX(æ—¥ä»˜) AS mx
                FROM price_history
                GROUP BY ã‚³ãƒ¼ãƒ‰
              ) ld
                ON a.ã‚³ãƒ¼ãƒ‰ = ld.ã‚³ãƒ¼ãƒ‰ AND a.æ—¥ä»˜ = ld.mx
              JOIN price_history p
                ON p.ã‚³ãƒ¼ãƒ‰ = ld.ã‚³ãƒ¼ãƒ‰ AND p.æ—¥ä»˜ = ld.mx
            )
            UPDATE screener
            SET ATR14_PCT = ROUND(
                  (SELECT (ATR14 / NULLIF(çµ‚å€¤,0)) * 100.0
                   FROM last_row
                   WHERE last_row.ã‚³ãƒ¼ãƒ‰ = screener.ã‚³ãƒ¼ãƒ‰),
                2)
            WHERE EXISTS (SELECT 1 FROM last_row WHERE last_row.ã‚³ãƒ¼ãƒ‰ = screener.ã‚³ãƒ¼ãƒ‰);
        """)
        conn.commit()
        # ä½•ä»¶æ›´æ–°ã•ã‚ŒãŸã‹ã®æ¨å®šï¼ˆå³å¯†ãªä»¶æ•°å–å¾—ã¯é›£ã—ã„ãŸã‚ã‚µãƒ³ãƒ—ãƒ«ã§ä»£ç”¨ï¼‰
        cur.execute("SELECT COUNT(*) FROM screener WHERE ATR14_PCT IS NOT NULL")
        n = cur.fetchone()[0]
        cur.close()
        return n

    except sqlite3.OperationalError:
        # 3) ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆpandasã§è¨ˆç®—ï¼‰
        cur.close()
        try:
            import pandas as pd
            import numpy as np
        except Exception as e:
            # pandasãŒç„¡ã‘ã‚Œã°ä½•ã‚‚ã›ãšçµ‚äº†
            return 0

        ph = pd.read_sql_query(
            "SELECT ã‚³ãƒ¼ãƒ‰, æ—¥ä»˜, é«˜å€¤, å®‰å€¤, çµ‚å€¤ "
            "FROM price_history ORDER BY ã‚³ãƒ¼ãƒ‰, æ—¥ä»˜",
            conn
        )
        if ph.empty:
            return 0

        ph["prevC"] = ph.groupby("ã‚³ãƒ¼ãƒ‰")["çµ‚å€¤"].shift(1)

        tr = np.maximum.reduce([
            (ph["é«˜å€¤"] - ph["å®‰å€¤"]).abs().values,
            (ph["é«˜å€¤"] - ph["prevC"]).abs().values,
            (ph["å®‰å€¤"] - ph["prevC"]).abs().values
        ])
        ph["TR"] = tr

        atr14 = (
            ph.groupby("ã‚³ãƒ¼ãƒ‰")["TR"]
              .rolling(14, min_periods=14)
              .mean()
              .reset_index(level=0, drop=True)
        )
        ph["ATR14"] = atr14

        last = (
            ph.groupby("ã‚³ãƒ¼ãƒ‰")
              .tail(1)[["ã‚³ãƒ¼ãƒ‰", "ATR14", "çµ‚å€¤"]]
              .dropna(subset=["ATR14", "çµ‚å€¤"])
              .copy()
        )
        last["ATR14_PCT"] = (last["ATR14"] / last["çµ‚å€¤"] * 100.0).round(2)

        cur = conn.cursor()
        cur.executemany(
            "UPDATE screener SET ATR14_PCT=? WHERE ã‚³ãƒ¼ãƒ‰=?",
            list(zip(last["ATR14_PCT"].tolist(),
                     last["ã‚³ãƒ¼ãƒ‰"].astype(str).tolist()))
        )
        conn.commit()
        n = len(last)
        cur.close()
        return n

def ensure_since_schema(conn):
    """Schema fixed: no-op."""
    return
    def need(col, decl):
        if col not in cols:
            add.append((col, decl))
    need("åˆå‹•é–‹å§‹æ—¥", "TEXT")
    need("åº•æ‰“ã¡é–‹å§‹æ—¥", "TEXT")
    need("æ—©æœŸé–‹å§‹æ—¥", "TEXT")
    need("å³è‚©é–‹å§‹æ—¥", "TEXT")
    need("æ—©æœŸç¨®åˆ¥é–‹å§‹æ—¥", "TEXT")
    need("æ—©æœŸå‰å›ç¨®åˆ¥", "TEXT")
    if add:
        cur = conn.cursor()
        for c, d in add:
            try:
                cur.execute(f"ALTER TABLE screener ADD COLUMN {c} {d}")
            except Exception:
                pass
        conn.commit(); cur.close()

def _parse_early_tag(detail: str) -> str | None:
    if detail is None:
        return None
    try:
        # ä¾‹: "ãƒ–ãƒ¬ã‚¤ã‚¯ | score=..." â†’ "ãƒ–ãƒ¬ã‚¤ã‚¯"
        head = str(detail).split("|", 1)[0].strip()
        return head if head else None
    except Exception:
        return None

def _prev_business_day(d, extra_closed):
    # æ—¢å­˜ã® prev_business_day_jp / is_jp_market_holiday ã‚’æƒ³å®š
    return prev_business_day_jp(d, extra_closed)

def _streak_start_for_kind(conn, code: str, kind: str, extra_closed) -> str | None:
    """
    signals_log(ã‚³ãƒ¼ãƒ‰, ç¨®åˆ¥)ã®ã€Œç›´è¿‘ã®é€£ç¶šåŒºé–“ã®é–‹å§‹æ—¥ã€ã‚’è¿”ã™ã€‚
    ä¼‘å ´æ—¥ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ã€å–¶æ¥­æ—¥é€£ç¶šãŒåˆ‡ã‚ŒãŸæ‰€ã§æ‰“ã¡åˆ‡ã‚Šã€‚
    """
    cur = conn.cursor()
    cur.execute("""
        SELECT æ—¥æ™‚ FROM signals_log 
        WHERE ã‚³ãƒ¼ãƒ‰=? AND ç¨®åˆ¥=? 
        ORDER BY æ—¥æ™‚ DESC
    """, (str(code), kind))
    rows = [r[0] for r in cur.fetchall()]
    cur.close()
    if not rows:
        return None

    def dstr(d): return d.strftime("%Y-%m-%d")
    try:
        latest = dtm.datetime.strptime(rows[0][:10], "%Y-%m-%d").date()
    except Exception:
        return None

    run_start = latest
    cur_check = latest
    have = {r[:10] for r in rows}

    while True:
        prev_d = _prev_business_day(cur_check, extra_closed)
        if dstr(prev_d) in have:
            run_start = prev_d
            cur_check = prev_d
            continue
        break
    return run_start.strftime("%Y-%m-%d") if run_start else None

def _early_type_range_and_prev(conn, code: str, extra_closed):
    """
    'å³è‚©ä¸ŠãŒã‚Š-æ—©æœŸ' ã®ã‚¿ã‚°æ¨ç§»ã‚’è§£æã€‚
    æˆ»ã‚Šå€¤: (start_date_str, current_tag, previous_tag) ã„ãšã‚Œã‚‚ç„¡ã‘ã‚Œã° None
    """
    cur = conn.cursor()
    cur.execute("""
        SELECT æ—¥æ™‚, è©³ç´° FROM signals_log
        WHERE ã‚³ãƒ¼ãƒ‰=? AND ç¨®åˆ¥='å³è‚©ä¸ŠãŒã‚Š-æ—©æœŸ'
        ORDER BY æ—¥æ™‚ DESC
    """, (str(code),))
    rows = cur.fetchall()
    cur.close()
    if not rows:
        return None, None, None

    cur_tag = None
    cur_dates = []
    prev_tag = None
    for dt_s, detail in rows:
        tag = _parse_early_tag(detail)
        d = dtm.datetime.strptime(dt_s[:10], "%Y-%m-%d").date()
        if cur_tag is None:
            cur_tag = tag
            cur_dates.append(d)
            continue
        if tag == cur_tag:
            cur_dates.append(d)
            continue
        prev_tag = tag  # ã‚¿ã‚°ãŒåˆ‡ã‚Šæ›¿ã‚ã£ãŸç›´å‰ã®ã‚¿ã‚°
        break

    if not cur_dates:
        return None, cur_tag, prev_tag
    start_date = min(cur_dates).strftime("%Y-%m-%d")
    return start_date, cur_tag, prev_tag

def phase_update_since_dates(conn):
    """
    screener ã«ä»¥ä¸‹ã‚’åŸ‹ã‚ã‚‹:
      - åˆå‹•é–‹å§‹æ—¥ / åº•æ‰“ã¡é–‹å§‹æ—¥ / æ—©æœŸé–‹å§‹æ—¥ / å³è‚©é–‹å§‹æ—¥
      - æ—©æœŸç¨®åˆ¥é–‹å§‹æ—¥ / æ—©æœŸå‰å›ç¨®åˆ¥
    """
    extra_closed = _load_extra_closed(EXTRA_CLOSED_PATH)
    cur = conn.cursor()
    cur.execute("""
        SELECT ã‚³ãƒ¼ãƒ‰, åˆå‹•ãƒ•ãƒ©ã‚°, åº•æ‰“ã¡ãƒ•ãƒ©ã‚°, å³è‚©ä¸ŠãŒã‚Šãƒ•ãƒ©ã‚°, å³è‚©æ—©æœŸãƒ•ãƒ©ã‚°, å³è‚©æ—©æœŸç¨®åˆ¥
        FROM screener
    """)
    rows = cur.fetchall()
    cur.close()

    upd = []
    for code, sh, bt, ru, er, etype in rows:
        code = str(code)

        s_sh = _streak_start_for_kind(conn, code, "åˆå‹•", extra_closed) if (sh == "å€™è£œ") else None
        s_bt = _streak_start_for_kind(conn, code, "åº•æ‰“ã¡", extra_closed) if (bt == "å€™è£œ") else None
        s_ru = _streak_start_for_kind(conn, code, "å³è‚©ä¸ŠãŒã‚Š", extra_closed) if (ru == "å€™è£œ") else None
        s_er = _streak_start_for_kind(conn, code, "å³è‚©ä¸ŠãŒã‚Š-æ—©æœŸ", extra_closed) if (er == "å€™è£œ") else None

        etype_start = None
        prev_type = None
        if etype and str(etype).strip() != "":
            etype_start, cur_type, prev_type = _early_type_range_and_prev(conn, code, extra_closed)
            # è¡¨ç¤ºã¨ãƒ­ã‚°ãŒé£Ÿã„é•ã£ãŸã‚‰ãƒ­ã‚°å´ã«åˆã‚ã›ã‚‹ï¼ˆä»»æ„ï¼‰
            if cur_type and cur_type != etype:
                etype = cur_type

        upd.append((s_sh, s_bt, s_er, s_ru, etype_start, prev_type, code))

    if upd:
        cur = conn.cursor()
        cur.executemany("""
            UPDATE screener
               SET åˆå‹•é–‹å§‹æ—¥=?,
                   åº•æ‰“ã¡é–‹å§‹æ—¥=?,
                   æ—©æœŸé–‹å§‹æ—¥=?,
                   å³è‚©é–‹å§‹æ—¥=?,
                   æ—©æœŸç¨®åˆ¥é–‹å§‹æ—¥=?,
                   æ—©æœŸå‰å›ç¨®åˆ¥=?
             WHERE ã‚³ãƒ¼ãƒ‰=?
        """, upd)
        conn.commit(); cur.close()

def relax_rejudge_signals(
    conn,
    lookahead_days: int = None,
    req_high_pct: float = None,
    max_adverse_pct: float = None,
):
    """
    signals_log ã§ 'å¤–ã‚Œ' ã«ãªã£ã¦ã„ã‚‹ã‚·ã‚°ãƒŠãƒ«ã‚’ã€ç™ºç”Ÿæ—¥ã‹ã‚‰ä¸€å®šæ—¥æ•°å†…ã®å€¤å‹•ãã§å†è©•ä¾¡ã€‚
    æ¡ä»¶:
      ãƒ»lookahead_days æ—¥ä»¥å†…ã« +req_high_pct% åˆ°é”
      ãƒ»ã‹ã¤ æœ€å¤§é€†è¡Œï¼ˆå®‰å€¤åŸºæº–ï¼‰ãŒ -max_adverse_pct% ä»¥å†…
    æº€ãŸã›ã° åˆ¤å®š='å†è©•ä¾¡OK' / ç†ç”± ã‚’ä¸Šæ›¸ãã€‚
    """

    L = lookahead_days or REJUDGE_LOOKAHEAD_DAYS
    UP = req_high_pct   or REJUDGE_REQ_HIGH_PCT
    DN = max_adverse_pct or REJUDGE_MAX_ADVERSE_PCT

    cur = conn.cursor()
    # ç›´è¿‘30æ—¥åˆ†ã® â€œå¤–ã‚Œâ€ ã‚’å¯¾è±¡ï¼ˆå¿…è¦ã«å¿œã˜ã¦æœŸé–“ã¯èª¿æ•´å¯ï¼‰
    cur.execute("""
      SELECT ã‚³ãƒ¼ãƒ‰, æ—¥æ™‚
        FROM signals_log
       WHERE åˆ¤å®š='å¤–ã‚Œ'
         AND æ—¥æ™‚ >= date('now','-30 day')
    """)
    rows = cur.fetchall()

    upd = 0
    for code, ts in rows:
        base_date = str(ts)[:10]
        g = pd.read_sql_query("""
          SELECT æ—¥ä»˜, çµ‚å€¤, é«˜å€¤, å®‰å€¤
            FROM price_history
           WHERE ã‚³ãƒ¼ãƒ‰=?
             AND æ—¥ä»˜ BETWEEN date(?) AND date(?, '+' || ? || ' day')
           ORDER BY æ—¥ä»˜ ASC
        """, conn, params=(code, base_date, base_date, L))

        if g.empty:
            continue

        entry = float(g.iloc[0]["çµ‚å€¤"])
        if entry is None or entry == 0:
            continue

        max_up = (g["é«˜å€¤"].max() / entry - 1.0) * 100.0
        max_dn = (g["å®‰å€¤"].min() / entry - 1.0) * 100.0  # è² ã®å€¤ï¼ˆä¾‹: -6.3ï¼‰

        if (max_up >= UP) and (max_dn >= -DN):
            cur2 = conn.cursor()
            cur2.execute("""
              UPDATE signals_log
                 SET åˆ¤å®š='å†è©•ä¾¡OK',
                     ç†ç”±=?
               WHERE ã‚³ãƒ¼ãƒ‰=? AND æ—¥æ™‚=?
            """, (f"delayed hit: {L}D +{max_up:.1f}% / MAE {max_dn:.1f}%", code, ts))
            conn.commit()
            cur2.close()
            upd += 1

    cur.close()
    if upd:
        print(f"[rejudge] å†è©•ä¾¡OK ã«æ›´æ–°: {upd} ä»¶")
    else:
        print("[rejudge] è©²å½“ãªã—")

# === è¿½åŠ ï¼šãƒ­ã‚¬ãƒ¼å…±é€šã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆæ–°è¦ï¼‰ ===

def setup_fin_logger(verbose: bool = False):
    """
    å¢—è³‡ãƒªã‚¹ã‚¯ç³»ã®å‡¦ç†ã§ä½¿ã†å…±é€šãƒ­ã‚¬ãƒ¼ã€‚
    - ã‚³ãƒ³ã‚½ãƒ¼ãƒ« & ãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›ï¼ˆãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
    - verbose=True ã§ DEBUGã€False ã§ INFO
    """
    logger = logging.getLogger("dilution")
    # ã™ã§ã«ãƒãƒ³ãƒ‰ãƒ©ä»˜ã„ã¦ãŸã‚‰å†åˆ©ç”¨
    if logger.handlers:
        logger.setLevel(logging.DEBUG if verbose else logging.INFO)
        return logger

    logger.setLevel(logging.DEBUG if verbose else logging.INFO)

    # å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆæ—¢å­˜ã® OUTPUT_DIR ã‚’åˆ©ç”¨ï¼‰
    try:
        base_dir = OUTPUT_DIR  # æ—¢å­˜å¤‰æ•°ã‚’åˆ©ç”¨:contentReference[oaicite:1]{index=1}
    except NameError:
        base_dir = os.getcwd()

    log_dir = os.path.join(base_dir, "logs")
    os.makedirs(log_dir, exist_ok=True)
    log_path = os.path.join(log_dir, f"dilution_{dtm.datetime.now().strftime('%Y%m%d')}.log")

    fmt = logging.Formatter("[%(asctime)s] %(levelname)s %(message)s")

    # ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ1MBãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³Ã—3ï¼‰
    fh = RotatingFileHandler(log_path, maxBytes=1_000_000, backupCount=3, encoding="utf-8")
    fh.setFormatter(fmt)
    fh.setLevel(logging.DEBUG)

    # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«
    ch = logging.StreamHandler()
    ch.setFormatter(fmt)
    ch.setLevel(logging.DEBUG if verbose else logging.INFO)

    logger.addHandler(fh)
    logger.addHandler(ch)
    logger.propagate = False
    logger.info(f"Logger initialized. log_path={log_path}")
    return logger

# ===== å¢—è³‡åˆ¤å®šç”¨

def _yf_num(x):
    try:
        if x is None or (isinstance(x, float) and math.isnan(x)): return None
        return float(x)
    except Exception:
        return None

def _sum_quarters(df_like, keys, n=4):
    """ç›´è¿‘nå››åŠæœŸã®åˆè¨ˆ"""
    if df_like is None or df_like.empty: return 0.0
    for k in keys:
        if k in df_like.index:
            vals = [ _yf_num(v) or 0.0 for v in list(df_like.loc[k].values)[:n] ]
            return float(sum(vals))
    return 0.0

# --- BEGIN: batch_update_all_financials (è²¼ã‚Šä»˜ã‘ç”¨) ---
# ä¾å­˜: pip install yahooquery
try:
    pass
except Exception:
    YQ = None

YQ_MAX_WORKERS = 8

def _safe_num(v):
    try:
        if v is None: return None
        if isinstance(v, str):
            s = v.strip().replace(",", "").replace(" ", "")
            if s in ("", "-", "None", "nan", "NaN"): return None
            return float(s)
        if isinstance(v, (int, float)):
            if isinstance(v, float) and (v != v): return None
            return float(v)
    except Exception:
        return None

def _get_from_periods(obj, keys):
    if obj is None: return None
    if isinstance(obj, dict):
        for k in keys:
            if k in obj and obj[k] is not None:
                try: return float(obj[k])
                except Exception: pass
        # iterate periods
        for per, fields in obj.items():
            if isinstance(fields, dict):
                for k in keys:
                    if k in fields and fields[k] is not None:
                        try: return float(fields[k])
                        except Exception: pass
    return None

def _sum_recent(obj, keys, n=4):
    if obj is None: return None
    total = 0.0; cnt = 0
    if isinstance(obj, dict):
        for per, fields in obj.items():
            if isinstance(fields, dict):
                v = None
                for k in keys:
                    if k in fields and fields[k] is not None:
                        try: v = float(fields[k]); break
                        except Exception: v = None
                if v is not None:
                    total += v
                cnt += 1
                if cnt >= n: break
    return total if cnt>0 else None

def _sum_dividends_1y(divs, one_year_ago):
    if divs is None: return 0.0
    s = 0.0
    try:
        if hasattr(divs, "items"):
            for k, v in dict(divs).items():
                try:
                    s += float(v)
                except Exception:
                    continue
            return float(s)
    except Exception:
        pass
    try:
        for item in divs:
            if isinstance(item, dict):
                amt = item.get("amount") or item.get("dividend") or item.get("value")
                if amt is not None:
                    try: s += float(amt)
                    except Exception: pass
        return float(s)
    except Exception:
        return 0.0

def add_column_if_missing(conn, table, colname, decl):
    """Schema fixed: no-op."""
    return

def _fmt(x, nd=2):
    """æ•°å€¤ã‚’å®‰å…¨ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆNoneâ†’'NA'ã€ä¾‹å¤–æ™‚ã‚‚'NA'ï¼‰"""
    try:
        if x is None:
            return "NA"
        return f"{float(x):.{nd}f}"
    except Exception:
        return "NA"

# === ç½®æ›ï¼šæœ¬ä½“ï¼ˆyahooquery å–å¾—â†’è§£æâ†’DBåæ˜ ï¼‰ ===
def batch_update_all_financials(conn,
                                chunk_size: int = 200,
                                force_refresh: bool = False,
                                sleep_between_chunks: float = 0.1,
                                verbose: bool = False,
                                set_wal: bool = True):
    """
    yahooquery ä¸€æ‹¬å–å¾— -> raw_fin_json ã‚­ãƒ£ãƒƒã‚·ãƒ¥ -> æŒ‡æ¨™æŠ½å‡º -> DB ä¸€æ‹¬æ›´æ–°
    ãƒ­ã‚°ã‚’è©³ç´°ã«å‡ºã™ï¼ˆINFO=è¦ç´„ / DEBUG=éŠ˜æŸ„ã”ã¨ã®è©³ç´°ï¼‰ã€‚
    - DataFrame è¿”å´æ™‚ã®ãƒ‘ãƒ¼ã‚¹ã«å¯¾å¿œ
    - æ•°å€¤ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå®‰å…¨åŒ–
    """
    # --------------------------
    # ãƒ­ã‚¬ãƒ¼
    # --------------------------
    log = setup_fin_logger(verbose)  # æ—¢å­˜ã®å…±é€šãƒ­ã‚¬ãƒ¼ã‚’åˆ©ç”¨

    # --------------------------
    # ä¾å­˜ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    # --------------------------
    try:
        _safe_num  # noqa
    except NameError:
        def _safe_num(v):
            try:
                if v is None: return None
                if isinstance(v, str):
                    s = v.strip().replace(",", "").replace(" ", "")
                    if s in ("", "-", "None", "nan", "NaN"): return None
                    return float(s)
                if isinstance(v, (int, float)):
                    if isinstance(v, float) and (v != v): return None
                    return float(v)
            except Exception:
                return None

    # --------------------------
    # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆå®‰å…¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼pandaså¯¾å¿œï¼‰
    # --------------------------
    def _fmt(x, nd=2):
        """æ•°å€¤ã‚’å®‰å…¨ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆNoneâ†’'NA'ã€ä¾‹å¤–æ™‚ã‚‚'NA'ï¼‰"""
        try:
            if x is None:
                return "NA"
            return f"{float(x):.{nd}f}"
        except Exception:
            return "NA"

    def _is_nonempty_df(x):
        try:
            import pandas as pd  # optional
            return isinstance(x, pd.DataFrame) and (not x.empty)
        except Exception:
            return False

    def _yf_pick_recent_from_df(df, keys):
        """DataFrameï¼ˆindex=é …ç›®ã€columns=æœŸï¼‰ã‹ã‚‰æœ€ã‚‚ç›´è¿‘åˆ—ã®æ•°å€¤ã‚’å–ã‚‹"""
        try:
            if not _is_nonempty_df(df):
                return None
            for k in keys:
                if k in df.index:
                    vals = list(df.loc[k].values)  # ç›´è¿‘ãŒå…ˆé ­ã®æƒ³å®šï¼ˆyahooqueryï¼‰
                    for v in vals:
                        try:
                            if v is None:
                                continue
                            return float(v)
                        except Exception:
                            continue
            return None
        except Exception:
            return None

    def _yf_sum_quarters_df(df, keys, n=4):
        """DataFrame ç‰ˆ ç›´è¿‘næœŸåˆè¨ˆ"""
        try:
            if not _is_nonempty_df(df):
                return 0.0
            for k in keys:
                if k in df.index:
                    vals = list(df.loc[k].values)[:n]
                    acc = 0.0
                    for v in vals:
                        try:
                            acc += float(v or 0.0)
                        except Exception:
                            pass
                    return float(acc)
            return 0.0
        except Exception:
            return 0.0

    def _get_from_periods(obj, keys):
        """dictç³»ï¼ˆyahooquery é€šå¸¸è¿”å´ï¼‰ã® periodâ†’field ã‹ã‚‰æœ€åˆã«è¦‹ã¤ã‹ã£ãŸå€¤ã‚’è¿”ã™"""
        if obj is None: return None
        if isinstance(obj, dict):
            # ç›´ã‚¢ã‚¯ã‚»ã‚¹
            for k in keys:
                if k in obj and obj[k] is not None:
                    try: return float(obj[k])
                    except Exception: pass
            # periods ã‚’èµ°æŸ»
            for per, fields in obj.items():
                if isinstance(fields, dict):
                    for k in keys:
                        if k in fields and fields[k] is not None:
                            try: return float(fields[k])
                            except Exception: pass
        return None

    def _sum_recent(obj, keys, n=4):
        """dictç³»ã®ç›´è¿‘næœŸåˆè¨ˆ"""
        if obj is None: return None
        total = 0.0; cnt = 0
        if isinstance(obj, dict):
            for per, fields in obj.items():
                if isinstance(fields, dict):
                    v = None
                    for k in keys:
                        if k in fields and fields[k] is not None:
                            try:
                                v = float(fields[k]); break
                            except Exception:
                                v = None
                    if v is not None:
                        total += v
                    cnt += 1
                    if cnt >= n: break
        return total if cnt > 0 else None

    def _sum_dividends_1y(divs, one_year_ago):
        """é…å½“ã¯æ§‹é€ ãŒæ§˜ã€…ãªã®ã§ã€dict/iterable/DF ã®é †ã«ãƒˆãƒ©ã‚¤ã€‚1å¹´åˆ¶é™ã¯æœ€å°é™ï¼ˆDFã¯å…¨åˆè¨ˆï¼‰ã€‚"""
        # dict/iterable
        if divs is None:
            return 0.0
        try:
            # dict å½¢å¼
            if hasattr(divs, "items"):
                s = 0.0
                for _, v in dict(divs).items():
                    try: s += float(v)
                    except Exception: pass
                return float(s)
        except Exception:
            pass
        try:
            # iterable of dict
            s = 0.0
            for item in divs:
                if isinstance(item, dict):
                    amt = item.get("amount") or item.get("dividend") or item.get("value")
                    if amt is not None:
                        try: s += float(amt)
                        except Exception: pass
            return float(s)
        except Exception:
            pass
        # DataFrame
        if _is_nonempty_df(divs):
            try:
                return float(divs.sum(numeric_only=True).sum())
            except Exception:
                return 0.0
        return 0.0

    # --------------------------
    # å‰å‡¦ç†ãƒ»ã‚«ãƒ©ãƒ ç¢ºä¿
    # --------------------------

    one_year_ago = dtm.date.today() - dtm.timedelta(days=365)

    if set_wal:
        try:
            log.debug("[DB] PRAGMA set WAL / synchronous=OFF")
        except Exception as e:
            log.warning(f"[DB] PRAGMA set failed: {e}")

    for name, decl in [
        ("raw_fin_json", "TEXT"),
        ("è²¡å‹™æ›´æ–°æ—¥", "TEXT"),
        ("è‡ªå·±è³‡æœ¬æ¯”ç‡", "REAL"),
        ("å–¶æ¥­CF_ç›´è¿‘", "REAL"),
        ("å–¶æ¥­CF_4Qåˆè¨ˆ", "REAL"),
        ("é…å½“1å¹´åˆè¨ˆ", "REAL"),
        ("è‡ªç¤¾æ ªè²·ã„4Qåˆè¨ˆ", "REAL"), ("å¢—è³‡ãƒªã‚¹ã‚¯", "INTEGER"), ("å¢—è³‡ã‚¹ã‚³ã‚¢", "REAL"), ("å¢—è³‡ç†ç”±", "TEXT"),
    ]:
        try:
            pass
        except Exception as e:
            log.warning(f"[batch] add column {name} failed: {e}")

    cur = conn.cursor()
    cur.execute('SELECT ã‚³ãƒ¼ãƒ‰, raw_fin_json, è²¡å‹™æ›´æ–°æ—¥ FROM screener')
    rows = cur.fetchall()
    cur.close()
    codes = [str(r[0]) for r in rows]
    raw_map = {str(r[0]): r[1] for r in rows}
    fin_date_map = {str(r[0]): r[2] for r in rows}

    total = len(codes)
    processed = 0; updated_rows = 0; flags_set = 0; errors = 0

    log.info(f"[batch.start] total={total} chunk={chunk_size} force_refresh={force_refresh} yq=ON")

    # --------------------------
    # batched commit
    # --------------------------
    def commit_batch(metrics_rows, flags_rows):
        nonlocal updated_rows, flags_set
        if metrics_rows:
            conn.executemany("""
                UPDATE screener SET
                  "è‡ªå·±è³‡æœ¬æ¯”ç‡"      = ?,
                  "å–¶æ¥­CF_ç›´è¿‘"       = ?,
                  "å–¶æ¥­CF_4Qåˆè¨ˆ"     = ?,
                  "é…å½“1å¹´åˆè¨ˆ"       = ?,
                  "è‡ªç¤¾æ ªè²·ã„4Qåˆè¨ˆ" = ?,
                  "è²¡å‹™æ›´æ–°æ—¥"        = ?,
                  "raw_fin_json"      = ?
                WHERE "ã‚³ãƒ¼ãƒ‰" = ?
            """, metrics_rows)
            conn.commit()
            updated_rows += len(metrics_rows)
            log.info(f"[commit.metrics] rows={len(metrics_rows)} total_updated={updated_rows}")
        if flags_rows:
            conn.executemany("""
                UPDATE screener SET "å¢—è³‡ãƒªã‚¹ã‚¯"=?, "å¢—è³‡ã‚¹ã‚³ã‚¢"=?, "å¢—è³‡ç†ç”±"=? WHERE "ã‚³ãƒ¼ãƒ‰"=?
            """, flags_rows)
            conn.commit()
            flags_set += len(flags_rows)
            log.info(f"[commit.flags] rows={len(flags_rows)} total_flags={flags_set}")

    # --------------------------
    # main loop
    # --------------------------
    for i in range(0, total, chunk_size):
        chunk = codes[i:i+chunk_size]
        syms = [c if c.endswith(".T") else f"{c}.T" for c in chunk]
        log.info(f"[batch.chunk] {i}-{i+len(chunk)-1} ({len(chunk)})")

        # å–å¾—è¦å¦åˆ¤å®š
        to_fetch = []
        for c, s in zip(chunk, syms):
            if force_refresh:
                to_fetch.append(s); continue
            raw = raw_map.get(c)
            if not raw:
                to_fetch.append(s); continue
            fin_d = fin_date_map.get(c)
            if not fin_d:
                to_fetch.append(s); continue
            try:
                fd = date.fromisoformat(str(fin_d))
                if (dtm.date.today() - fd).days >= 30:
                    to_fetch.append(s)
            except Exception:
                to_fetch.append(s)
        log.info(f"[fetch.plan] need_fetch={len(to_fetch)}/{len(chunk)}")

        # å–å¾—
        fetched_raw = {}
        if to_fetch:
            if False:
                log.error("[fetch] yahooquery not installed; skip this chunk fetch")
                errors += len(to_fetch)
            else:
                try:
                    tk = YQ(to_fetch, max_workers=YQ_MAX_WORKERS)
                    quotes = getattr(tk, "quotes", {}) or {}
                    try: bs = tk.balance_sheet()
                    except Exception: bs = None
                    try: cf = tk.cash_flow()
                    except Exception: cf = None
                    try: divs = tk.dividends()
                    except Exception: divs = None

                    for s in to_fetch:
                        q = quotes.get(s) if isinstance(quotes, dict) else quotes
                        b = bs.get(s) if isinstance(bs, dict) else bs
                        cflow = cf.get(s) if isinstance(cf, dict) else cf
                        d = divs.get(s) if isinstance(divs, dict) else divs
                        fetched_raw[s] = {"quotes": q, "balance_sheet": b, "cashflow": cflow, "dividends": d}
                    log.info(f"[fetch.done] symbols={len(to_fetch)}")
                except Exception as e:
                    log.exception(f"[fetch.error] {e}")
                    errors += len(to_fetch)

        # è§£æâ†’DBè¡Œ
        metrics_rows = []; flags_rows = []
        for c, s in zip(chunk, syms):
            processed += 1
            raw_text = None; sym_raw = None
            if s in fetched_raw:
                sym_raw = fetched_raw[s]
                try:
                    raw_text = json.dumps(sym_raw, default=str, ensure_ascii=False)
                except Exception:
                    raw_text = None
            else:
                raw_text = raw_map.get(c)

            marketCap = None; equity_ratio = None; ocf_recent_val = None; ocf_4q_val = None
            div_1y = 0.0; buyback_4q = 0.0

            try:
                if sym_raw is not None:
                    # --- quotes ---
                    q = sym_raw.get("quotes") or {}
                    mc = None
                    if isinstance(q, dict):
                        mc = q.get("marketCap") or q.get("market_cap") or q.get("regularMarketMarketCap")
                    marketCap = _safe_num(mc)

                    # --- balance_sheet ---
                    bsobj = sym_raw.get("balance_sheet")
                    if bsobj is not None:
                        assets = _get_from_periods(bsobj, ["totalAssets","Total Assets","total_assets"])
                        equity = _get_from_periods(bsobj, ["totalStockholderEquity","Total Stockholder Equity","total_equity"])
                        if (assets is None or equity is None) and _is_nonempty_df(bsobj):
                            assets = assets or _yf_pick_recent_from_df(bsobj, ["totalAssets","Total Assets","total_assets"])
                            equity = equity or _yf_pick_recent_from_df(bsobj, ["totalStockholderEquity","Total Stockholder Equity","total_equity"])
                        if assets and equity:
                            try: equity_ratio = float(equity) / float(assets) * 100.0
                            except Exception: equity_ratio = None

                    # --- cash_flow ---
                    cfobj = sym_raw.get("cashflow")
                    if cfobj is not None:
                        ocf_recent = _get_from_periods(cfobj, ["operatingCashflow","Operating Cash Flow","operatingCashFlow","OperatingCashFlow"])
                        ocf_4q_val = _sum_recent(cfobj, ["operatingCashflow","Operating Cash Flow","operatingCashFlow","OperatingCashFlow"], 4) or 0.0
                        ocf_recent_val = _safe_num(ocf_recent)
                        buy = _sum_recent(cfobj, ["repurchaseOfStock","Repurchase Of Stock","repurchaseOfCapitalStock","RepurchaseOfCapitalStock"], 4)
                        buyback_4q = float(buy) if buy is not None else 0.0

                        if (ocf_recent_val is None or ocf_4q_val == 0.0) and _is_nonempty_df(cfobj):
                            ocf_recent_val = ocf_recent_val if ocf_recent_val is not None else _yf_pick_recent_from_df(
                                cfobj, ["operatingCashflow","Operating Cash Flow","operatingCashFlow","OperatingCashFlow"]
                            )
                            if not ocf_4q_val:
                                ocf_4q_val = _yf_sum_quarters_df(cfobj, ["operatingCashflow","Operating Cash Flow","operatingCashFlow","OperatingCashFlow"], 4)
                            if buyback_4q == 0.0:
                                buyback_4q = _yf_sum_quarters_df(cfobj, ["repurchaseOfStock","Repurchase Of Stock",
                                                                         "repurchaseOfCapitalStock","RepurchaseOfCapitalStock"], 4)

                    # --- dividends ---
                    divobj = sym_raw.get("dividends")
                    div_1y = _sum_dividends_1y(divobj, one_year_ago)

                else:
                    # æ—¢å­˜ raw ã‹ã‚‰è§£æ
                    parsed = None
                    if raw_text:
                        try:
                            if isinstance(raw_text, str) and raw_text.strip().startswith("{"):
                                parsed = json.loads(raw_text)
                            elif isinstance(raw_text, dict):
                                parsed = raw_text
                        except Exception as e:
                            log.debug(f"[parse.fallback.warn] {c} json.loads failed: {e}")

                    if parsed is not None and isinstance(parsed, dict):
                        # --- quotes ---
                        q = parsed.get("quotes") or {}
                        marketCap = _safe_num(q.get("marketCap") or q.get("market_cap") or q.get("regularMarketMarketCap"))

                        # --- balance_sheet ---
                        bsobj = parsed.get("balance_sheet")
                        if bsobj is not None:
                            assets = _get_from_periods(bsobj, ["totalAssets","Total Assets","total_assets"])
                            equity = _get_from_periods(bsobj, ["totalStockholderEquity","Total Stockholder Equity","total_equity"])
                            if (assets is None or equity is None) and _is_nonempty_df(bsobj):
                                assets = assets or _yf_pick_recent_from_df(bsobj, ["totalAssets","Total Assets","total_assets"])
                                equity = equity or _yf_pick_recent_from_df(bsobj, ["totalStockholderEquity","Total Stockholder Equity","total_equity"])
                            if assets and equity:
                                try: equity_ratio = float(equity) / float(assets) * 100.0
                                except Exception: equity_ratio = None

                        # --- cash_flow ---
                        cfobj = parsed.get("cashflow")
                        if cfobj is not None:
                            ocf_recent = _get_from_periods(cfobj, ["operatingCashflow","Operating Cash Flow","operatingCashFlow","OperatingCashFlow"])
                            ocf_4q_val = _sum_recent(cfobj, ["operatingCashflow","Operating Cash Flow","operatingCashFlow","OperatingCashFlow"], 4) or 0.0
                            ocf_recent_val = _safe_num(ocf_recent)
                            buyback_4q = _sum_recent(cfobj, ["repurchaseOfStock","Repurchase Of Stock","repurchaseOfCapitalStock","RepurchaseOfCapitalStock"], 4) or 0.0

                            if (ocf_recent_val is None or ocf_4q_val == 0.0) and _is_nonempty_df(cfobj):
                                ocf_recent_val = ocf_recent_val if ocf_recent_val is not None else _yf_pick_recent_from_df(
                                    cfobj, ["operatingCashflow","Operating Cash Flow","operatingCashFlow","OperatingCashFlow"]
                                )
                                if not ocf_4q_val:
                                    ocf_4q_val = _yf_sum_quarters_df(cfobj, ["operatingCashflow","Operating Cash Flow","operatingCashFlow","OperatingCashFlow"], 4)
                                if buyback_4q == 0.0:
                                    buyback_4q = _yf_sum_quarters_df(cfobj, ["repurchaseOfStock","Repurchase Of Stock",
                                                                             "repurchaseOfCapitalStock","RepurchaseOfCapitalStock"], 4)

                        # --- dividends ---
                        divobj = parsed.get("dividends")
                        div_1y = _sum_dividends_1y(divobj, one_year_ago)

            except Exception as e:
                log.debug(f"[parse.warn] {c} parse error: {e}")

            # åˆ¤å®š
            mcap_ok = False
            if marketCap is not None:
                try:
                    if marketCap >= 300e8: mcap_ok = True
                except Exception:
                    mcap_ok = False

            ok_equity = (equity_ratio is not None) and (equity_ratio >= 60.0)
            ok_ocf    = (ocf_recent_val is not None and ocf_recent_val > 0) or (ocf_4q_val is not None and ocf_4q_val > 0)
            ok_return = (div_1y > 0) or (buyback_4q < 0)

            # è©³ç´°ãƒ­ã‚°ï¼ˆéŠ˜æŸ„ã”ã¨ï¼‰
            log.debug(
                f"[judge] {c} "
                f"EQ={_fmt(equity_ratio)} "
                f"OCF1={_fmt(ocf_recent_val)} "
                f"OCF4Q={_fmt(ocf_4q_val)} "
                f"DIV1Y={_fmt(div_1y,1)} "
                f"BUY4Q={_fmt(buyback_4q,1)} "
                f"MCAP={'NA' if marketCap is None else int(marketCap)} "
                f"flags:EQ={ok_equity} OCF={ok_ocf} RET={ok_return} MCAP_OK={mcap_ok}"
            )

            today_iso = dtm.date.today().isoformat()
            metrics_rows.append((
                float(equity_ratio) if (equity_ratio is not None) else None,
                float(ocf_recent_val) if (ocf_recent_val is not None) else None,
                float(ocf_4q_val) if (ocf_4q_val is not None) else None,
                float(div_1y) if (div_1y is not None) else 0.0,
                float(buyback_4q) if (buyback_4q is not None) else 0.0,
                today_iso,
                raw_text,
                c
            ))

            if all([ok_equity, ok_ocf, ok_return, mcap_ok]):
                reasons = []
                if ok_equity: reasons.append("è‡ªå·±è³‡æœ¬æ¯”ç‡â‰¥60")
                if ok_ocf:    reasons.append("å–¶æ¥­CFé»’å­—")
                if ok_return: reasons.append("é…å½“/è‡ªç¤¾æ ªè²·ã„ã‚ã‚Š")
                if mcap_ok:   reasons.append("æ™‚ä¾¡ç·é¡â‰¥300å„„")
                flags_rows.append(("â—‹", " / ".join(reasons), c))
                log.info(f"[flag.ok] {c} æ—§ãƒ­ã‚¸ãƒƒã‚¯(å‚è€ƒ)=â—‹ reasons={'; '.join(reasons)}")
            else:
                miss = []
                if not ok_equity: miss.append("EQ<60 or NA")
                if not ok_ocf:    miss.append("OCF<=0 or NA")
                if not ok_return: miss.append("ç„¡é…/è²·æˆ»ã—ãªã—")
                if not mcap_ok:   miss.append("MCAP<300å„„ or NA")
                log.debug(f"[flag.ng] {c} reasons_miss={'; '.join(miss)}")

        # commit
        try:
            commit_batch(metrics_rows, flags_rows)
        except Exception as e:
            log.exception(f"[DB.commit.error] chunk {i}-{i+len(chunk)-1}: {e}")
            errors += 1

        log.info(f"[batch.progress] processed={min(i+chunk_size, total)}/{total} updated_rows={updated_rows} flags={flags_set} errors={errors}")
        time.sleep(sleep_between_chunks)

    summary = {"total": total, "processed": processed, "updated_rows": updated_rows, "flags_set": flags_set, "errors": errors}
    log.info(f"[batch.done] {summary}")
    return summary

# --- END: batch_update_all_financials ---

# ===== fetch_all é€£æº =====
def _run_fetch_all(fetch_path: str | None = None,
                   extra_args: list[str] | None = None,
                   timeout_sec: int | None = None,
                   use_lock: bool = True) -> None:
    """
    è‡ªåˆ†ã¨åŒã˜ Python ã§ fetch_all.py ã‚’ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹å®Ÿè¡Œã€‚
    ãƒ»stdout ã‚’é€æ¬¡ãã®ã¾ã¾ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã¸æµã™
    ãƒ»ç•°å¸¸çµ‚äº†/ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚ã¯ä¾‹å¤–
    ãƒ»å¤šé‡èµ·å‹•ã‚’é¿ã‘ã‚‹ãŸã‚ lock ãƒ•ã‚¡ã‚¤ãƒ«(ä»»æ„)ã‚’åˆ©ç”¨
    """
    # 1) ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å ´æ‰€ã‚’è§£æ±ºï¼ˆæŒ‡å®šãŒãªã‘ã‚Œã°è‡ªåˆ†ã¨åŒã˜ãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¢ã™ï¼‰
    if fetch_path is None:
        base_dir = os.path.dirname(os.path.abspath(__file__))
        cand = os.path.join(base_dir, "fetch_all.py")
        if not os.path.exists(cand):
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ç’°å¢ƒã®çµ¶å¯¾ãƒ‘ã‚¹ä¾‹ï¼ˆå¿…è¦ãªã‚‰ã“ã“ã‚’ã‚ãªãŸã®ç’°å¢ƒã«åˆã‚ã›ã¦å›ºå®šã‚‚å¯ï¼‰
            cand = r"H:\desctop\æ ªæ”»ç•¥\1-ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°è‡ªå‹•åŒ–ãƒ—ãƒ­ã‚°ãƒ©ãƒ \fetch_all.py"
        fetch_path = cand

    if not os.path.exists(fetch_path):
        raise FileNotFoundError(f"fetch_all.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {fetch_path}")

    py = sys.executable  # ã„ã¾å®Ÿè¡Œä¸­ã® Python ã‚’ä½¿ã†ï¼ˆä»®æƒ³ç’°å¢ƒã®å–ã‚Šé•ãˆé˜²æ­¢ï¼‰
    cmd = [py, "-u", fetch_path]
    if extra_args:
        cmd.extend(extra_args)

    # 2) ãƒ­ãƒƒã‚¯ï¼ˆç°¡æ˜“ï¼‰
    lock_path = os.path.splitext(fetch_path)[0] + ".lock"  # ä¾‹: fetch_all.lock
    if use_lock:
        if os.path.exists(lock_path):
            # å¤ã„ãƒ­ãƒƒã‚¯ã¯5æ™‚é–“ã§ç„¡è¦–ï¼ˆé©å½“ãªä¿é™ºï¼‰
            try:
                if time.time() - os.path.getmtime(lock_path) < 5*60*60:
                    print(f"[fetch_all] lockæ¤œçŸ¥ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—: {lock_path}")
                    return
            except Exception:
                pass
        # ä½œæˆ
        try:
            with open(lock_path, "w", encoding="utf-8") as lf:
                lf.write(f"pid={os.getpid()}\nstart={time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        except Exception:
            pass

    print(f"[fetch_all] å®Ÿè¡Œé–‹å§‹: {cmd}")
    proc = None
    try:
        proc = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            bufsize=1,
            universal_newlines=True,
        )
        start = time.time()
        # é€æ¬¡å‡ºåŠ›
        for line in proc.stdout:
            print(line.rstrip())
            if timeout_sec and (time.time() - start) > timeout_sec:
                proc.kill()
                raise TimeoutError(f"fetch_all ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆ{timeout_sec}sï¼‰")

        rc = proc.wait()
        if rc != 0:
            raise RuntimeError(f"fetch_all ç•°å¸¸çµ‚äº†: returncode={rc}")

        print("[fetch_all] æ­£å¸¸çµ‚äº†")
    finally:
        # ãƒ­ãƒƒã‚¯è§£é™¤
        if use_lock:
            try:
                if os.path.exists(lock_path):
                    os.remove(lock_path)
            except Exception:
                pass

# ===== ã‚«ãƒ–ã‚¿ãƒ³å‘¼ã³å‡ºã—

def run_fundamental_daily(force: bool = False):
    today = dtm.date.today()

    # 1) mtimeã§åˆ¤å®šï¼ˆä¸­èº«ã¯è¦‹ãªã„ï¼‰
    if not force and MARKER_FILE.exists():
        mtime = dtm.datetime.fromtimestamp(MARKER_FILE.stat().st_mtime).date()
        print(f"[fundamental] marker_mtime={mtime} today={today}")
        if mtime == today:
            print("[fundamental] ä»Šæ—¥ã™ã§ã«å®Ÿè¡Œæ¸ˆã¿ â†’ ã‚¹ã‚­ãƒƒãƒ—")
            return

    # 2) å®Ÿè¡Œ
    try:
        print(f"[fundamental] å®Ÿè¡Œé–‹å§‹: {FUND_SCRIPT}")
        subprocess.run(["python", FUND_SCRIPT], check=True)
        print("[fundamental] æ ªæ¢ãƒ•ã‚¡ãƒ³ãƒ€ å…¨éŠ˜æŸ„å‡¦ç† OK")
    except subprocess.CalledProcessError as e:
        print(f"[fundamental][ERROR] å­ãƒ—ãƒ­ã‚»ã‚¹å¤±æ•—: returncode={e.returncode}")
        return

    # 3) ãƒãƒ¼ã‚«ãƒ¼æ›´æ–°ï¼ˆtouchç›¸å½“ï¼‰
    MARKER_FILE.parent.mkdir(parents=True, exist_ok=True)
    MARKER_FILE.touch()  # ä¸­èº«ã¯ä¸è¦ã€æ›´æ–°æ—¥æ™‚ã ã‘ä½¿ã†
    print(f"[fundamental] ãƒãƒ¼ã‚«ãƒ¼æ›´æ–°(mtime): {MARKER_FILE}")

# ======= æ±ºç®—é–¢é€£ =======

#  signals_logä¾å­˜
def build_earnings_edge_scores(conn, lookback_n=6, follow_days=5, since="2022-01-01"):
    """
    signals_log('æ±ºç®—')ã«ä¾å­˜ã›ãšã€earnings_eventsÃ—price_history ã‹ã‚‰
    å„ã‚³ãƒ¼ãƒ‰ã®ç›´è¿‘Nå›ã®â€œå‹ç‡/ã‚®ãƒ£ãƒƒãƒ—å¹³å‡/ãƒ•ã‚©ãƒ­ãƒ¼å¹³å‡/ç›´è¿‘é€£å‹â€ã‚’ã‚ªãƒ³ã‚¶ãƒ•ãƒ©ã‚¤ã§ç®—å‡ºã€‚
    DBã«ã¯æ›¸ãè¾¼ã¾ãªã„ï¼ˆè¿”ã‚Šå€¤DFã®ã¿ï¼‰ã€‚
    """

    ev = pd.read_sql_query(f"""
        SELECT ã‚³ãƒ¼ãƒ‰, DATE(æå‡ºæ™‚åˆ») AS ev_date
        FROM earnings_events
        WHERE DATE(æå‡ºæ™‚åˆ») >= DATE(?)
        ORDER BY ã‚³ãƒ¼ãƒ‰, æå‡ºæ™‚åˆ» DESC
    """, conn, params=[since])

    if ev.empty:
        return pd.DataFrame(columns=["ã‚³ãƒ¼ãƒ‰","edge_score"])

    codes = ev["ã‚³ãƒ¼ãƒ‰"].astype(str).unique().tolist()
    ph = pd.read_sql_query(f"""
        SELECT ã‚³ãƒ¼ãƒ‰, substr(æ—¥ä»˜,1,10) AS æ—¥ä»˜, å§‹å€¤, é«˜å€¤, å®‰å€¤, çµ‚å€¤
        FROM price_history
        WHERE ã‚³ãƒ¼ãƒ‰ IN ({",".join(["?"]*len(codes))})
        ORDER BY ã‚³ãƒ¼ãƒ‰, æ—¥ä»˜
    """, conn, params=codes)

    if ph.empty:
        # price_history ãŒç„¡ã„ã¨è¨ˆç®—ä¸å¯ â†’ ã‚¨ãƒƒã‚¸0æ‰±ã„ï¼ˆç©ºDFï¼‰
        return pd.DataFrame(columns=["ã‚³ãƒ¼ãƒ‰","edge_score"])

    ph["æ—¥ä»˜"] = pd.to_datetime(ph["æ—¥ä»˜"], format="%Y-%m-%d", errors="coerce")
    ev["ev_date"] = pd.to_datetime(ev["ev_date"], errors="coerce")

    outs = []
    for code, g_ev in ev.groupby("ã‚³ãƒ¼ãƒ‰", sort=False):
        g_ph = ph[ph["ã‚³ãƒ¼ãƒ‰"]==code].dropna(subset=["æ—¥ä»˜"]).sort_values("æ—¥ä»˜").reset_index(drop=True)
        if g_ph.empty:
            continue
        g_ph["idx"] = range(len(g_ph))

        # ç›´è¿‘Nå›ã®ã‚¤ãƒ™ãƒ³ãƒˆã ã‘è¦‹ã‚‹
        g_ev = g_ev.head(max(lookback_n, 6))  # å°‘ã—å¤šã‚ã«æ‹¾ã£ã¦ãŠã
        rets, follows, wins = [], [], []

        for _, row in g_ev.iterrows():
            d0 = row["ev_date"]
            if pd.isna(d0):
                continue
            after = g_ph[g_ph["æ—¥ä»˜"] > d0]
            if after.empty:
                continue
            d1_idx = int(after["idx"].iloc[0])
            if d1_idx == 0:
                continue
            d0_idx = d1_idx - 1

            try:
                prev_close = float(g_ph.loc[d0_idx, "çµ‚å€¤"])
                next_close = float(g_ph.loc[d1_idx, "çµ‚å€¤"])
            except Exception:
                continue

            ret_close_pct = ((next_close/prev_close) - 1.0) * 100.0
            hi_window = g_ph.loc[d1_idx : d1_idx + follow_days - 1, "é«˜å€¤"]
            follow_hi_pct = None if hi_window.empty else ((float(hi_window.max())/next_close) - 1.0) * 100.0

            rets.append(ret_close_pct)
            follows.append(follow_hi_pct)
            win = (ret_close_pct is not None and ret_close_pct >= 3.0) or\
                  (follow_hi_pct is not None and follow_hi_pct >= 7.0)
            wins.append(1 if win else 0)

        if not rets and not follows:
            continue

        # ç›´è¿‘Nä»¶ã«çµã£ã¦ã‚¹ã‚³ã‚¢åŒ–
        wins2 = wins[:lookback_n]
        rets2 = [x for x in rets[:lookback_n] if x is not None]
        fol2  = [x for x in follows[:lookback_n] if x is not None]

        win_rate   = (sum(wins2)/len(wins2)) if wins2 else 0.0
        gap_mean   = (sum(rets2)/len(rets2)) if rets2 else 0.0
        follow_mean= (sum(fol2)/len(fol2)) if fol2 else 0.0
        cons       = (sum(wins2[:3])/3.0) if len(wins2)>=3 else (sum(wins2)/max(1,len(wins2)))

        s = (win_rate*60.0) + (max(0.0,gap_mean)/6.0*20.0) + (max(0.0,follow_mean)/10.0*10.0) + (cons*10.0)
        outs.append((code, round(min(100.0, max(0.0, s)), 1)))

    return pd.DataFrame(outs, columns=["ã‚³ãƒ¼ãƒ‰","edge_score"])

def build_pre_earnings_rank(conn: sqlite3.Connection) -> pd.DataFrame:
    """
    â€œæ±ºç®—å‰ã®è‰¯ã•â€ã‚’å…¨éŠ˜æŸ„ã«ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ï¼š
    äº‹å‰ã‚¹ã‚³ã‚¢ = 0.6*edge_score + 0.4*momentum_score
    momentum_score ã¯ã€Œå³è‚©ä¸ŠãŒã‚Š/HHè¿‘æ¥/å‡ºæ¥é«˜å¢—åŠ ã€ã‹ã‚‰ç°¡æ˜“åˆæˆï¼ˆ0-100ï¼‰
    """
    edge = build_earnings_edge_scores(conn)  # ã‚³ãƒ¼ãƒ‰, edge_score

    # ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ å´ï¼ˆæ—¢å­˜ã‚«ãƒ©ãƒ ã‚’åˆ©ç”¨ï¼‰
    q = """
       SELECT ã‚³ãƒ¼ãƒ‰, éŠ˜æŸ„å, ç¾åœ¨å€¤, å‰æ—¥çµ‚å€¤æ¯”ç‡, å‡ºæ¥é«˜, å³è‚©ä¸ŠãŒã‚Šã‚¹ã‚³ã‚¢
       FROM screener
    """
    s = pd.read_sql_query(q, conn)
    if s.empty:
        s = pd.DataFrame(columns=["ã‚³ãƒ¼ãƒ‰"])
    # é«˜å€¤æ¥è¿‘åº¦ï¼šç›´è¿‘60æ—¥é«˜å€¤æ¯”ï¼ˆprice_historyã‹ã‚‰ï¼‰
    hi = pd.read_sql_query("""
      WITH z AS(
        SELECT ã‚³ãƒ¼ãƒ‰, MAX(æ—¥ä»˜) AS d FROM price_history GROUP BY ã‚³ãƒ¼ãƒ‰
      )
      SELECT p.ã‚³ãƒ¼ãƒ‰, p.çµ‚å€¤ AS close, (
               SELECT MAX(é«˜å€¤) FROM price_history q
               WHERE q.ã‚³ãƒ¼ãƒ‰=p.ã‚³ãƒ¼ãƒ‰ AND q.æ—¥ä»˜ >= date(p.æ—¥ä»˜, '-60 day')
             ) AS hh60
      FROM price_history p
      JOIN z ON p.ã‚³ãƒ¼ãƒ‰=z.ã‚³ãƒ¼ãƒ‰ AND p.æ—¥ä»˜=z.d
    """, conn)
    if not hi.empty:
        hi["near_hh"] = (hi["close"]/hi["hh60"]-1.0)*100.0
        hi["near_hh_score"] = hi["near_hh"].apply(lambda x: 100.0 if x>=-1.0 else (50.0 if x>=-5.0 else 0.0))
    else:
        hi = pd.DataFrame(columns=["ã‚³ãƒ¼ãƒ‰","near_hh_score"])

    # å‡ºæ¥é«˜ãƒ–ãƒ¼ã‚¹ãƒˆï¼ˆéå»20æ—¥ç§»å‹•å¹³å‡æ¯”ï¼‰
    vol = pd.read_sql_query("""
      WITH cur AS(
        SELECT ã‚³ãƒ¼ãƒ‰, MAX(æ—¥ä»˜) d FROM price_history GROUP BY ã‚³ãƒ¼ãƒ‰
      ),
      v AS(
        SELECT p.ã‚³ãƒ¼ãƒ‰, p.å‡ºæ¥é«˜ AS v0,
               (SELECT AVG(å‡ºæ¥é«˜) FROM price_history q WHERE q.ã‚³ãƒ¼ãƒ‰=p.ã‚³ãƒ¼ãƒ‰ AND q.æ—¥ä»˜>=date(p.æ—¥ä»˜,'-20 day') AND q.æ—¥ä»˜<p.æ—¥ä»˜) AS v20
        FROM price_history p
        JOIN cur ON p.ã‚³ãƒ¼ãƒ‰=cur.ã‚³ãƒ¼ãƒ‰ AND p.æ—¥ä»˜=cur.d
      )
      SELECT ä»£ç  as ã‚³ãƒ¼ãƒ‰, v0, v20 FROM (
        SELECT ã‚³ãƒ¼ãƒ‰ as ä»£ç , v0, v20 FROM v
      )
    """, conn)
    # SQLiteäº’æ›ã®ãŸã‚åˆ¥åçµŒç”±

    if not vol.empty:
        vol["boost"] = vol.apply(lambda r: (r["v0"]/max(1.0, r["v20"])) if r["v20"] else 1.0, axis=1)
        vol["vol_score"] = vol["boost"].apply(lambda x: 100.0 if x>=3.0 else (70.0 if x>=2.0 else (40.0 if x>=1.3 else 0.0)))
    else:
        vol = pd.DataFrame(columns=["ã‚³ãƒ¼ãƒ‰","vol_score"])

    # çµåˆ
    df = s.merge(edge, on="ã‚³ãƒ¼ãƒ‰", how="left").merge(hi[["ã‚³ãƒ¼ãƒ‰","near_hh_score"]], on="ã‚³ãƒ¼ãƒ‰", how="left").merge(vol[["ã‚³ãƒ¼ãƒ‰","vol_score"]], on="ã‚³ãƒ¼ãƒ‰", how="left")
    df["edge_score"] = df["edge_score"].fillna(0.0)
    # å³è‚©ã‚¹ã‚³ã‚¢ãŒã‚ã‚Œã°å„ªé‡
    df["mom_raw"] = df[["å³è‚©ä¸ŠãŒã‚Šã‚¹ã‚³ã‚¢"]].fillna(0.0).clip(lower=0, upper=100).iloc[:,0]*0.6 + df["near_hh_score"].fillna(0.0)*0.25 + df["vol_score"].fillna(0.0)*0.15
    df["momentum_score"] = df["mom_raw"].clip(0,100)
    df["pre_score"] = (0.6*df["edge_score"] + 0.4*df["momentum_score"]).round(1)
    df = df.sort_values(["pre_score"], ascending=False)
    print("pre_earn sample:", df.head(5).to_dict(orient="records"))
    cols = ["ã‚³ãƒ¼ãƒ‰","éŠ˜æŸ„å","pre_score","edge_score","momentum_score"]
    df = df
    return df[cols]

def yj_board(code: str, name: str):
    c = str(code).zfill(4)
    return f'<a href="https://finance.yahoo.co.jp/quote/{c}.T/bbs" target="_blank" rel="noopener">{name} <span class="code">({c})</span></a>'

def _build_preearn_fallback(conn):
    """
    ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼špreearn_rows ãŒç©ºã«ãªã£ãŸå ´åˆã€screener ã‹ã‚‰æš«å®šãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ä½œã‚‹ã€‚
    ãƒ»pre_score = å³è‚©ä¸ŠãŒã‚Šã‚¹ã‚³ã‚¢(ç„¡ã‘ã‚Œã°0)
    ãƒ»momentum_score = å³è‚©ä¸ŠãŒã‚Šã‚¹ã‚³ã‚¢
    ãƒ»edge_score = 0
    ãƒ»éŠ˜æŸ„ ã¯ Yahooãƒªãƒ³ã‚¯ä»˜ã
    è¿”ã‚Šå€¤: list[dict]
    """
    try:
        s = pd.read_sql_query(
            """
            SELECT ã‚³ãƒ¼ãƒ‰, éŠ˜æŸ„å, å³è‚©ä¸ŠãŒã‚Šã‚¹ã‚³ã‚¢
              FROM screener
            """, conn
        )
    except Exception:
        return []

    if s.empty:
        return []

    def _mk(code, name):
        c = str(code).zfill(4)
        nm = name if (isinstance(name, str) and name) else str(code)
        return f'<a href="https://finance.yahoo.co.jp/quote/{c}.T" target="_blank" rel="noopener">{nm} <span class="code">({c})</span></a>'

    s["éŠ˜æŸ„"] = [_mk(c, n) for c, n in zip(s["ã‚³ãƒ¼ãƒ‰"], s.get("éŠ˜æŸ„å", ""))]
    s["edge_score"] = 0.0
    s["momentum_score"] = s["å³è‚©ä¸ŠãŒã‚Šã‚¹ã‚³ã‚¢"].fillna(0.0)
    s["pre_score"] = s["momentum_score"].fillna(0.0).round(1)
    s = s.sort_values(["pre_score"], ascending=False)
    out = s[["éŠ˜æŸ„", "pre_score", "edge_score", "momentum_score"]].head(200)
    # äºˆæ¸¬ã‚¿ãƒ–äº’æ›ã®5åˆ—ã‚’ãƒ€ãƒŸãƒ¼ã§ä»˜ä¸ï¼ˆç©ºæ¬„åŒ–ã‚’é¿ã‘ã‚‹ï¼‰
    out["ã‚¹ã‚³ã‚¢ç†ç”±"] = "æ ¹æ‹ è–„ã‚ï¼ˆæš«å®šï¼‰"
    out["äºˆæ¸¬ãƒ’ãƒ³ãƒˆ"] = ""
    out["æœŸå¾…æ ªä¾¡"]   = float("nan")
    out["ä¿®æ­£è¦‹é€šã—"] = "ä¸­ç«‹"
    out["éç†±åº¦"]     = "ä¸­ç«‹"

    # JSONåŒ–ã§ NaN ã‚’å¼¾ã
    return [{k: (None if (isinstance(v, float) and (v != v)) else v) for k, v in r.items()}
            for r in out.to_dict("records")]
def build_earnings_tables(conn):
    """
    å®Ÿç¸¾(ç›´è¿‘1æ—¥) ã¨ äºˆæ¸¬ãƒ©ãƒ³ã‚­ãƒ³ã‚° ã‚’è¿”ã™ (ev_df, pre_df)
    """

    # ========== å®Ÿç¸¾ï¼ˆåˆ—ã®å­˜åœ¨ã‚’å‹•çš„ã«ç¢ºèªã—ã¦SELECTï¼‰ ==========
    # 1) å®Ÿãƒ†ãƒ¼ãƒ–ãƒ«ã®åˆ—åã‚’å–å¾—
    have = set(cols_df["name"].astype(str))

    base_cols = ["ã‚³ãƒ¼ãƒ‰", "æå‡ºæ™‚åˆ»", "ã‚¿ã‚¤ãƒˆãƒ«", "ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ"]  # å¿…é ˆå€™è£œ
    opt_cols  = ["ãƒ’ãƒƒãƒˆKW"]                                        # ã‚ã‚Œã°ä½¿ã†
    sel_cols  = [c for c in base_cols + opt_cols if c in have]      # å®Ÿåœ¨åˆ—ã ã‘

    # 2) SQLã‚’å®Ÿåœ¨åˆ—ã ã‘ã§ä½œæˆ
    ev_sql = f"""
      SELECT {", ".join("e."+c for c in sel_cols)}
      FROM earnings_events e
      WHERE e.æå‡ºæ™‚åˆ» >= datetime(date('now','-1 day') || ' 00:00:00')
      ORDER BY e.æå‡ºæ™‚åˆ» DESC
    """
    ev_df = pd.read_sql_query(ev_sql, conn) if sel_cols else pd.DataFrame()
    ev_df = ev_df

    if not ev_df.empty:
        names = pd.read_sql_query("SELECT ã‚³ãƒ¼ãƒ‰, éŠ˜æŸ„å FROM screener", conn)
        names = names
        ev_df = ev_df
        ev_df = ev_df.merge(names, on="ã‚³ãƒ¼ãƒ‰", how="left")

        # æ™‚åˆ»æ•´å½¢ï¼ˆå¤±æ•—æ™‚ã¯å…ƒã®å€¤ï¼‰
        ts = pd.to_datetime(ev_df.get("æå‡ºæ™‚åˆ»"), errors="coerce")
        ev_df["æ™‚åˆ»"] = ts.dt.strftime("%Y/%m/%d %H:%M").fillna(ev_df.get("æå‡ºæ™‚åˆ»", "").astype(str))

        # éŠ˜æŸ„ãƒªãƒ³ã‚¯ï¼ˆyj_board æœªå®šç¾©ã§ã‚‚è½ã¡ãªã„ï¼‰
        def _mk_name(code, name):
            label = name if (isinstance(name, str) and name) else str(code)
            try:
                return yj_board(code, label)
            except Exception:
                return label

        ev_df["éŠ˜æŸ„"] = [_mk_name(c, n) for c, n in zip(ev_df["ã‚³ãƒ¼ãƒ‰"], ev_df.get("éŠ˜æŸ„å", ""))]
        ev_df = ev_df[["éŠ˜æŸ„", "ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ", "ã‚¿ã‚¤ãƒˆãƒ«", "æ™‚åˆ»"]]
    else:
        ev_df = pd.DataFrame(columns=["éŠ˜æŸ„", "ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ", "ã‚¿ã‚¤ãƒˆãƒ«", "æ™‚åˆ»"])

    # ========== äºˆæ¸¬ ==========
    pre_df = build_pre_earnings_rank(conn)
    pre_df = pre_df

    if not pre_df.empty:
        # éŠ˜æŸ„åãŒç„¡ã‘ã‚Œã°ä»˜ä¸
        if "éŠ˜æŸ„å" not in pre_df.columns:
            names = pd.read_sql_query("SELECT ã‚³ãƒ¼ãƒ‰, éŠ˜æŸ„å FROM screener", conn)
            names = names
            pre_df = pre_df
            pre_df = pre_df.merge(names, on="ã‚³ãƒ¼ãƒ‰", how="left")

        def _mk_name2(code, name):
            label = name if (isinstance(name, str) and name) else str(code)
            try:
                return yj_board(code, label)
            except Exception:
                return label

        pre_df["éŠ˜æŸ„"] = [_mk_name2(c, n) for c, n in zip(pre_df["ã‚³ãƒ¼ãƒ‰"], pre_df.get("éŠ˜æŸ„å", ""))]
        pre_df = pre_df[["éŠ˜æŸ„", "pre_score", "edge_score", "momentum_score"]].head(200)
    else:
        pre_df = pd.DataFrame(columns=["éŠ˜æŸ„", "pre_score", "edge_score", "momentum_score"])
    
    print("[dbg] ev/pre rows:", len(ev_df), len(pre_df))
    return ev_df, pre_df

# ===================== ï¼ˆæ±ºç®—ãƒªã‚¹ãƒˆï¼‰ =====================

def _guess_sentiment_by_title(title: str) -> str:
    t = title or ""
    if any(k in t for k in _POS_KEYS): return "Bullish"
    if any(k in t for k in _NEG_KEYS): return "Bearish"
    return "Neutral"

def _edinet_list(date_str: str) -> list:
    """
    EDINET ã®ãƒ¡ã‚¿ä¸€è¦§ã‚’1æ—¥åˆ†å–å¾—ï¼ˆtype=2=ä¸€è¦§ï¼‰
    """
    url = "https://disclosure.edinet-fsa.go.jp/api/v2/documents.json"
    params = {"date": date_str, "type": 2}
    r = requests.get(url, params=params, timeout=30)
    r.raise_for_status()
    j = r.json() if r.headers.get("Content-Type","").startswith("application/json") else {}
    return j.get("results", [])

def _is_kessan_like(doc: dict) -> bool:
    desc = (doc.get("docDescription") or "")
    if _DECISION_PAT.search(desc):
        return True
    # formCode/ordinanceCode ã§å³å¯†åŒ–ã—ãŸã„å ´åˆã¯ã“ã“ã«è¿½åŠ 
    return False

def _normalize_sec_code(sec: str) -> str | None:
    """
    EDINETã® secCode ã‚’ 4æ¡ã«æ­£è¦åŒ–ï¼ˆæ ªå¼ä»¥å¤–ã¯ Noneï¼‰
    """
    if not sec: return None
    s = str(sec).strip()
    # å…ˆé ­0åŸ‹ã‚4æ¡ï¼ˆ5æ¡ä»¥ä¸Šã¯ETF/æŠ•ä¿¡ãªã©ã®å¯èƒ½æ€§ãŒé«˜ã„ã®ã§é™¤å¤–ï¼‰
    if s.isdigit() and 1 <= len(s) <= 4:
        return s.zfill(4)
    return None

def _yahoo_quote_url(code4: str) -> str:
    # æ²ç¤ºæ¿ã¾ã§é£›ã°ã™ãªã‚‰ "/bbs" ã‚’æœ«å°¾ã«ä»˜ã‘ã‚‹ï¼ˆYahooå´ã®ä»•æ§˜å¤‰æ›´ã«æ³¨æ„ï¼‰
    return f"https://finance.yahoo.co.jp/quote/{code4}.T/bbs"

def _x_search_url(code4: str) -> str:
    # ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚° #ã‚³ãƒ¼ãƒ‰ ã§æ¤œç´¢
    return f"https://x.com/search?q=%23{code4}"

# ================= å®‰å…¨ç‰ˆï¼šç›´è¿‘æ±ºç®—èª­ã¿è¾¼ã¿ï¼ˆå®Œå…¨ç½®ãæ›ãˆï¼‰ =================

# ===== TDnetæ±ºç®—(earnings)ã®ç›´è¿‘Næ—¥ã‚’DBã‹ã‚‰èª­ã‚€ =====
def load_recent_earnings_from_db(db_path: str, days: int = 7, limit: int = 300):
    """
    earnings_events ã‚’â€œæ—¥æœ¬èªã‚«ãƒ©ãƒ ã®ã¿â€ã§èª­ã‚€ï¼ˆDBãƒ‘ã‚¹æŒ‡å®šç‰ˆï¼‰
    """

    if not os.path.exists(db_path):
        print(f"[earnings][WARN] DB not found: {db_path} â†’ []")
        return []

    conn = sqlite3.connect(db_path)
    try:
        conn.row_factory = sqlite3.Row
        cur = conn.cursor()

        # ãƒ†ãƒ¼ãƒ–ãƒ«å­˜åœ¨ãƒã‚§ãƒƒã‚¯
        cur.execute("SELECT 1 FROM sqlite_master WHERE type='table' AND name='earnings_events'")
        if not cur.fetchone():
            print("[earnings][WARN] table earnings_events not found â†’ []")
            return []

        since = (dtm.datetime.now() - dtm.timedelta(days=int(days))).strftime("%Y-%m-%d 00:00:00")

        cur.execute("""
            SELECT
              ã‚³ãƒ¼ãƒ‰,
              éŠ˜æŸ„å,
              ã‚¿ã‚¤ãƒˆãƒ«,
              ãƒªãƒ³ã‚¯,
              COALESCE(ç™ºè¡¨æ—¥æ™‚, æå‡ºæ™‚åˆ») AS ts,
              è¦ç´„,
              åˆ¤å®š,
              åˆ¤å®šã‚¹ã‚³ã‚¢,
              ç†ç”±JSON,
              æŒ‡æ¨™JSON,
              é€²æ—ç‡,
              ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ,
              ç´ ç‚¹
            FROM earnings_events
            WHERE COALESCE(ç™ºè¡¨æ—¥æ™‚, æå‡ºæ™‚åˆ») >= ?
            ORDER BY COALESCE(ç™ºè¡¨æ—¥æ™‚, æå‡ºæ™‚åˆ») DESC
            LIMIT ?
        """, (since, int(limit)))

        rows = []
        for row in cur.fetchall():
            d = dict(row)
            for k in ("ç†ç”±JSON", "æŒ‡æ¨™JSON"):
                if k in d and isinstance(d[k], str):
                    try:
                        d[k] = json.loads(d[k])
                    except Exception:
                        d[k] = [] if k == "ç†ç”±JSON" else {}
            rows.append({
                "ticker":   str(d.get("ã‚³ãƒ¼ãƒ‰") or "").zfill(4),
                "name":     d.get("éŠ˜æŸ„å") or "",
                "title":    d.get("ã‚¿ã‚¤ãƒˆãƒ«") or "",
                "link":     d.get("ãƒªãƒ³ã‚¯") or "",
                "time":     d.get("ts") or "",
                "summary":  d.get("è¦ç´„") or "",
                "verdict":  d.get("åˆ¤å®š") or "",
                "score_judge": int(d.get("åˆ¤å®šã‚¹ã‚³ã‚¢") or 0),
                "reasons":  d.get("ç†ç”±JSON") or [],
                "metrics":  d.get("æŒ‡æ¨™JSON") or {},
                "progress": d.get("é€²æ—ç‡"),
                "sentiment": d.get("ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ") or "",
                "score":     int(d.get("ç´ ç‚¹") or 0),
            })
        return rows
    finally:
        conn.close()

# ===== äºˆæ¸¬ã‚¿ãƒ–ã®ä»˜åŠ æƒ…å ±ï¼ˆåˆ—ï¼‰ã‚’ä½œã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ =====

def _mk_score_reason(rec: dict) -> str:
    # æ±ºç®—ã€ˆäºˆæ¸¬ã€‰ã‚¿ãƒ–å‘ã‘ã®â€œæ±ºç®—ã£ã½ã„â€æ ¹æ‹ æ–‡ã‚’ç”Ÿæˆã€‚
    # ä½¿ã†è¦ç´ : momentum_score / near_hh_score / vol_score / edge_score / ä¿®æ­£è¦‹é€šã—
    t = []
    def f(x):
        try:
            return float(x)
        except Exception:
            return 0.0

    mom = f(rec.get("momentum_score"))
    hh  = f(rec.get("near_hh_score"))
    vol = f(rec.get("vol_score"))
    edg = f(rec.get("edge_score"))
    bias = str(rec.get("ä¿®æ­£è¦‹é€šã—") or "").strip()

    # ---- ã‚¨ãƒƒã‚¸ï¼ˆéå»æ±ºç®—ã®â€œç¿Œæ—¥ãƒªã‚¿ãƒ¼ãƒ³â€ç”±æ¥ã‚¹ã‚³ã‚¢ï¼‰ ----
    if edg >= 85:
        t.append("éå»æ±ºç®—ã®ç¿Œæ—¥ãƒªã‚¿ãƒ¼ãƒ³å‹ç‡ãŒé«˜ã‚ï¼ˆã‚¢ãƒãƒãƒªãƒ¼è‰¯ï¼‰")
    elif edg >= 70:
        t.append("éå»æ±ºç®—ã®ç¿Œæ—¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒã‚„ã‚„è‰¯å¥½")

    # ---- éœ€çµ¦ï¼ˆç›´å‰ã®è²·ã„é›†ã‚/æœŸå¾…å…ˆè¡Œï¼‰ ----
    if mom >= 90:
        t.append("æ±ºç®—å‰ã®ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ å¼·")
    elif mom >= 80:
        t.append("éœ€çµ¦æ”¹å–„ï¼ˆè²·ã„å„ªå‹¢ï¼‰")

    if hh >= 90:
        t.append("60æ—¥é«˜å€¤åœï¼ˆã‚µãƒ—ãƒ©ã‚¤ã‚ºæœŸå¾…ã®è²·ã„ä¸ŠãŒã‚Šï¼‰")
    elif hh >= 50:
        t.append("60æ—¥é«˜å€¤ã«æ¥è¿‘")

    if vol >= 90:
        t.append("å‡ºæ¥é«˜ãƒ–ãƒ¼ã‚¹ãƒˆï¼ˆæ±ºç®—ãƒ—ãƒ¬ã‚¤ã®è³‡é‡‘æµå…¥ï¼‰")
    elif vol >= 70:
        t.append("å‡ºæ¥é«˜å¢—åŠ ")

    # ---- ä¿®æ­£ãƒã‚¤ã‚¢ã‚¹ã®è£œè¶³ ----
    if bias and bias != "ä¸­ç«‹":
        t.append(f"ä¿®æ­£è¦‹é€šã—:{bias}")

    return " / ".join(t) or "æ ¹æ‹ ä¸è¶³ï¼ˆæ±ºç®—å‰ã®æ°—é…ã¯å¼±ã‚ï¼‰"

def _mk_hint(rec: dict) -> str:
    # æ±ºç®—å‰ã®â€œé‹ç”¨ãƒ’ãƒ³ãƒˆâ€ã€‚ã‚¹ã‚³ã‚¢ã—ãã„å€¤ã§ç°¡æ˜“ã«åˆ†å²ã€‚
    # - ã‚¨ãƒƒã‚¸é«˜Ã—éœ€çµ¦å¼·: ãƒ–ãƒ¬ã‚¤ã‚¯ç‹™ã„ or ç›´å‰åˆ†å‰²IN
    # - ã‚¨ãƒƒã‚¸ä¸­Ã—éœ€çµ¦ä¸­: æŠ¼ã—ç›®å¾…ã¡ï¼ˆç™ºè¡¨è·¨ãã¯å°å£ï¼‰
    # - å¼±: è¦‹é€ã‚Š/ææ–™å¾…ã¡
    def f(x):
        try:
            return float(x)
        except Exception:
            return 0.0
    mom = f(rec.get("momentum_score"))
    hh  = f(rec.get("near_hh_score"))
    vol = f(rec.get("vol_score"))
    edg = f(rec.get("edge_score"))
    rvol= f(rec.get("RVOLä»£é‡‘") or rec.get("RVOL_ä»£é‡‘") or rec.get("rvol"))

    strong_flow = (mom >= 90) or (hh >= 80 and vol >= 70) or (rvol >= 2.0)

    if edg >= 85 and strong_flow:
        return "ä¸Šæ–¹ã‚µãƒ—ãƒ©ã‚¤ã‚ºç‹™ã„ã€‚ç›´è¿‘é«˜å€¤ãƒ–ãƒ¬ã‚¤ã‚¯ã§åˆ†å‰²INã€å¤±é€Ÿãªã‚‰å³æ’¤é€€ã€‚"
    if edg >= 70 and (mom >= 80 or rvol >= 1.5):
        return "å¥½ãƒˆãƒ©ãƒƒã‚¯ãƒ¬ã‚³ãƒ¼ãƒ‰ã€‚-3ã€œ-5%æŠ¼ã—ã§æ‹¾ã„ã€ç™ºè¡¨ã¯å°å£è·¨ãã€‚"
    if edg >= 55:
        return "ä¸­ç«‹ã€‚ç™ºè¡¨è·¨ãã¯æœ€å°ãƒ­ãƒƒãƒˆã€æ±ºç®—å¾Œã®åˆå‹•ã§è¿½éšã€‚"
    return "è¦‹é€ã‚Šã€‚ææ–™/å‡ºæ¥é«˜ã®å¢—åŠ å¾…ã¡ã€‚"

def _mk_overheat_bucket(r20_pct: float, mom: float) -> str:
    """éç†±åº¦ã®ãƒã‚±ãƒƒãƒˆåŒ–ï¼ˆéç†±/ã‚„ã‚„éç†±/ä¸­ç«‹/ã‚„ã‚„èª¿æ•´/èª¿æ•´ï¼‰"""
    if r20_pct >= 90 or mom >= 90: return "éç†±"
    if r20_pct >= 75 or mom >= 85: return "ã‚„ã‚„éç†±"
    if r20_pct <= 10 or mom <= 40: return "èª¿æ•´"
    if r20_pct <= 25 or mom <= 60: return "ã‚„ã‚„èª¿æ•´"
    return "ä¸­ç«‹"

def _attach_overheat_and_hints(conn, pre_df):
    """pre_df ã«ã€éç†±åº¦ã€ã€äºˆæ¸¬ãƒ’ãƒ³ãƒˆã€ã‚’ä»˜ä¸ï¼ˆé †ä½ã¯å¤‰æ›´ã—ãªã„ï¼‰"""
    if pre_df is None or pre_df.empty:
        pre_df = pd.DataFrame(columns=list(pre_df.columns)+["éç†±åº¦","äºˆæ¸¬ãƒ’ãƒ³ãƒˆ"])
        return pre_df

    # ç›´è¿‘20æ—¥ãƒªã‚¿ãƒ¼ãƒ³ã¨ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«
    r20 = pd.read_sql_query("""
        WITH cur AS (SELECT ã‚³ãƒ¼ãƒ‰, MAX(æ—¥ä»˜) d FROM price_history GROUP BY ã‚³ãƒ¼ãƒ‰),
             base AS (
               SELECT p.ã‚³ãƒ¼ãƒ‰, p.çµ‚å€¤ AS c0,
                      (SELECT çµ‚å€¤ FROM price_history q
                       WHERE q.ã‚³ãƒ¼ãƒ‰=p.ã‚³ãƒ¼ãƒ‰ AND q.æ—¥ä»˜=date(p.æ—¥ä»˜,'-20 day')) AS c20
               FROM price_history p JOIN cur ON p.ã‚³ãƒ¼ãƒ‰=cur.ã‚³ãƒ¼ãƒ‰ AND p.æ—¥ä»˜=cur.d
             )
        SELECT ã‚³ãƒ¼ãƒ‰, 100.0*(c0 - c20)/NULLIF(c20,0) AS r20
        FROM base
    """, conn)
    r20["r20"] = pd.to_numeric(r20["r20"], errors="coerce").fillna(0.0)
    r20["r20_pct"] = (r20["r20"].rank(pct=True) * 100.0).clip(0, 100)

    df = pre_df.merge(r20[["ã‚³ãƒ¼ãƒ‰","r20","r20_pct"]], on="ã‚³ãƒ¼ãƒ‰", how="left")
    df["éç†±åº¦"] = df.apply(
        lambda r: _mk_overheat_bucket(float(r.get("r20_pct") or 0), float(r.get("momentum_score") or 0)),
        axis=1
    )
    # äºˆæ¸¬ãƒ’ãƒ³ãƒˆï¼ˆè¡Œã«è¶³ã‚Šãªã„ã‚«ãƒ©ãƒ ã¯ã‚ã£ã¦ã‚‚ãªãã¦ã‚‚OKãªè¨­è¨ˆï¼‰
    df["äºˆæ¸¬ãƒ’ãƒ³ãƒˆ"] = df.apply(_mk_hint, axis=1)
    return df

def _compute_expected_price_and_revision(conn, pre_df):
    """
    DBã®éå»æ±ºç®—åå¿œã‹ã‚‰â€œæœŸå¾…ä¾¡æ ¼â€ã‚’ä½œã‚‹ï¼‹ç°¡æ˜“ãƒ«ãƒ¼ãƒ«ã§â€œæ¥­ç¸¾ä¿®æ­£äºˆæƒ³â€ã‚’ä»˜ä¸ã€‚
    - æœŸå¾…ä¾¡æ ¼ = ç¾åœ¨å€¤ Ã— (1 + æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³[%]/100)
      æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³ã¯ã€éå»ã® earnings_events å½“æ—¥ã€œç¿Œå–¶æ¥­æ—¥ã®å¸‚å ´å¹³å‡åå¿œã‚’ãƒ™ãƒ¼ã‚¹ã«ã€
      ä»Šã®ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ï¼ˆr20_pct, momentum_scoreï¼‰ã§å¼±/å¼·è£œæ­£ã€‚
    - æ¥­ç¸¾ä¿®æ­£äºˆæƒ³ = {ä¸Šæ–¹è¦³æ¸¬ / æ®ç½®è¦‹é€šã— / ä¸‹æ–¹è¦³æ¸¬}
      ï¼ˆå››åŠæœŸPLãŒã‚ã‚Œã°é€²æ—ã¨YoYã€ãªã‘ã‚Œã°æœ€è¿‘ã®ã‚¤ãƒ™ãƒ³ãƒˆãƒ»ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã§è¿‘ä¼¼ï¼‰
    """

    if pre_df is None or pre_df.empty:
        return pd.DataFrame(columns=["ã‚³ãƒ¼ãƒ‰","æœŸå¾…ä¾¡æ ¼","æ¥­ç¸¾ä¿®æ­£äºˆæƒ³"])

    codes = tuple(pre_df["ã‚³ãƒ¼ãƒ‰"].astype(str).tolist())

    # ã„ã¾ã®ç¾åœ¨å€¤ï¼ˆæœ€æ–°çµ‚å€¤ï¼‰
    px = pd.read_sql_query("""
        WITH cur AS (SELECT ã‚³ãƒ¼ãƒ‰, MAX(æ—¥ä»˜) d FROM price_history GROUP BY ã‚³ãƒ¼ãƒ‰)
        SELECT p.ã‚³ãƒ¼ãƒ‰, p.çµ‚å€¤ AS ç¾åœ¨å€¤
        FROM price_history p JOIN cur ON p.ã‚³ãƒ¼ãƒ‰=cur.ã‚³ãƒ¼ãƒ‰ AND p.æ—¥ä»˜=cur.d
    """, conn)
    px["ç¾åœ¨å€¤"] = pd.to_numeric(px["ç¾åœ¨å€¤"], errors="coerce")

    # éå»ã®æ±ºç®—ã‚¤ãƒ™ãƒ³ãƒˆæ—¥ã¨ç¿Œå–¶æ¥­æ—¥ã®ãƒªã‚¿ãƒ¼ãƒ³ï¼ˆå…¨éŠ˜æŸ„å¹³å‡ï¼‰
    # â€» ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ»åˆ—ãŒç„¡ã„å ´åˆã¯ except ã§ 0% ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    try:
        ev = pd.read_sql_query("""
            SELECT ã‚³ãƒ¼ãƒ‰, DATE(æå‡ºæ™‚åˆ») AS d
            FROM earnings_events
            WHERE æå‡ºæ™‚åˆ» IS NOT NULL
              AND DATE(æå‡ºæ™‚åˆ») >= date('now','-720 day')
        """, conn)

        if ev.empty:
            base_ret = 0.0
        else:
            # ã‚¤ãƒ™ãƒ³ãƒˆæ—¥ã®å‰æ—¥çµ‚å€¤ã¨ç¿Œå–¶æ¥­æ—¥çµ‚å€¤ã§ +1æ—¥åå¿œã‚’æ¸¬ã‚‹
            # å‰æ—¥ï¼d-1å–¶æ¥­æ—¥æ‰±ã„ã¯å›°é›£ãªã®ã§è¿‘ä¼¼ï¼šd-1ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼æ—¥/ç¿Œå–¶æ¥­æ—¥ã‚’SQLã§è¿‘ä¼¼å–å¾—
            # ãšã‚Œã‚’è¨±å®¹ã—ã¤ã¤å¹³å‡ã‚’ã¨ã‚‹
            ret = pd.read_sql_query("""
                WITH e AS (
                  SELECT ã‚³ãƒ¼ãƒ‰, DATE(æå‡ºæ™‚åˆ») AS d FROM earnings_events
                  WHERE æå‡ºæ™‚åˆ» IS NOT NULL AND DATE(æå‡ºæ™‚åˆ») >= date('now','-720 day')
                ),
                p0 AS (
                  SELECT e.ã‚³ãƒ¼ãƒ‰, e.d,
                         (SELECT çµ‚å€¤ FROM price_history p WHERE p.ã‚³ãƒ¼ãƒ‰=e.ã‚³ãƒ¼ãƒ‰ AND p.æ—¥ä»˜<=date(e.d,'-1 day') ORDER BY p.æ—¥ä»˜ DESC LIMIT 1) AS c0
                  FROM e
                ),
                p1 AS (
                  SELECT e.ã‚³ãƒ¼ãƒ‰, e.d,
                         (SELECT çµ‚å€¤ FROM price_history p WHERE p.ã‚³ãƒ¼ãƒ‰=e.ã‚³ãƒ¼ãƒ‰ AND p.æ—¥ä»˜>=date(e.d,'+1 day') ORDER BY p.æ—¥ä»˜ ASC LIMIT 1) AS c1
                  FROM e
                )
                SELECT e.ã‚³ãƒ¼ãƒ‰, e.d,
                       100.0 * (p1.c1 - p0.c0) / NULLIF(p0.c0,0) AS r1d
                FROM e
                JOIN p0 ON p0.ã‚³ãƒ¼ãƒ‰=e.ã‚³ãƒ¼ãƒ‰ AND p0.d=e.d
                JOIN p1 ON p1.ã‚³ãƒ¼ãƒ‰=e.ã‚³ãƒ¼ãƒ‰ AND p1.d=e.d
            """, conn)
            ret["r1d"] = pd.to_numeric(ret["r1d"], errors="coerce")
            base_ret = float(ret["r1d"].median()) if not ret.empty else 0.0  # ä¸­å¤®å€¤ã§ãƒ­ãƒã‚¹ãƒˆ
    except Exception:
        base_ret = 0.0

    # ã„ã¾ã® r20_pct ã¨ momentum ã§å¼±/å¼·è£œæ­£ï¼ˆÂ±5%å¹…ï¼‰
    # ä¾‹ï¼šr20_pctãŒä¸Šä½ã®æ™‚ã¯ +2.5%ã€momentumãŒå¼·ã„æ™‚ã¯ +2.5% ä¸Šä¹—ã› ç­‰
    # â†’ éå»å¹³å‡ã« â€œçŠ¶æ³ä¿‚æ•°â€ ã‚’è»½ãæ›ã‘ã‚‹
    r20 = pd.read_sql_query("""
        WITH cur AS (SELECT ã‚³ãƒ¼ãƒ‰, MAX(æ—¥ä»˜) d FROM price_history GROUP BY ã‚³ãƒ¼ãƒ‰),
             base AS (
               SELECT p.ã‚³ãƒ¼ãƒ‰, p.çµ‚å€¤ AS c0,
                      (SELECT çµ‚å€¤ FROM price_history q
                       WHERE q.ã‚³ãƒ¼ãƒ‰=p.ã‚³ãƒ¼ãƒ‰ AND q.æ—¥ä»˜=date(p.æ—¥ä»˜,'-20 day')) AS c20
               FROM price_history p JOIN cur ON p.ã‚³ãƒ¼ãƒ‰=cur.ã‚³ãƒ¼ãƒ‰ AND p.æ—¥ä»˜=cur.d
             )
        SELECT ã‚³ãƒ¼ãƒ‰, 100.0*(c0 - c20)/NULLIF(c20,0) AS r20
        FROM base
    """, conn)
    r20["r20"] = pd.to_numeric(r20["r20"], errors="coerce").fillna(0.0)
    r20["r20_pct"] = (r20["r20"].rank(pct=True) * 100.0).clip(0,100)

    df = pre_df.merge(px, on="ã‚³ãƒ¼ãƒ‰", how="left")\
               .merge(r20[["ã‚³ãƒ¼ãƒ‰","r20_pct"]], on="ã‚³ãƒ¼ãƒ‰", how="left")

    def _situ_boost(r):
        boost = 1.0
        r20p = float(r.get("r20_pct") or 0)
        mom  = float(r.get("momentum_score") or 0)
        if r20p >= 75: boost += 0.025
        if r20p >= 90: boost += 0.025
        if mom  >= 85: boost += 0.025
        if mom  >= 95: boost += 0.025
        if r20p <= 25: boost -= 0.025
        if r20p <= 10: boost -= 0.025
        if mom  <= 60: boost -= 0.025
        if mom  <= 40: boost -= 0.025
        return boost

    df["æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³ï¼…"] = base_ret * df.apply(_situ_boost, axis=1)
    df["æœŸå¾…ä¾¡æ ¼"] = (pd.to_numeric(df["ç¾åœ¨å€¤"], errors="coerce") *
                   (1.0 + df["æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³ï¼…"].astype(float)/100.0)).round(2)

    # æ¥­ç¸¾ä¿®æ­£äºˆæƒ³ï¼ˆå››åŠæœŸPLãŒã‚ã‚Œã°ä½¿ã†ï¼ç„¡ã‘ã‚Œã°ã‚¤ãƒ™ãƒ³ãƒˆè¿‘ä¼¼ï¼‰
    try:
        pl = pd.read_sql_query("""
            SELECT ã‚³ãƒ¼ãƒ‰, æ±ºç®—æœŸ, å››åŠæœŸ,
                   å£²ä¸Šé«˜, å–¶æ¥­åˆ©ç›Š,
                   CASE WHEN å£²ä¸Šé«˜ IS NOT NULL AND å£²ä¸Šé«˜ != 0
                        THEN 100.0 * å–¶æ¥­åˆ©ç›Š/å£²ä¸Šé«˜ END AS åˆ©ç›Šç‡,
                   é€šæœŸé€²æ—ç‡
            FROM pl_quarter
        """, conn)
        pl["æ±ºç®—æœŸ_ord"] = pd.to_datetime(pl["æ±ºç®—æœŸ"], errors="coerce")
        last = pl.dropna(subset=["æ±ºç®—æœŸ_ord"]).sort_values(["ã‚³ãƒ¼ãƒ‰","æ±ºç®—æœŸ_ord"]).groupby("ã‚³ãƒ¼ãƒ‰").tail(1)
        # é€²æ—ã®åŸºæº–ï¼šQ1:25/Q2:50/Q3:75/Q4:100
        import numpy as np
        q = last["å››åŠæœŸ"].fillna(0)
        target = np.select([q==1,q==2,q==3,q>=4], [25.0,50.0,75.0,100.0], default=0.0)
        last = last.assign(_prog_gap=(last["é€šæœŸé€²æ—ç‡"].fillna(0.0) - target))

        # YoYï¼ˆå–¶æ¥­åˆ©ç›Šï¼‰ã‚‚è¦‹ã‚‹ï¼ˆ4Qå‰æ¯”ï¼‰
        pl = pl.sort_values(["ã‚³ãƒ¼ãƒ‰","æ±ºç®—æœŸ_ord"])
        pl["å–¶åˆ©YoY"] = pl.groupby("ã‚³ãƒ¼ãƒ‰")["å–¶æ¥­åˆ©ç›Š"].pct_change(4) * 100.0
        yoy = pl.groupby("ã‚³ãƒ¼ãƒ‰").tail(1)[["ã‚³ãƒ¼ãƒ‰","å–¶åˆ©YoY"]]

        base_rev = last[["ã‚³ãƒ¼ãƒ‰","_prog_gap"]].merge(yoy, on="ã‚³ãƒ¼ãƒ‰", how="left")
        def _rev_label(r):
            prog = float(r.get("_prog_gap") or 0.0)
            yoyp = float(r.get("å–¶åˆ©YoY") or 0.0)
            if prog >= 5 and yoyp >= 0:  return "ä¸Šæ–¹è¦³æ¸¬"
            if prog <= -5 and yoyp <= 0: return "ä¸‹æ–¹è¦³æ¸¬"
            return "æ®ç½®è¦‹é€šã—"
        base_rev["æ¥­ç¸¾ä¿®æ­£äºˆæƒ³"] = base_rev.apply(_rev_label, axis=1)
        rev = base_rev[["ã‚³ãƒ¼ãƒ‰","æ¥­ç¸¾ä¿®æ­£äºˆæƒ³"]]
    except Exception:
        # è¿‘60æ—¥ã‚¤ãƒ™ãƒ³ãƒˆã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã§è¿‘ä¼¼ï¼ˆãƒ—ãƒ©ã‚¹å¤šâ†’ä¸Šæ–¹ã€ãƒã‚¤ãƒŠã‚¹å¤šâ†’ä¸‹æ–¹ï¼‰
        try:
            evs = pd.read_sql_query("""
                SELECT ã‚³ãƒ¼ãƒ‰,
                       SUM(CASE WHEN ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ LIKE '%pos%' OR ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ LIKE '%ãƒã‚¸%' THEN 1
                                WHEN ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ LIKE '%neg%' OR ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ LIKE '%ãƒã‚¬%' THEN -1
                                ELSE 0 END) AS s
                FROM earnings_events
                WHERE æå‡ºæ™‚åˆ» >= datetime('now','-60 day')
                GROUP BY ã‚³ãƒ¼ãƒ‰
            """, conn)
            def _lbl(s):
                s = float(s or 0)
                if s >= 2:  return "ä¸Šæ–¹è¦³æ¸¬"
                if s <= -2: return "ä¸‹æ–¹è¦³æ¸¬"
                return "æ®ç½®è¦‹é€šã—"
            evs["æ¥­ç¸¾ä¿®æ­£äºˆæƒ³"] = evs["s"].apply(_lbl)
            rev = evs[["ã‚³ãƒ¼ãƒ‰","æ¥­ç¸¾ä¿®æ­£äºˆæƒ³"]]
        except Exception:
            rev = pd.DataFrame(columns=["ã‚³ãƒ¼ãƒ‰","æ¥­ç¸¾ä¿®æ­£äºˆæƒ³"])

    out = df.merge(rev, on="ã‚³ãƒ¼ãƒ‰", how="left")
    return out[["ã‚³ãƒ¼ãƒ‰","æœŸå¾…ä¾¡æ ¼","æ¥­ç¸¾ä¿®æ­£äºˆæƒ³"]]

def _pct(a, b):
    try:
        if b in (0, None) or pd.isna(b):
            return np.nan
        return 100.0 * (a - b) / b
    except Exception:
        return np.nan

def calc_expected_price(conn, code: str, latest_close: float,
                        momentum_score: float = 0.0, edge_score: float = 0.0) -> float:
    """
    DBã®éå»æ±ºç®—ç¿Œæ—¥ã®å®Ÿãƒªã‚¿ãƒ¼ãƒ³å¹³å‡ã‹ã‚‰ã€ŒæœŸå¾…æ ªä¾¡ã€ã‚’è¦‹ç©ã‚‚ã‚‹ç°¡æ˜“ç‰ˆã€‚
    æ¨™æœ¬ãŒä¹ã—ã„å ´åˆã¯ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ /ã‚¨ãƒƒã‚¸ã§å¾®èª¿æ•´ï¼ˆÂ±0.5%/10ptï¼‰ã€‚
    """
    # ç›´è¿‘ã®çµ‚å€¤ãŒç„¡ã‘ã‚Œã°ãã®ã¾ã¾è¿”ã™
    if latest_close in (None, 0) or pd.isna(latest_close):
        return float("nan")

    # 1) ã‚³ãƒ¼ãƒ‰ã®éå»æ±ºç®—æ—¥ã‚’å–å¾—
    ev = pd.read_sql_query("""
      SELECT æ—¥ä»˜ AS ev_day
      FROM earnings_events
      WHERE ã‚³ãƒ¼ãƒ‰ = ?
      ORDER BY æ—¥ä»˜ DESC
      LIMIT 10
    """, conn, params=[code])

    # 2) å„æ±ºç®—æ—¥ã®ã€Œç¿Œå–¶æ¥­æ—¥ã€çµ‚å€¤ã‚’å¼•ã„ã¦ã€å‰å–¶æ¥­æ—¥æ¯”ãƒªã‚¿ãƒ¼ãƒ³ã‚’ä½œã‚‹
    rets = []
    if not ev.empty:
      for d in ev["ev_day"].tolist():
        pr = pd.read_sql_query("""
          WITH prev AS (
            SELECT æ—¥ä»˜, çµ‚å€¤ FROM price_history
            WHERE ã‚³ãƒ¼ãƒ‰=? AND æ—¥ä»˜ <= ?
            ORDER BY æ—¥ä»˜ DESC LIMIT 1
          ),
          next AS (
            SELECT æ—¥ä»˜, çµ‚å€¤ FROM price_history
            WHERE ã‚³ãƒ¼ãƒ‰=? AND æ—¥ä»˜ > ?
            ORDER BY æ—¥ä»˜ ASC LIMIT 1
          )
          SELECT
            (SELECT çµ‚å€¤ FROM next) AS c_next,
            (SELECT çµ‚å€¤ FROM prev) AS c_prev
        """, conn, params=[code, d, code, d])
        if not pr.empty:
            c_prev = pr.at[0, "c_prev"]
            c_next = pr.at[0, "c_next"]
            if pd.notna(c_prev) and pd.notna(c_next) and c_prev:
                rets.append(_pct(c_next, c_prev))

    # 3) å¹³å‡åå¿œï¼ˆ%ï¼‰
    if rets:
        base_ret = float(np.nanmean(rets))
    else:
        base_ret = 0.0  # æ¨™æœ¬ãŒç„¡ã‘ã‚Œã°ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«

    # 4) ã‚µãƒ³ãƒ—ãƒ«ä¸è¶³ã®ã¨ãã¯ã‚¹ã‚³ã‚¢ã§å¾®èª¿æ•´ï¼ˆÂ±0.5%/10ptï¼‰
    if len(rets) < 3:
        base_ret += 0.05 * ((momentum_score - 50.0) / 10.0)   # 50åŸºæº–
        base_ret += 0.05 * ((edge_score     - 50.0) / 10.0)

    # 5) æœŸå¾…æ ªä¾¡ = æœ€æ–°çµ‚å€¤ Ã— (1 + æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³%)
    expected = latest_close * (1.0 + base_ret / 100.0)
    return round(float(expected), 2)

def classify_revision_bias(edge_score: float,
                           momentum_score: float) -> Literal["ä¸Šæ–¹å¯„ã‚Š", "ä¸­ç«‹", "ä¸‹æ–¹å¯„ã‚Š"]:
    """
    æ±ºç®—ã®ä¸ŠæŒ¯ã‚Œ/ä¸‹æŒ¯ã‚Œâ€œè¦‹é€šã—â€ã‚’è¶…å˜ç´”åŒ–ã€‚
    edgeï¼ˆå†…å®¹å¯„ã‚Šï¼‰ã‚’ä¸»ã€momï¼ˆéœ€çµ¦å¯„ã‚Šï¼‰ã‚’å¾“ã¨ã—ã¦åˆ¤å®šã€‚
    """
    e = float(edge_score or 0.0)
    m = float(momentum_score or 0.0)

    if e >= 65 or (e >= 55 and m >= 70):
        return "ä¸Šæ–¹å¯„ã‚Š"
    if e <= 35 or (e <= 45 and m <= 40):
        return "ä¸‹æ–¹å¯„ã‚Š"
    return "ä¸­ç«‹"

def judge_overheat(conn, code: str,
                   momentum_score: float) -> Literal["éç†±", "ã‚„ã‚„éç†±", "ä¸­ç«‹", "ã‚„ã‚„æŠ¼ã—ç›®", "æŠ¼ã—ç›®"]:
    """
    éŠ˜æŸ„ç›¸å¯¾ã®20æ—¥ãƒªã‚¿ãƒ¼ãƒ³ï¼ˆr20 = ç›´è¿‘çµ‚å€¤/20æ—¥å‰çµ‚å€¤ - 1ï¼‰ã¨
    å¸‚å ´å…¨ä½“ã«å¯¾ã™ã‚‹r20ã®ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ï¼ˆ<= r20 ã®æ¯”ç‡ï¼‰ï¼‹ momentum_score ã§â€œéç†±åº¦â€ã‚’5åˆ†é¡ã€‚
    """
    # å¯¾è±¡éŠ˜æŸ„ã® r20
    r = pd.read_sql_query(
        """
        WITH cur AS (
          SELECT MAX(æ—¥ä»˜) d FROM price_history WHERE ã‚³ãƒ¼ãƒ‰=?
        )
        SELECT
          100.0 * (
            (SELECT çµ‚å€¤ FROM price_history p WHERE p.ã‚³ãƒ¼ãƒ‰=? AND p.æ—¥ä»˜=cur.d)
            -
            (SELECT çµ‚å€¤ FROM price_history q WHERE q.ã‚³ãƒ¼ãƒ‰=? AND q.æ—¥ä»˜=date(cur.d,'-20 day'))
          ) / NULLIF(
            (SELECT çµ‚å€¤ FROM price_history q WHERE q.ã‚³ãƒ¼ãƒ‰=? AND q.æ—¥ä»˜=date(cur.d,'-20 day')), 0
          ) AS r20
        FROM cur
        """,
        conn, params=[code, code, code, code]
    )
    r20 = float(r.at[0, "r20"]) if (not r.empty and pd.notna(r.at[0, "r20"])) else 0.0

    # å¸‚å ´å…¨ä½“ã® r20 åˆ†å¸ƒ
    allr = pd.read_sql_query(
        """
        WITH cur AS (
          SELECT ã‚³ãƒ¼ãƒ‰, MAX(æ—¥ä»˜) d FROM price_history GROUP BY ã‚³ãƒ¼ãƒ‰
        ),
        base AS (
          SELECT p.ã‚³ãƒ¼ãƒ‰,
                 p.çµ‚å€¤ AS c0,
                 (SELECT çµ‚å€¤ FROM price_history q
                  WHERE q.ã‚³ãƒ¼ãƒ‰=p.ã‚³ãƒ¼ãƒ‰ AND q.æ—¥ä»˜=date(p.æ—¥ä»˜,'-20 day')) AS c20
          FROM price_history p
          JOIN cur ON p.ã‚³ãƒ¼ãƒ‰=cur.ã‚³ãƒ¼ãƒ‰ AND p.æ—¥ä»˜=cur.d
        )
        SELECT 100.0 * (c0 - c20) / NULLIF(c20,0) AS r20 FROM base
        """,
        conn
    )

    if allr.empty:
        r20pct = 50.0
    else:
        s = pd.to_numeric(allr["r20"], errors="coerce").fillna(0.0)
        # ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ã¯ã€Œå…¨ä½“ã®ä¸­ã§è‡ªåˆ†ä»¥ä¸‹ã®å‰²åˆã€ã‚’æ¡ç”¨
        r20pct = float(((s <= r20).mean()) * 100.0)

    mom = float(momentum_score or 0.0)

    # ã—ãã„å€¤ï¼ˆå¿…è¦ã«å¿œã˜ã¦å¾®èª¿æ•´å¯ï¼‰
    if r20pct >= 90 or mom >= 90:
        return "éç†±"
    if r20pct >= 75 or mom >= 80:
        return "ã‚„ã‚„éç†±"
    if r20pct <= 10 or mom <= 35:
        return "æŠ¼ã—ç›®"
    if r20pct <= 25 or mom <= 55:
        return "ã‚„ã‚„æŠ¼ã—ç›®"
    return "ä¸­ç«‹"
    
def phase_sync_finance_comments(conn):
    """
    finance_notes(ã‚³ãƒ¼ãƒ‰, è²¡å‹™ã‚³ãƒ¡ãƒ³ãƒˆ, score, progress_percent)
      -> screener.è²¡å‹™ã‚³ãƒ¡ãƒ³ãƒˆ, screener.ã‚¹ã‚³ã‚¢, screener.é€²æ—ç‡ ã«åŒæœŸ
    """
    import sqlite3
    cur = conn.cursor()

    # 1) å¾Œæ–¹äº’æ›: åˆ—ãŒç„¡ã‘ã‚Œã°è¿½åŠ 
    cur.execute("PRAGMA table_info(screener)")
    cols = {r[1] for r in cur.fetchall()}
    add_sql = []
    if "è²¡å‹™ã‚³ãƒ¡ãƒ³ãƒˆ" not in cols:
        add_sql.append("ALTER TABLE screener ADD COLUMN è²¡å‹™ã‚³ãƒ¡ãƒ³ãƒˆ TEXT")
    if "ã‚¹ã‚³ã‚¢" not in cols:
        add_sql.append("ALTER TABLE screener ADD COLUMN ã‚¹ã‚³ã‚¢ REAL")
    if "é€²æ—ç‡" not in cols:
        add_sql.append("ALTER TABLE screener ADD COLUMN é€²æ—ç‡ REAL")
    for s in add_sql:
        try:
            cur.execute(s)
        except Exception:
            pass
    conn.commit()

    # 2) finance_notes -> screener åŒæœŸï¼ˆã‚³ãƒ¼ãƒ‰ã¯0åŸ‹ã‚4æ¡ã§æ¯”è¼ƒï¼‰
    cur.execute(
        """
        UPDATE screener AS s
        SET è²¡å‹™ã‚³ãƒ¡ãƒ³ãƒˆ = (
              SELECT n.è²¡å‹™ã‚³ãƒ¡ãƒ³ãƒˆ
              FROM finance_notes n
              WHERE printf('%04d', CAST(n.ã‚³ãƒ¼ãƒ‰ AS INTEGER)) = printf('%04d', CAST(s.ã‚³ãƒ¼ãƒ‰ AS INTEGER))
            ),
            ã‚¹ã‚³ã‚¢ = (
              SELECT n.score
              FROM finance_notes n
              WHERE printf('%04d', CAST(n.ã‚³ãƒ¼ãƒ‰ AS INTEGER)) = printf('%04d', CAST(s.ã‚³ãƒ¼ãƒ‰ AS INTEGER))
            ),
            é€²æ—ç‡ = (
              SELECT n.progress_percent
              FROM finance_notes n
              WHERE printf('%04d', CAST(n.ã‚³ãƒ¼ãƒ‰ AS INTEGER)) = printf('%04d', CAST(s.ã‚³ãƒ¼ãƒ‰ AS INTEGER))
            )
        WHERE EXISTS (
          SELECT 1 FROM finance_notes n
          WHERE printf('%04d', CAST(n.ã‚³ãƒ¼ãƒ‰ AS INTEGER)) = printf('%04d', CAST(s.ã‚³ãƒ¼ãƒ‰ AS INTEGER))
        )
        """
    )
    conn.commit()
    cur.close()

def _timed(label, func, *args, **kwargs):
    """é–¢æ•°ã®å‡¦ç†æ™‚é–“ã‚’è¨ˆæ¸¬ã—ã¦ãƒ­ã‚°å‡ºåŠ›ã™ã‚‹ãƒ©ãƒƒãƒ‘ãƒ¼"""
    t0 = time.time()
    try:
        return func(*args, **kwargs)
    finally:
        dt = time.time() - t0
        print(f"[TIMER] {label}: {dt:.2f} ç§’")
        

# ===== å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰åˆ¤å®šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ =====
def _auto_run_mode():
    """JSTã§ 11:30-12:30 ã¯ MIDDAYãã‚Œä»¥å¤–ã¯EOD"""
    if not AUTO_MODE:
        return RUN_SESSION.upper()

    try:
        now = dtm.datetime.now(ZoneInfo("Asia/Tokyo")).time()
    except Exception:
        now = dtm.datetime.now().time()

    return "MIDDAY" if dtm.time(11,30) <= now < dtm.time(12,30) else "EOD"

# ===== ãƒ¡ã‚¤ãƒ³å‡¦ç† =====
def main():
    t0 = time.time()
    print("=== é–‹å§‹ ===")

    # (0) ä»˜å¸¯å‡¦ç†ï¼šç©ºå£²ã‚Šæ©Ÿé–¢ãƒªã‚¹ãƒˆã®æ›´æ–°
    try:
        _timed("run_karauri_script", run_karauri_script)
    except Exception as e:
        print("[karauri][WARN]", e)
    
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”Ÿæˆå‰ãªã©ã«
    run_fundamental_daily()
    
    # â–¼ ã“ã“ã‚’è¿½åŠ ï¼šèµ·å‹•æ™‚ã«ã¾ãš fetch_all ã‚’å®Ÿè¡Œï¼ˆDBã«åé›†ãƒ»ä¿å­˜ã•ã›ã‚‹ï¼‰
    try:
        _timed("fetch_all", _run_fetch_all,
               # fetch_path=None â†’ è‡ªå‹•è§£æ±ºã€‚å›ºå®šã—ãŸã‘ã‚Œã°çµ¶å¯¾ãƒ‘ã‚¹ã‚’æ¸¡ã™
               fetch_path=r"H:\desctop\æ ªæ”»ç•¥\2-ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ„ãƒ¼ãƒ«\fetch_all.py",
               # extra_args ã¯ fetch_all å´ã®å¼•æ•°ä»•æ§˜ã«åˆã‚ã›ã¦é©å®œ
               extra_args=[],     # ä¾‹: ["--earnings-only", "--force"]
               timeout_sec=None,  # å¿…è¦ãªã‚‰ç§’æŒ‡å®š
               use_lock=True)
    except Exception as e:
        # åé›†ã«å¤±æ•—ã—ã¦ã‚‚ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”Ÿæˆè‡ªä½“ã¯ç¶šè¡Œã—ãŸã„ãªã‚‰ warn ã§æ¡ã‚Šã¤ã¶ã™
        print(f"[fetch_all][WARN] {e}")

    # (1) DB open & ã‚¹ã‚­ãƒ¼ãƒä¿è¨¼
    conn = open_conn(DB_PATH)
    # [v12] removed: lib.parse import quote as _q


    extra_closed = _load_extra_closed(EXTRA_CLOSED_PATH)
    # if is_jp_market_holiday(dtm.date.today(), extra_closed):
    #     print(f"æ—¥æœ¬ã®ä¼‘å ´æ—¥ï¼ˆ{dtm.date.today()}ï¼‰ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
    #     print("=== çµ‚äº† ==="); return

    # (3) CSVå–ã‚Šè¾¼ã¿ï¼ˆã‚³ãƒ¼ãƒ‰ãƒ»éŠ˜æŸ„åãƒ»å¸‚å ´ãƒ»ç™»éŒ²æ—¥ã®ã¿ï¼‰
    if USE_CSV:
        try:
            _timed("phase_csv_import", phase_csv_import, conn, overwrite_registered_date=False)
        except Exception as e:
            print("[csv-import][WARN]", e)

    # (4) ä¸Šå ´å»ƒæ­¢/ç©ºå£²ã‚Šç„¡ã—ã®åæ˜ 
    try:
       _timed("phase_delist_cleanup", phase_delist_cleanup, conn, also_clean_notes=True)
    except Exception as e:
        print("[delist][WARN]", e)

    try:
        _timed("phase_mark_karauri_nashi", phase_mark_karauri_nashi, conn)
    except Exception as e:
        print("[karauri-flag][WARN]", e)

    # (5) å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰æ±ºå®š
    RUN = _auto_run_mode()
    print(f"[AUTO_MODE={AUTO_MODE}] mode={RUN}")

    # (6) å‡¦ç†å¯¾è±¡éŠ˜æŸ„
    codes = [str(r[0]) for r in conn.execute("SELECT ã‚³ãƒ¼ãƒ‰ FROM screener").fetchall()]
    if TEST_MODE:
        codes = codes[:TEST_LIMIT]
        print(f"[TEST] å¯¾è±¡ {len(codes)} éŠ˜æŸ„ã«åˆ¶é™")

    try:
        if RUN == "MIDDAY":
            # ===== MIDDAYãƒ¢ãƒ¼ãƒ‰ =====
            _timed("yahoo_intraday_snapshot", phase_yahoo_intraday_snapshot, conn)
            _timed("snapshot_shodou_baseline", phase_snapshot_shodou_baseline, conn)
            _timed("update_shodou_multipliers", phase_update_shodou_multipliers, conn)
            _timed("compute_right_up_persistent", compute_right_up_persistent, conn)
            _timed("compute_right_up_early_triggers", compute_right_up_early_triggers, conn)
            _timed("derive_update", phase_derive_update, conn)
            _timed("signal_detection", phase_signal_detection, conn)
            _timed("update_since_dates", phase_update_since_dates, conn)

        else:
            # ===== EODãƒ¢ãƒ¼ãƒ‰ =====
            _timed("yahoo_bulk_refresh", phase_yahoo_bulk_refresh, conn, codes, batch_size=200)
            _timed("refresh_full_history_for_insufficient", refresh_full_history_for_insufficient,conn, codes, batch_size=200)
            _timed("compute_right_up_persistent", compute_right_up_persistent, conn)
            _timed("compute_right_up_early_triggers", compute_right_up_early_triggers, conn)

            # ç¾åœ¨æ™‚åˆ»ãŒ12:30ä»¥å‰ãªã‚‰ã€Œé‡ã„å‡¦ç†ã€ã‚‚å®Ÿè¡Œã™ã‚‹
            now = dtm.datetime.now().time()
            if now < dtm.time(12,30):
                _timed("update_market_cap_all", update_market_cap_all, conn, batch_size=100, max_workers=4)
                try:
                    _timed("update_operating_income_and_ratio", update_operating_income_and_ratio, conn)
                except Exception as e:
                    print("[operating-income][WARN]", e)
            else:
                print("[SKIP] å–¶æ¥­åˆ©ç›Šãƒ»æ™‚ä¾¡ç·é¡ã®æ›´æ–°ï¼ˆ12:30ä»¥é™ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ï¼‰")

            _timed("snapshot_shodou_baseline", phase_snapshot_shodou_baseline, conn)
            _timed("update_shodou_multipliers", phase_update_shodou_multipliers, conn)
            _timed("derive_update", phase_derive_update, conn)
            _timed("signal_detection", phase_signal_detection, conn)
            _timed("update_since_dates", phase_update_since_dates, conn)

            try:
                _timed("validate_prev_business_day", phase_validate_prev_business_day, conn)
            except Exception as e:
                print("[validate-prev][WARN]", e)
                
        
        # æœ€å¾Œã« build_earnings_tables(conn) ã‚’å‘¼ã‚“ã§ HTML ã«ã‚¿ãƒ–ã‚’è¿½åŠ 

        # (6.5)
        _timed("relax_rejudge_signals", relax_rejudge_signals, conn)

        # (7) æ•°å€¤ã®æ­£è¦åŒ–
        # [v12] æ•°å€¤ã®æ­£è¦åŒ–ã‚¹ãƒ†ãƒƒãƒ—ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆå›ºå®šã‚¹ã‚­ãƒ¼ãƒå‰æï¼‰






        # (7.1) è²¡å‹™ã‚³ãƒ¡ãƒ³ãƒˆè¿½åŠ 
        phase_sync_finance_comments(conn)

        # (8) ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰å‡ºåŠ›
        html_path = os.path.join(OUTPUT_DIR, "index.html")
        _timed("export_html_dashboard", phase_export_html_dashboard_offline, conn, html_path)

        # (9) ãƒ¡ãƒ¼ãƒ«é€ä¿¡ï¼ˆä»»æ„ï¼‰
        #try:
        #    _timed("send_index_html_via_gmail", send_index_html_via_gmail, html_path)
        # ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ãªã—ã§å¼·åˆ¶ã‚ªãƒ¼ãƒ—ãƒ³
        ok = open_html_locally(r"H:\desctop\æ ªæ”»ç•¥\1-ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°è‡ªå‹•åŒ–ãƒ—ãƒ­ã‚°ãƒ©ãƒ \screen_data\index.html", cool_min=0, force=True)
        print("opened:", ok)
        #
        #except Exception as e:
        #    print("[gmail][WARN]", e)
        #    
        #

    finally:
        conn.close()
    print(f"å®Ÿè¡Œæ™‚é–“ï¼š {time.time() - t0:.2f}s")
    print("=== çµ‚äº† ===")

# ===== ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ =====
if __name__ == "__main__":
    main()