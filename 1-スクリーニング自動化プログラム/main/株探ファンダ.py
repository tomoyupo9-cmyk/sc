# -*- coding: utf-8 -*-
# æ ªæ¢ãƒ•ã‚¡ãƒ³ãƒ€_v12_retry_dbskip_default__FULL_FIXED_v6.py
# - ãƒªãƒˆãƒ©ã‚¤ï¼ˆæŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ï¼‹ã‚¸ãƒƒã‚¿ãƒ¼ï¼‰
# - ä¸¦åˆ—æ•°å¯å¤‰ (--workers)
# - é€²æ—ç‡ãƒ­ã‚° (--log-progress, --log-file)
# - æœ€æ–°ç™ºè¡¨æ—¥ã§ã®ã‚¹ã‚­ãƒƒãƒ—ï¼šDBã‚­ãƒ£ãƒƒã‚·ãƒ¥åŸºæº–ï¼ˆHTTPå‰ï¼‰ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæœ‰åŠ¹ã€‘
#   * ENABLE_DB_SKIP = True
#   * SKIP_RECENT_DAYS_DEFAULT = 84 (=28æ—¥Ã—3) ã«ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
# - ç›´è¿‘ãŒç•°å¸¸çµ‚äº†ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—ç„¡åŠ¹ï¼ˆå¿…ãšå†å–å¾—ï¼‰
# - DBæ›¸ãè¾¼ã¿ã®ON/OFF (--no-db)
#
# è¿½åŠ ï¼š
# - ã‚¹ã‚³ã‚¢â†’ã‚¢ãƒ«ãƒ•ã‚¡ï¼ˆS++/A+/B/C/D-ï¼‰ã‚’ overall_alpha ã¨ã—ã¦ finance_notes ã«ä¿å­˜
# - å››åŠæœŸãƒ†ãƒ¼ãƒ–ãƒ«ãŒå–ã‚Œãªãã¦ã‚‚ã€Œç™ºè¡¨æ—¥ã ã‘å–å¾—ã§ããŸã‚‰ã€earnings_cache ã‚’ ANNOUNCE_ONLY ã§æ›´æ–°
# - ä¾‹å¤–æ™‚ã‚‚å¯èƒ½ãªã‚‰ç™ºè¡¨æ—¥ã ã‘æ‹¾ã£ã¦ ANNOUNCE_ONLY ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›´æ–°ï¼ˆæ¬¡å›ã‚¹ã‚­ãƒƒãƒ—ãŒåŠ¹ãï¼‰
# - ã€å³æ ¼å¯¾ç­–ã€‘æœªå®šç¾©ã‚¨ãƒ©ãƒ¼é˜²æ­¢ï¼šæ—¥æœ¬èªåã®æ®‹éª¸å‚ç…§ã‚’ç„¡å®³åŒ–ï¼ˆglobals ã«ãƒ€ãƒŸãƒ¼å®šç¾©ï¼‰

import re
import argparse
import sys
import os
import sqlite3
import asyncio
from datetime import datetime, timezone, timedelta
from io import StringIO
import random

import aiohttp
import pandas as pd
import numpy as np
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
from matplotlib import font_manager, rcParams
from plotly.subplots import make_subplots
import plotly.graph_objects as go
from bs4 import BeautifulSoup

# --- NameErroré˜²æ­¢ï¼ˆä»–ãƒ•ã‚¡ã‚¤ãƒ«ç”±æ¥ã®æ—¥æœ¬èªè­˜åˆ¥å­ã®æ®‹éª¸ã«å‚™ãˆã‚‹ï¼‰ ---
globals().update({'æœ€æ–°_label': None, 'æœ€æ–°_cumulative_op': None})

# ===== æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆ =====
def _set_japanese_font():
    preferred = ["Meiryo", "Yu Gothic", "YuGothic", "IPAexGothic",
                 "Noto Sans CJK JP", "Noto Sans JP", "TakaoGothic", "MS Gothic"]
    available = {f.name for f in font_manager.fontManager.ttflist}
    for name in preferred:
        if name in available:
            rcParams["font.family"] = name
            break
    rcParams["axes.unicode_minus"] = False
_set_japanese_font()

# ===== å®šæ•° =====
HEADERS = {
    "User-Agent": ("Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                   "AppleWebKit/537.36 (KHTML, like Gecko) "
                   "Chrome/126.0.0.0 Safari/537.36")
}
ASYNC_CONCURRENCY_LIMIT = 15
MASTER_CODES_PATH = r"H:\desctop\æ ªæ”»ç•¥\1-ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°è‡ªå‹•åŒ–ãƒ—ãƒ­ã‚°ãƒ©ãƒ \main\input_data\æ ªã‚³ãƒ¼ãƒ‰ç•ªå·.txt"
DB_PATH = r"H:\desctop\æ ªæ”»ç•¥\1-ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°è‡ªå‹•åŒ–ãƒ—ãƒ­ã‚°ãƒ©ãƒ \main\db\kani2.db"

# ãƒªãƒˆãƒ©ã‚¤è¨­å®š
RETRY_HTTP_STATUSES = {429, 500, 502, 503, 504}
MAX_RETRIES = 4
BACKOFF_BASE_SEC = 1.5   # 1.0,1.5,2.25,3.38... + ã‚¸ãƒƒã‚¿ãƒ¼
JITTER_SEC = 0.3

# DBã‚¹ã‚­ãƒƒãƒ—ï¼šãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæœ‰åŠ¹ï¼ˆç„¡åŠ¹åŒ–ã¯ --no-db-skipï¼‰
ENABLE_DB_SKIP = True
SKIP_RECENT_DAYS_DEFAULT = 84

# DBã‚¹ã‚­ãƒƒãƒ—åˆ¤å®šç”¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ†é¡
BAD_LAST_STATUSES = {
    "ERROR_429", "ERROR_500", "ERROR_502", "ERROR_503", "ERROR_504",
    "TIMEOUT", "CONN_ERROR", "HTTP_ERROR", "PARSE_ERROR", "UNKNOWN_ERROR"
}
GOOD_LAST_STATUSES = {"OK", "FETCHED", "EMPTY_QUARTERLY", "ANNOUNCE_ONLY"}

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¼•æ•°
_ARGS = None

# å¸‚å ´ã«ã‚ˆã‚‹ã‚¹ã‚­ãƒƒãƒ—åˆ¤å®šã«ä½¿ã†ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
SKIP_MARKET_KEYWORDS = ("ETF", "æŒ‡æ•°")

# ===== ãƒ˜ãƒ«ãƒ‘ãƒ¼ =====

def _get_market_from_db(code: str) -> str | None:
    """screener ã‹ã‚‰å¸‚å ´ã‚’å–å¾—ï¼ˆãªã‘ã‚Œã° Noneï¼‰ã€‚"""
    try:
        conn = sqlite3.connect(DB_PATH, timeout=10)
        cur = conn.cursor()
        cur.execute("SELECT å¸‚å ´ FROM screener WHERE ã‚³ãƒ¼ãƒ‰ = ? LIMIT 1;", (str(code),))
        row = cur.fetchone()
        return row[0] if row and row[0] else None
    except Exception:
        return None
    finally:
        try:
            conn.close()
        except Exception:
            pass

def _is_skip_market(market: str | None) -> bool:
    """å¸‚å ´ãŒETF/æŒ‡æ•°ãªã‚‰Trueã€‚è¡¨è¨˜ã‚†ã‚Œ(ç©ºç™½ç­‰)ã‚‚ã–ã£ãã‚Šå¸åã€‚"""
    if not market:
        return False
    s = str(market).replace("ã€€", "").replace(" ", "")
    return any(k in s for k in SKIP_MARKET_KEYWORDS)

async def _fetch_text_with_retry(session: aiohttp.ClientSession, url: str, *, timeout_sec: int = 15) -> str:
    last_err = None
    for attempt in range(1, MAX_RETRIES + 1):
        try:
            async with session.get(url, headers=HEADERS, timeout=timeout_sec) as res:
                if res.status in RETRY_HTTP_STATUSES:
                    _ = await res.text()  # èª­ã¿æ¨ã¦
                    raise aiohttp.ClientResponseError(
                        request_info=res.request_info, history=res.history,
                        status=res.status, message=f"retryable status {res.status}",
                        headers=res.headers
                    )
                res.raise_for_status()
                return await res.text(encoding=res.get_encoding() or "utf-8")
        except (aiohttp.ClientResponseError, aiohttp.ClientConnectorError, asyncio.TimeoutError) as e:
            last_err = e
            if isinstance(e, aiohttp.ClientResponseError) and e.status not in RETRY_HTTP_STATUSES:
                break
            if attempt < MAX_RETRIES:
                sleep_sec = (BACKOFF_BASE_SEC ** (attempt - 1)) + random.uniform(0, JITTER_SEC)
                print(f"[RETRY] {url} attempt {attempt}/{MAX_RETRIES} -> sleep {sleep_sec:.2f}s ({type(e).__name__}: {getattr(e,'status', '')})")
                await asyncio.sleep(sleep_sec)
    raise last_err if last_err else RuntimeError("Unknown retry failure")

def _fiscal_key(label: str) -> str | None:
    if not isinstance(label, str):
        return None
    m = re.search(r'(\d{4}\.\d{1,2})', label)
    return m.group(1) if m else None

def _fiscal_key_from_quarter_label(q_label: str, fiscal_end_month: int) -> str | None:
    """
    '25.04-06' / '25/04-06' ãªã©ã®å››åŠæœŸãƒ©ãƒ™ãƒ« â†’ 'YYYY.MM'ï¼ˆæ±ºç®—æœˆï¼‰ã¸ã€‚
    çµ‚äº†æœˆ <= æ±ºç®—æœˆ ãªã‚‰å½“å¹´ã€> æ±ºç®—æœˆãªã‚‰ç¿Œå¹´ã‚’FYå¹´ã¨ã™ã‚‹ã€‚
    """
    if not isinstance(q_label, str) or fiscal_end_month is None:
        return None
    trans = str.maketrans({'ï¼':'/', 'ï¼':'-', 'â€•':'-', 'ãƒ¼':'-', 'ï¼':'.'})
    s = q_label.translate(trans).replace('/', '.')
    m = re.search(r'(?P<yy>\d{2})[\.\/](?P<m1>\d{2})[-â€“-](?P<m2>\d{2})', s)
    if not m:
        return None
    yy = int(m.group('yy')); end_m = int(m.group('m2'))
    base_year = 2000 + yy
    fy_year = base_year if end_m <= fiscal_end_month else base_year + 1
    return f"{fy_year}.{fiscal_end_month:02d}"

def _print_html_snippet_on_error(code: str, html_content: str, func_name: str):
    start_index = html_content.find('<table')
    if start_index != -1:
        snippet = html_content[start_index:start_index + 500]
        print(f"[DEBUG_HTML] {code} in {func_name}: Table snippet: {snippet}...")
    else:
        print(f"[DEBUG_HTML] {code} in {func_name}: Table not found near start. Snippet: {html_content[:500]}...")

# ===== DBï¼šearnings_cacheï¼ˆç™ºè¡¨æ—¥ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰ =====

def _ensure_cache_table():
    try:
        conn = sqlite3.connect(DB_PATH, timeout=10)
        cur = conn.cursor()
        cur.execute("""
        CREATE TABLE IF NOT EXISTS earnings_cache (
          ã‚³ãƒ¼ãƒ‰ TEXT PRIMARY KEY,
          latest_announce_date TEXT,   -- 'YYYY-MM-DD'
          last_status TEXT,            -- OK / ERROR_503 / etc
          updated_at TEXT              -- ISO
        );
        """)
        conn.commit()
    except Exception:
        pass
    finally:
        try: conn.close()
        except Exception: pass

def db_get_cached_announce(code: str) -> tuple[datetime | None, str | None]:
    _ensure_cache_table()
    try:
        conn = sqlite3.connect(DB_PATH, timeout=10)
        cur = conn.cursor()
        cur.execute("SELECT latest_announce_date, last_status FROM earnings_cache WHERE ã‚³ãƒ¼ãƒ‰ = ?", (code,))
        row = cur.fetchone()
        if not row or not row[0]:
            return (None, None)
        try:
            dt = datetime.fromisoformat(row[0])
        except Exception:
            dt = datetime.strptime(row[0], "%Y-%m-%d")
        return (dt, row[1])
    except Exception:
        return (None, None)
    finally:
        try: conn.close()
        except Exception: pass

def db_upsert_cached_announce(code: str, latest_announce_date: datetime | None, last_status: str):
    _ensure_cache_table()
    try:
        conn = sqlite3.connect(DB_PATH, timeout=10)
        cur = conn.cursor()
        iso_date = latest_announce_date.date().isoformat() if latest_announce_date else None
        ts = datetime.now().isoformat(timespec="seconds")
        cur.execute("""
        INSERT INTO earnings_cache (ã‚³ãƒ¼ãƒ‰, latest_announce_date, last_status, updated_at)
        VALUES (?, ?, ?, ?)
        ON CONFLICT(ã‚³ãƒ¼ãƒ‰) DO UPDATE SET
          latest_announce_date = excluded.latest_announce_date,
          last_status = excluded.last_status,
          updated_at = excluded.updated_at;
        """, (code, iso_date, last_status, ts))
        conn.commit()
    except Exception as e:
        print(f"[DB][WARN] earnings_cache upsert failed: {type(e).__name__}: {e}")
    finally:
        try: conn.close()
        except Exception: pass

# ===== ã‚¢ãƒ«ãƒ•ã‚¡è©•ä¾¡ =====
def _get_overall_alpha(score: int) -> str:
    if score >= 8: return "S++"
    elif score >= 5: return "A+"
    elif score >= 2: return "B"
    elif score >= 0: return "C"
    else: return "D-"

def _get_overall_verdict_label(score: int) -> str:
    if score >= 8: return "è¶…å„ªè‰¯ (S++)"
    elif score >= 5: return "å„ªè‰¯ (A+)"
    elif score >= 2: return "æˆé•·æœŸå¾… (B)"
    elif score >= 0: return "ç¾çŠ¶ç¶­æŒ (C)"
    else: return "è¦æ³¨æ„ (D-)"

# ===== DBï¼šfinance_notes æ›¸ãè¾¼ã¿ =====
def batch_record_to_sqlite(results: list[dict]):
    if not results:
        print("[DB] è¨˜éŒ²ã™ã¹ãæˆåŠŸçµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    try:
        conn = sqlite3.connect(DB_PATH, timeout=20)
        cur = conn.cursor()
        # æ—¢å®šãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆå¤ã„ç’°å¢ƒã§ã‚‚é€šã‚‹æœ€å°æ§‹æˆï¼‰
        cur.execute("""
        CREATE TABLE IF NOT EXISTS finance_notes (
          ã‚³ãƒ¼ãƒ‰ TEXT PRIMARY KEY,
          è²¡å‹™ã‚³ãƒ¡ãƒ³ãƒˆ TEXT,
          score INTEGER,
          progress_percent REAL,
          html_path TEXT,
          updated_at TEXT
        );
        """)
        # ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆä¸è¶³åˆ—ã‚’è¿½åŠ ï¼‰
        for col, coltype in [
            ("score", "INTEGER"),
            ("progress_percent", "REAL"),
            ("html_path", "TEXT"),
            ("updated_at","TEXT"),
            ("overall_alpha","TEXT"),          # â˜… è¿½åŠ åˆ—ï¼šã‚¢ãƒ«ãƒ•ã‚¡è©•ä¾¡
        ]:
            try:
                cur.execute(f"SELECT {col} FROM finance_notes LIMIT 1;")
            except sqlite3.OperationalError:
                print(f"[DB] ã‚¹ã‚­ãƒ¼ãƒä¿®æ­£: '{col}' ã‚«ãƒ©ãƒ ã‚’è¿½åŠ ã—ã¾ã™ã€‚")
                cur.execute(f"ALTER TABLE finance_notes ADD COLUMN {col} {coltype};")
        conn.commit()

        ts = datetime.now().isoformat(timespec="seconds")
        data_to_insert = []
        for res in results:
            if res.get('status') == 'OK':
                data_to_insert.append((
                    res['code'],
                    res.get('formatted_verdict') or "",
                    res.get('score'),
                    res.get('progress_percent'),
                    res.get('out_html') or "",
                    ts,
                    res.get('overall_alpha') or None,   # â˜… è¿½åŠ 
                ))
        if data_to_insert:
            cur.executemany("""
            INSERT INTO finance_notes (ã‚³ãƒ¼ãƒ‰, è²¡å‹™ã‚³ãƒ¡ãƒ³ãƒˆ, score, progress_percent, html_path, updated_at, overall_alpha)
            VALUES (?, ?, ?, ?, ?, ?, ?)
            ON CONFLICT(ã‚³ãƒ¼ãƒ‰) DO UPDATE SET
              è²¡å‹™ã‚³ãƒ¡ãƒ³ãƒˆ    = excluded.è²¡å‹™ã‚³ãƒ¡ãƒ³ãƒˆ,
              score           = excluded.score,
              progress_percent= excluded.progress_percent,
              html_path       = excluded.html_path,
              updated_at      = excluded.updated_at,
              overall_alpha   = excluded.overall_alpha;
            """, data_to_insert)
            conn.commit()
            print(f"[DB][INFO] {len(data_to_insert)}ä»¶ã®çµæœã‚’SQLiteã«ä¸€æ‹¬è¨˜éŒ²ã—ã¾ã—ãŸã€‚")
    except sqlite3.OperationalError as e:
        print(f"[DB][CRITICAL ERROR] SQLite DBæ“ä½œã‚¨ãƒ©ãƒ¼: {e}")
    except Exception as e:
        print(f"[DB][CRITICAL ERROR] äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
    finally:
        try:
            conn.close()
        except Exception:
            pass

# ===== å–å¾—é–¢æ•° =====

async def fetch_quarterly_financials(code: str, session: aiohttp.ClientSession) -> pd.DataFrame:
    url = f"https://kabutan.jp/stock/finance?code={code}"
    print(f"[INFO] fetching quarterly data: {url}")
    try:
        html_content = await _fetch_text_with_retry(session, url, timeout_sec=15)
        soup = BeautifulSoup(html_content, "lxml")
        target = None
        target_heading = soup.find(string=lambda t: t and '3ãƒµæœˆæ±ºç®—ã€å®Ÿç¸¾ã€‘' in t)
        if target_heading:
            target = target_heading.find_next('table')
        if target is None:
            return pd.DataFrame()
        df = pd.read_html(StringIO(str(target)), flavor="lxml", header=0)[0]
        df = df.drop(columns=[c for c in df.columns if "æç›Šç‡" in c], errors='ignore')

        # æ•´å½¢
        df.columns = df.columns.astype(str).str.replace(" ", "", regex=False).str.replace("ã€€", "", regex=False)
        if "æ±ºç®—æœŸ" in df.columns:
            mask = ~df["æ±ºç®—æœŸ"].astype(str).str.contains("å‰æœŸæ¯”|å‰å¹´åŒæœŸæ¯”|äºˆ|é€šæœŸ", na=False)
            df = df[mask].copy()
        df = df[df["æ±ºç®—æœŸ"].notna()].copy()
        df["æ±ºç®—æœŸ"] = df["æ±ºç®—æœŸ"].astype(str).str.strip()
        df.reset_index(drop=True, inplace=True)

        for col in ["å£²ä¸Šé«˜", "å–¶æ¥­ç›Š", "çµŒå¸¸ç›Š", "æœ€çµ‚ç›Š", "ä¿®æ­£1æ ªç›Š", "ä¿®æ­£1æ ªé…"]:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors="coerce")

        if "ç™ºè¡¨æ—¥" in df.columns:
            df["ç™ºè¡¨æ—¥"] = pd.to_datetime(
                df["ç™ºè¡¨æ—¥"].astype(str).str.split(r'\(| ').str[0].str.strip(),
                format="%y/%m/%d", errors='coerce'
            )
            df.dropna(subset=["ç™ºè¡¨æ—¥"], inplace=True)

        df = df.sort_values(by="ç™ºè¡¨æ—¥", ascending=True).reset_index(drop=True)
        return df

    except Exception as e:
        _print_html_snippet_on_error(code, locals().get('html_content',""), "fetch_quarterly_financials")
        print(f"[ERROR] {code}: 3ãƒµæœˆå®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿è§£æä¸­ã«ã‚¨ãƒ©ãƒ¼ - {type(e).__name__}: {e}")
        return pd.DataFrame()

async def fetch_full_year_financials(code: str, session: aiohttp.ClientSession) -> pd.DataFrame:
    url = f"https://kabutan.jp/stock/finance?code={code}"
    print(f"[INFO] fetching full year actual data: {url}")
    try:
        html_content = await _fetch_text_with_retry(session, url, timeout_sec=15)
        soup = BeautifulSoup(html_content, "lxml")
        tables = soup.find_all('table')
        target = None
        for table in tables:
            header_row = table.find('tr')
            if header_row and header_row.find(string=lambda t: t and ('æ±ºç®—æœŸ' in t or 'é€šæœŸ' in t)):
                target = table
                break
        if target is None:
            print(f"[WARN] é€šæœŸæ¥­ç¸¾æ¨ç§»ãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ (code={code})")
            return pd.DataFrame()

        df = pd.read_html(StringIO(str(target)), flavor="lxml", header=0)[0]
        df.columns = df.columns.astype(str).str.replace(r'\s+', '', regex=True)
        if "æ±ºç®—æœŸ" in df.columns:
            mask = ~df["æ±ºç®—æœŸ"].astype(str).str.contains("å‰æœŸæ¯”|å‰å¹´æ¯”", na=False)
            df = df[mask].copy()
        df = df[df["æ±ºç®—æœŸ"].notna()].copy()
        df["æ±ºç®—æœŸ"] = df["æ±ºç®—æœŸ"].astype(str).str.strip()
        df.reset_index(drop=True, inplace=True)
        for col in ["å£²ä¸Šé«˜", "å–¶æ¥­ç›Š", "çµŒå¸¸ç›Š", "æœ€çµ‚ç›Š", "ä¿®æ­£1æ ªç›Š", "ä¿®æ­£1æ ªé…"]:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors="coerce")
        df = df.drop(columns=["ç™ºè¡¨æ—¥"], errors='ignore')
        df = df.sort_values(by="æ±ºç®—æœŸ", ascending=True).reset_index(drop=True)
        return df

    except Exception as e:
        _print_html_snippet_on_error(code, locals().get('html_content',""), "fetch_full_year_financials")
        print(f"[ERROR] {code}: é€šæœŸå®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿è§£æä¸­ã«ã‚¨ãƒ©ãƒ¼ - {type(e).__name__}: {e}")
        return pd.DataFrame()

# ===== ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šç™ºè¡¨æ—¥ã ã‘æŠ½å‡º =====

def _parse_latest_announce_from_any_table(html_content: str) -> datetime | None:
    try:
        soup = BeautifulSoup(html_content, "lxml")
        for tbl in soup.find_all("table"):
            try:
                df = pd.read_html(StringIO(str(tbl)), flavor="lxml", header=0)[0]
            except Exception:
                continue
            cols = [str(c) for c in df.columns]
            if any("ç™ºè¡¨æ—¥" in c for c in cols):
                try:
                    ser = df[[c for c in df.columns if "ç™ºè¡¨æ—¥" in str(c)][0]].astype(str)
                    ser = pd.to_datetime(ser.str.split(r'\(| ').str[0].str.strip(), format="%y/%m/%d", errors="coerce")
                    ser = ser.dropna()
                    if not ser.empty:
                        return pd.to_datetime(ser.iloc[-1])
                except Exception:
                    continue
        return None
    except Exception:
        return None

async def fetch_latest_announce_date_only(session: aiohttp.ClientSession, code: str) -> datetime | None:
    """ãƒšãƒ¼ã‚¸å…¨ä½“ã‚’è¦‹ã¦â€œç™ºè¡¨æ—¥â€ã ã‘æ‹¾ã†ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‚"""
    url = f"https://kabutan.jp/stock/finance?code={code}"
    try:
        html_content = await _fetch_text_with_retry(session, url, timeout_sec=10)
        return _parse_latest_announce_from_any_table(html_content)
    except Exception as e:
        print(f"[FALLBACK] announce-only failed for {code}: {type(e).__name__}: {e}")
        return None

# ===== é€²æ—ï¼†è©•ä¾¡ =====
def compute_progress_details(quarterly_df: pd.DataFrame, forecast_series: pd.Series):
    details = {"latest_label": None, "key_q": None, "key_f": None,
               "fiscal_end_month": None, "cumulative_op": None, "full_op_val": None,
               "status": None, "progress": None}
    if (quarterly_df is None or quarterly_df.empty or
        "å–¶æ¥­ç›Š" not in quarterly_df.columns or "æ±ºç®—æœŸ" not in quarterly_df.columns):
        details["status"] = "å››åŠæœŸDFæ¬ æ";  return details
    latest_row = quarterly_df.tail(1)
    if latest_row.empty:
        details["status"] = "å››åŠæœŸDFç©º";  return details
    latest_label = str(latest_row["æ±ºç®—æœŸ"].iloc[0]);  details["latest_label"] = latest_label
    if forecast_series is None or forecast_series.empty:
        details["status"] = "äºˆæƒ³æœªç™ºè¡¨";  return details
    full_op_val = pd.to_numeric(forecast_series.get("å–¶æ¥­ç›Š"), errors="coerce")
    details["full_op_val"] = None if pd.isna(full_op_val) else float(full_op_val)
    if pd.isna(full_op_val): details["status"] = "äºˆæƒ³ãƒ‡ãƒ¼ã‚¿æ¬ æ";  return details
    if full_op_val == 0: details["status"] = "äºˆæƒ³ã‚¼ãƒ­";  return details
    key_f = _fiscal_key(str(forecast_series.get("æ±ºç®—æœŸ", "")));  details["key_f"] = key_f
    if not key_f: details["status"] = "äºˆæƒ³æœªç™ºè¡¨";  return details
    m = re.search(r"(\d{4})\.(\d{1,2})", key_f);  fiscal_end_month = int(m.group(2)) if m else None
    details["fiscal_end_month"] = fiscal_end_month
    key_q = _fiscal_key_from_quarter_label(latest_label, fiscal_end_month);  details["key_q"] = key_q
    if not key_q: details["status"] = "äºˆæƒ³ãƒ‡ãƒ¼ã‚¿æ¬ æ";  return details
    mask_same_fy = quarterly_df["æ±ºç®—æœŸ"].astype(str).apply(
        lambda s: _fiscal_key_from_quarter_label(s, fiscal_end_month) == key_q
    )
    cumulative_op = pd.to_numeric(quarterly_df.loc[mask_same_fy, "å–¶æ¥­ç›Š"], errors="coerce").sum(min_count=1)
    details["cumulative_op"] = None if pd.isna(cumulative_op) else float(cumulative_op)
    if pd.isna(cumulative_op): details["status"] = "äºˆæƒ³ãƒ‡ãƒ¼ã‚¿æ¬ æ";  return details
    if key_q != key_f: details["status"] = "ä¼šè¨ˆæœŸä¸ä¸€è‡´";  return details
    if full_op_val < 0 or (cumulative_op < 0 and full_op_val > 0): details["status"] = "äºˆæƒ³ãƒ‡ãƒ¼ã‚¿æ¬ æ";  return details
    progress = float(cumulative_op) / float(full_op_val) * 100.0
    if progress > 3000: details["status"] = "äºˆæƒ³ãƒ‡ãƒ¼ã‚¿æ¬ æ";  return details
    details["progress"] = round(progress, 1);  details["status"] = "OK";  return details

def log_progress_details(code: str, details: dict, log_path: str | None = None):
    print(
        f"[PROG] {code} label={details.get('latest_label')}  "
        f"key_q={details.get('key_q')}  key_f={details.get('key_f')}  "
        f"cum_op={details.get('cumulative_op')}  full_op={details.get('full_op_val')}  "
        f"status={details.get('status')}  progress={details.get('progress')}%"
    )
    if log_path:
        import csv
        header = ["code","latest_label","key_q","key_f","fiscal_end_month","cumulative_op","full_op_val","status","progress"]
        write_header = not os.path.isfile(log_path)
        with open(log_path, "a", newline="", encoding="utf-8-sig") as f:
            w = csv.writer(f)
            if write_header:
                w.writerow(header)
            w.writerow([
                code,
                details.get("latest_label"),
                details.get("key_q"),
                details.get("key_f"),
                details.get("fiscal_end_month"),
                details.get("cumulative_op"),
                details.get("full_op_val"),
                details.get("status"),
                details.get("progress"),
            ])

def _safe_growth(latest, prev):
    if pd.isna(latest) or pd.isna(prev): return None
    if prev == 0: return 100 if latest > 0 else (0 if latest == 0 else -100)
    return ((latest - prev) / prev) * 100

def _format_verdict_with_progress(qp, raw_verdict: str, score: int) -> str:
    """
    å›ºå®šãƒ†ãƒ³ãƒ—ãƒ¬ç‰ˆï¼ˆå¸¸ã«8è¡Œã€åŒã˜é †åºï¼‰ã€‚
      1: ã€ç·åˆè©•ä¾¡ã€‘â€¦
      2: [æ±ºç®—æœŸ/é€²æ—â€¦] or [é€²æ—ç‡ (æƒ…å ±ä¸è¶³)]
      3: ã‚¹ã‚³ã‚¢ â€¦ ç‚¹
      4: --- è©³ç´° ---
      5-8: è©³ç´°æœ¬æ–‡ï¼ˆæœ€å¤§4è¡Œã«ãƒˆãƒªãƒ ã€è¶³ã‚Šãªã‘ã‚Œã° 'ï¼ˆè©³ç´°ãªã—ï¼‰' ã§ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ï¼‰
    """
    overall_label = _get_overall_verdict_label(score)

    # é€²æ—ãƒ˜ãƒƒãƒ€
    prog_header = "[é€²æ—ç‡ (æƒ…å ±ä¸è¶³)]"
    if qp is not None:
        latest_label, progress, status, _ = qp
        if status == "OK":
            prog_header = f"[{latest_label}ï¼šé€²æ—{progress}%]"
        elif status in ("äºˆæƒ³æœªç™ºè¡¨", "äºˆæƒ³ã‚¼ãƒ­", "äºˆæƒ³ãƒ‡ãƒ¼ã‚¿æ¬ æ", "ä¼šè¨ˆæœŸä¸ä¸€è‡´"):
            prog_header = f"[{latest_label}ï¼šé€²æ—ç‡ ({status})]"

    score_header = f"ã‚¹ã‚³ã‚¢ {score} ç‚¹"

    # æœ¬æ–‡ã‚’æœ€å¤§4è¡Œã«æƒãˆã‚‹
    body_lines = [s.strip() for s in (raw_verdict or "").splitlines() if s.strip()]
    body_fixed = body_lines[:4]
    while len(body_fixed) < 4:
        body_fixed.append("ï¼ˆè©³ç´°ãªã—ï¼‰")

    lines = [
        f"ã€ç·åˆè©•ä¾¡ã€‘{overall_label}",
        prog_header,
        score_header,
        "--- è©³ç´° ---",
        *body_fixed[:4]
    ]
    return "\n".join(lines[:8])

def judge_and_score_performance(df: pd.DataFrame) -> tuple[str, int]:
    if df.empty or len(df) < 2:
        return "ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®ãŸã‚åˆ¤å®šã§ãã¾ã›ã‚“ã€‚", 0
    is_forecast = "äºˆ" in str(df.iloc[-1]["æ±ºç®—æœŸ"])
    df_latest = df.iloc[-1]
    df_prev = df.iloc[-2]
    comparison_period = "é€šæœŸäºˆæƒ³ vs å‰æœŸå®Ÿç¸¾" if is_forecast else "ç›´è¿‘å®Ÿç¸¾ vs å‰æœŸå®Ÿç¸¾ (é€šæœŸäºˆæƒ³ãƒ‡ãƒ¼ã‚¿æ¬ æ)"
    latest_sales, latest_op, latest_eps = df_latest.get("å£²ä¸Šé«˜"), df_latest.get("å–¶æ¥­ç›Š"), df_latest.get("ä¿®æ­£1æ ªç›Š")
    prev_sales, prev_op, prev_eps = df_prev.get("å£²ä¸Šé«˜"), df_prev.get("å–¶æ¥­ç›Š"), df_prev.get("ä¿®æ­£1æ ªç›Š")
    op_growth = _safe_growth(latest_op, prev_op)
    eps_growth = _safe_growth(latest_eps, prev_eps)
    sales_growth = _safe_growth(latest_sales, prev_sales)
    msgs, score = [f"ï¼ˆæ¯”è¼ƒæœŸé–“ï¼š{comparison_period}ï¼‰"], 0
    # EPS
    if eps_growth is not None:
        if eps_growth > 20: score += 3; msgs.append(f"ğŸŸ¢ EPSæˆé•·ç‡: {eps_growth:.1f}% (é«˜æˆé•·)")
        elif eps_growth > 10: score += 2; msgs.append(f"ğŸŸ¡ EPSæˆé•·ç‡: {eps_growth:.1f}% (å®‰å®šæˆé•·)")
        elif eps_growth > 0: score += 1; msgs.append(f"âšªï¸ EPSæˆé•·ç‡: {eps_growth:.1f}% (å¾®å¢—)")
        elif eps_growth == 0: msgs.append("âš«ï¸ EPSæˆé•·ç‡: 0.0% (æ¨ªã°ã„)")
        else: score -= 2; msgs.append(f"ğŸ”´ EPSæˆé•·ç‡: {eps_growth:.1f}% (æ¸›ç›Šæ³¨æ„)")
    else:
        msgs.append("EPSæˆé•·ç‡: ãƒ‡ãƒ¼ã‚¿æ¬ æ")
    # å–¶æ¥­ç›Š
    if op_growth is not None:
        if op_growth > 20: score += 2; msgs.append(f"ğŸŸ¢ å–¶æ¥­ç›Šæˆé•·ç‡: {op_growth:.1f}% (é«˜æˆé•·)")
        elif op_growth > 10: score += 1; msgs.append(f"ğŸŸ¡ å–¶æ¥­ç›Šæˆé•·ç‡: {op_growth:.1f}% (å®‰å®šæˆé•·)")
        elif op_growth < 0: score -= 1; msgs.append(f"ğŸ”´ å–¶æ¥­ç›Šæˆé•·ç‡: {op_growth:.1f}% (æ¸›ç›Šæ³¨æ„)")
        else: msgs.append(f"âšªï¸ å–¶æ¥­ç›Šæˆé•·ç‡: {op_growth:.1f}%")
    else:
        msgs.append("å–¶æ¥­ç›Šæˆé•·ç‡: ãƒ‡ãƒ¼ã‚¿æ¬ æ")
    # å£²ä¸Šé«˜
    if sales_growth is not None:
        if sales_growth > 10: score += 1; msgs.append(f"ğŸŸ¢ å£²ä¸Šé«˜æˆé•·ç‡: {sales_growth:.1f}% (é«˜æˆé•·)")
        elif sales_growth < 0: score -= 1; msgs.append(f"ğŸ”´ å£²ä¸Šé«˜æˆé•·ç‡: {sales_growth:.1f}% (æ¸›åæ³¨æ„)")
        else: msgs.append(f"âšªï¸ å£²ä¸Šé«˜æˆé•·ç‡: {sales_growth:.1f}%")
    else:
        msgs.append("å£²ä¸Šé«˜æˆé•·ç‡: ãƒ‡ãƒ¼ã‚¿æ¬ æ")
    if (op_growth is not None and op_growth > 0) and (eps_growth is not None and eps_growth > 0):
        msgs.insert(1, "ğŸ’¡ " + ("é€šæœŸäºˆæƒ³ã¯å¢—åå¢—ç›Šã®è¦‹è¾¼ã¿ã§ã™ã€‚" if is_forecast else "ç›´è¿‘å®Ÿç¸¾ã¯å¢—åå¢—ç›Šã§ã—ãŸã€‚"))
    return "\n".join(msgs), score

def calc_progress_from_df_op(quarterly_df: pd.DataFrame, forecast_series: pd.Series):
    """
    è¿”ã‚Šå€¤: (æœ€æ–°æ±ºç®—æœŸãƒ©ãƒ™ãƒ«, è¡¨ç¤ºç”¨%, ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹, DBä¿å­˜å€¤)
      - OK: å®Ÿæ•°
      - äºˆæƒ³æœªç™ºè¡¨: -3.0
      - äºˆæƒ³ã‚¼ãƒ­:   -2.0
      - äºˆæƒ³ãƒ‡ãƒ¼ã‚¿æ¬ æ: -1.0
      - ä¼šè¨ˆæœŸä¸ä¸€è‡´: -4.0
    """
    required_cols = ["å–¶æ¥­ç›Š", "æ±ºç®—æœŸ"]
    if quarterly_df is None or quarterly_df.empty or any(c not in quarterly_df.columns for c in required_cols):
        return None

    latest_row = quarterly_df.tail(1)
    if latest_row.empty:
        return None

    latest_label = str(latest_row["æ±ºç®—æœŸ"].iloc[0])

    # åˆ†æ¯ï¼ˆé€šæœŸäºˆæƒ³ï¼‰
    if forecast_series is None or forecast_series.empty or "å–¶æ¥­ç›Š" not in forecast_series:
        return (latest_label, 0.0, "äºˆæƒ³æœªç™ºè¡¨", -3.0)

    full_op_val = pd.to_numeric(forecast_series.get("å–¶æ¥­ç›Š"), errors="coerce")
    if pd.isna(full_op_val):
        return (latest_label, 0.0, "äºˆæƒ³ãƒ‡ãƒ¼ã‚¿æ¬ æ", -1.0)
    if float(full_op_val) == 0.0:
        return (latest_label, 0.0, "äºˆæƒ³ã‚¼ãƒ­", -2.0)

    key_f = _fiscal_key(str(forecast_series.get("æ±ºç®—æœŸ", "")))
    if not key_f:
        return (latest_label, 0.0, "äºˆæƒ³æœªç™ºè¡¨", -3.0)

    m = re.search(r"(\d{4})\.(\d{1,2})", key_f)
    fiscal_end_month = int(m.group(2)) if m else None

    # åˆ†å­ï¼ˆåŒä¸€FYã®å››åŠæœŸå–¶æ¥­ç›Šã‚’åˆç®—ï¼‰
    key_q = _fiscal_key_from_quarter_label(latest_label, fiscal_end_month)
    if not key_q:
        return (latest_label, 0.0, "äºˆæƒ³ãƒ‡ãƒ¼ã‚¿æ¬ æ", -1.0)

    mask_same_fy = quarterly_df["æ±ºç®—æœŸ"].astype(str).apply(
        lambda s: _fiscal_key_from_quarter_label(s, fiscal_end_month) == key_q
    )
    latest_cumulative_op = pd.to_numeric(quarterly_df.loc[mask_same_fy, "å–¶æ¥­ç›Š"], errors="coerce").sum(min_count=1)
    if pd.isna(latest_cumulative_op):
        return (latest_label, 0.0, "äºˆæƒ³ãƒ‡ãƒ¼ã‚¿æ¬ æ", -1.0)

    if key_q != key_f:
        return (latest_label, 0.0, "ä¼šè¨ˆæœŸä¸ä¸€è‡´", -4.0)

    if float(full_op_val) < 0 or (float(latest_cumulative_op) < 0 and float(full_op_val) > 0):
        return (latest_label, 0.0, "äºˆæƒ³ãƒ‡ãƒ¼ã‚¿æ¬ æ", -1.0)

    progress = float(latest_cumulative_op) / float(full_op_val) * 100.0
    if progress > 3000:
        return (æœ€æ–°_label, 0.0, "äºˆæƒ³ãƒ‡ãƒ¼ã‚¿æ¬ æ", -1.0)

    return (latest_label, round(progress, 1), "OK", progress)

def get_latest_announce_date(quarterly_df: pd.DataFrame) -> datetime | None:
    if quarterly_df is None or quarterly_df.empty or "ç™ºè¡¨æ—¥" not in quarterly_df.columns:
        return None
    if quarterly_df["ç™ºè¡¨æ—¥"].isna().all():
        return None
    try:
        return pd.to_datetime(quarterly_df["ç™ºè¡¨æ—¥"].iloc[-1])
    except Exception:
        return None

# ===== HTMLå‡ºåŠ› =====
def export_html(df: pd.DataFrame, code: str, out_html: str, qp_result=None, verdict_str: str = ""):
    x_actual_period = df["æ±ºç®—æœŸ"].tolist() if not df.empty and "æ±ºç®—æœŸ" in df.columns else []
    x_custom_labels = []
    for period in x_actual_period:
        label = f"{period}" + ("\n(é€šæœŸäºˆæƒ³)" if "äºˆ" in period else "\n(å®Ÿç¸¾)")
        x_custom_labels.append(label)
    x_full_plot = x_custom_labels

    if df.empty:
        print(f"[WARN] code={code}: ãƒ‡ãƒ¼ã‚¿ãŒãªã„ãŸã‚ã€HTMLå‡ºåŠ›ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™ã€‚")
        fig = go.Figure().update_layout(title=f"é€šæœŸå®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ãªã—ï¼ˆcode={code}ï¼‰")
        body = fig.to_html(include_plotlyjs="cdn", full_html=False)
    else:
        df_growth = df.copy()
        use_cols = [c for c in ["å£²ä¸Šé«˜", "å–¶æ¥­ç›Š", "ä¿®æ­£1æ ªç›Š"] if c in df_growth.columns]
        if use_cols:
            df_growth = df_growth.set_index("æ±ºç®—æœŸ")[use_cols].pct_change(fill_method=None)*100
        else:
            df_growth = pd.DataFrame(index=df_growth["æ±ºç®—æœŸ"])
        qp = qp_result

        title_suffix = ""
        if qp:
            latest_label, progress, status, _ = qp
            if status == "OK": title_suffix = f" / {latest_label}ï¼šé€²æ—{progress}%"
            elif status == "äºˆæƒ³æœªç™ºè¡¨": title_suffix = " / é€²æ—ç‡ (äºˆæƒ³æœªç™ºè¡¨)"
            elif status == "äºˆæƒ³ã‚¼ãƒ­": title_suffix = " / é€²æ—ç‡ (äºˆæƒ³ã‚¼ãƒ­)"
            elif status == "äºˆæƒ³ãƒ‡ãƒ¼ã‚¿æ¬ æ": title_suffix = " / é€²æ—ç‡ (äºˆæƒ³ãƒ‡ãƒ¼ã‚¿æ¬ æ)"
            elif status == "ä¼šè¨ˆæœŸä¸ä¸€è‡´": title_suffix = " / é€²æ—ç‡ (ä¼šè¨ˆæœŸä¸ä¸€è‡´)"

        fig = make_subplots(
            rows=2, cols=1, shared_xaxes=False,
            specs=[[{"secondary_y": True}], [{"secondary_y": False}]],
            vertical_spacing=0.12,
            subplot_titles=(f"é€šæœŸå®Ÿç¸¾æ¨ç§»ï¼ˆæ ªæ¢ãƒ‡ãƒ¼ã‚¿, code={code}ï¼‰{title_suffix}", "æˆé•·ç‡æ¨ç§»")
        )

        # å£²ä¸Šé«˜
        if "å£²ä¸Šé«˜" in df.columns and df["å£²ä¸Šé«˜"].notna().any():
            sales_full = (df["å£²ä¸Šé«˜"]/1e2).round(1).tolist()
            colors = ['rgba(173, 216, 230, 0.8)'] * (len(sales_full)-1)
            if len(sales_full) > 0:
                colors.append('rgba(173, 216, 230, 0.4)' if pd.notna(sales_full[-1]) else 'rgba(173, 216, 230, 0.2)')
            fig.add_trace(
                go.Bar(
                    x=x_full_plot, y=sales_full, name="å£²ä¸Šé«˜ï¼ˆå„„å††ï¼‰",
                    marker_color=colors, width=0.4,
                    customdata=df["æ±ºç®—æœŸ"].tolist(),
                    hovertemplate='<b>%{customdata}</b><br>å£²ä¸Šé«˜: %{y:.1f}å„„å††<extra></extra>',
                ),
                row=1, col=1, secondary_y=False
            )

        # å–¶æ¥­ç›Š
        if "å–¶æ¥­ç›Š" in df.columns and df["å–¶æ¥­ç›Š"].notna().any():
            op_full = (df["å–¶æ¥­ç›Š"]/1e2).round(1).tolist()
            fig.add_trace(
                go.Scatter(
                    x=x_full_plot[:-1], y=op_full[:-1], mode="lines+markers",
                    name="å–¶æ¥­ç›Šï¼ˆå®Ÿç¸¾ï¼‰", marker_symbol="circle",
                    customdata=df["æ±ºç®—æœŸ"].tolist()[:-1],
                    hovertemplate='<b>%{customdata}</b><br>å–¶æ¥­ç›Š: %{y:.1f}å„„å††<extra></extra>',
                    showlegend=True
                ),
                row=1, col=1, secondary_y=False
            )
            if len(op_full) >= 2 and pd.notna(op_full[-1]):
                fig.add_trace(
                    go.Scatter(
                        x=[x_full_plot[-2], x_full_plot[-1]], y=[op_full[-2], op_full[-1]],
                        mode="lines", name="å–¶æ¥­ç›Šï¼ˆäºˆï¼‰æ¥ç¶š",
                        line=dict(dash='dot'), showlegend=False
                    ),
                    row=1, col=1, secondary_y=False
                )
                fig.add_trace(
                    go.Scatter(
                        x=[x_full_plot[-1]], y=[op_full[-1]], mode="markers",
                        name="å–¶æ¥­ç›Šï¼ˆäºˆï¼‰",
                        marker=dict(symbol="circle-open"),
                        customdata=[df["æ±ºç®—æœŸ"].iloc[-1]],
                        hovertemplate='<b>%{customdata}</b><br>å–¶æ¥­ç›Š(äºˆ): %{y:.1f}å„„å††<extra></extra>',
                        showlegend=False
                    ),
                    row=1, col=1, secondary_y=False
                )

        # EPS
        if "ä¿®æ­£1æ ªç›Š" in df.columns and df["ä¿®æ­£1æ ªç›Š"].notna().any():
            eps_full = df["ä¿®æ­£1æ ªç›Š"].round(1).tolist()
            fig.add_trace(
                go.Scatter(
                    x=x_full_plot[:-1], y=eps_full[:-1], mode="lines+markers",
                    name="EPSï¼ˆå††ï¼‰", marker_symbol="diamond",
                    customdata=df["æ±ºç®—æœŸ"].tolist()[:-1],
                    hovertemplate='<b>%{customdata}</b><br>EPS: %{y:.1f}å††<extra></extra>',
                    showlegend=True
                ),
                row=1, col=1, secondary_y=True
            )
            if len(eps_full) >= 2 and pd.notna(eps_full[-1]):
                fig.add_trace(
                    go.Scatter(
                        x=[x_full_plot[-2], x_full_plot[-1]], y=[eps_full[-2], eps_full[-1]],
                        mode="lines", name="EPSï¼ˆäºˆï¼‰æ¥ç¶š",
                        line=dict(dash='dot'), showlegend=False
                    ),
                    row=1, col=1, secondary_y=True
                )
                fig.add_trace(
                    go.Scatter(
                        x=[x_full_plot[-1]], y=[eps_full[-1]], mode="markers",
                        name="EPSï¼ˆäºˆï¼‰",
                        marker=dict(symbol="diamond-open"),
                        customdata=[df["æ±ºç®—æœŸ"].iloc[-1]],
                        hovertemplate='<b>%{customdata}</b><br>EPS(äºˆ): %{y:.1f}å††<extra></extra>',
                        showlegend=False
                    ),
                    row=1, col=1, secondary_y=True
                )

        # é…å½“
        if "ä¿®æ­£1æ ªé…" in df.columns and df["ä¿®æ­£1æ ªé…"].notna().any():
            div_full = df["ä¿®æ­£1æ ªé…"].round(1).tolist()
            fig.add_trace(
                go.Scatter(
                    x=x_full_plot[:-1], y=div_full[:-1], mode="lines+markers",
                    name="é…å½“ï¼ˆå††ï¼‰", marker_symbol="x",
                    customdata=df["æ±ºç®—æœŸ"].tolist()[:-1],
                    hovertemplate='<b>%{customdata}</b><br>é…å½“: %{y:.1f}å††<extra></extra>',
                    showlegend=True
                ),
                row=1, col=1, secondary_y=True
            )
            if len(div_full) >= 2 and pd.notna(div_full[-1]):
                fig.add_trace(
                    go.Scatter(
                        x=[x_full_plot[-2], x_full_plot[-1]], y=[div_full[-2], div_full[-1]],
                        mode="lines", name="é…å½“ï¼ˆäºˆï¼‰æ¥ç¶š",
                        line=dict(dash='dot'), showlegend=False
                    ),
                    row=1, col=1, secondary_y=True
                )
                fig.add_trace(
                    go.Scatter(
                        x=[x_full_plot[-1]], y=[div_full[-1]], mode="markers",
                        name="é…å½“ï¼ˆäºˆï¼‰",
                        marker=dict(symbol="x-open"),
                        customdata=[df["æ±ºç®—æœŸ"].iloc[-1]],
                        hovertemplate='<b>%{customdata}</b><br>é…å½“(äºˆ): %{y:.1f}å††<extra></extra>',
                        showlegend=False
                    ),
                    row=1, col=1, secondary_y=True
                )

        # è»¸è¨­å®šãªã©
        try:
            max_sales_op = df[["å£²ä¸Šé«˜", "å–¶æ¥­ç›Š"]].apply(lambda s: s/1e2).stack().max()
        except Exception:
            max_sales_op = None
        max_sales_op_range = (max_sales_op * 1.1) if (max_sales_op and max_sales_op > 0.5) else None
        try:
            max_eps_div = df[["ä¿®æ­£1æ ªç›Š", "ä¿®æ­£1æ ªé…"]].stack().max()
        except Exception:
            max_eps_div = None
        max_eps_div_range = (max_eps_div * 1.1) if (max_eps_div and max_eps_div > 0.5) else None

        fig.update_xaxes(title_text="æ±ºç®—æœŸ", tickangle=0, type='category',
                         ticktext=x_full_plot, tickvals=x_full_plot, row=1, col=1)
        fig.update_yaxes(title_text="é‡‘é¡ï¼ˆå„„å††ï¼‰", range=[None, max_sales_op_range], row=1, col=1, secondary_y=False)
        fig.update_yaxes(title_text="EPS / é…å½“ï¼ˆå††ï¼‰", range=[None, max_eps_div_range], row=1, col=1, secondary_y=True)

        # æˆé•·ç‡
        x_full_growth_plot = x_full_plot[1:]
        if not df_growth.empty:
            if "å£²ä¸Šé«˜" in df_growth.columns and df_growth["å£²ä¸Šé«˜"].notna().any():
                sales_growth_full = df_growth["å£²ä¸Šé«˜"].tolist()
                fig.add_trace(
                    go.Scatter(
                        x=x_full_growth_plot[:-1], y=sales_growth_full[:-1], mode="lines+markers",
                        name="å£²ä¸Šé«˜æˆé•·ç‡ï¼ˆ%ï¼‰",
                        hovertemplate='å£²ä¸Šé«˜æˆé•·ç‡: %{y:.1f}%%<extra></extra>', showlegend=True
                    ),
                    row=2, col=1
                )
                if len(sales_growth_full) >= 2 and pd.notna(sales_growth_full[-1]):
                    fig.add_trace(
                        go.Scatter(
                            x=[x_full_growth_plot[-2], x_full_growth_plot[-1]], y=[sales_growth_full[-2], sales_growth_full[-1]],
                            mode="lines", name="å£²ä¸Šé«˜ï¼ˆäºˆï¼‰æ¥ç¶šï¼ˆæˆé•·ç‡ï¼‰",
                            line=dict(dash='dot'),
                            hovertemplate='å£²ä¸Šé«˜(äºˆ)æ¥ç¶š (æˆé•·ç‡)<extra></extra>', showlegend=False
                        ),
                        row=2, col=1
                    )
                    fig.add_trace(
                        go.Scatter(
                            x=[x_full_growth_plot[-1]], y=[sales_growth_full[-1]], mode="markers",
                            name="å£²ä¸Šé«˜æˆé•·ç‡ï¼ˆäºˆï¼‰", marker_symbol="square-open",
                            customdata=[df["æ±ºç®—æœŸ"].iloc[-1]],
                            hovertemplate=f'<b>%{{customdata}}</b><br>å£²ä¸Šé«˜æˆé•·ç‡(äºˆ): %{{y:.1f}}%%<extra></extra>',
                            showlegend=True
                        ),
                        row=2, col=1
                    )

            if "å–¶æ¥­ç›Š" in df_growth.columns and df_growth["å–¶æ¥­ç›Š"].notna().any():
                op_growth_full = df_growth["å–¶æ¥­ç›Š"].tolist()
                fig.add_trace(
                    go.Scatter(
                        x=x_full_growth_plot[:-1], y=op_growth_full[:-1], mode="lines+markers",
                        name="å–¶æ¥­ç›Šæˆé•·ç‡ï¼ˆ%ï¼‰",
                        hovertemplate='å–¶æ¥­ç›Šæˆé•·ç‡: %{y:.1f}%%<extra></extra>', showlegend=True
                    ),
                    row=2, col=1
                )
                if len(op_growth_full) >= 2 and pd.notna(op_growth_full[-1]):
                    fig.add_trace(
                        go.Scatter(
                            x=[x_full_growth_plot[-2], x_full_growth_plot[-1]], y=[op_growth_full[-2], op_growth_full[-1]],
                            mode="lines", name="å–¶æ¥­ç›Šï¼ˆäºˆï¼‰æ¥ç¶šï¼ˆæˆé•·ç‡ï¼‰",
                            line=dict(dash='dot'),
                            hovertemplate='å–¶æ¥­ç›Š(äºˆ)æ¥ç¶š (æˆé•·ç‡)<extra></extra>', showlegend=False
                        ),
                        row=2, col=1
                    )
                    fig.add_trace(
                        go.Scatter(
                            x=[x_full_growth_plot[-1]], y=[op_growth_full[-1]], mode="markers",
                            name="å–¶æ¥­ç›Šæˆé•·ç‡ï¼ˆäºˆï¼‰", marker_symbol="circle-open",
                            customdata=[df["æ±ºç®—æœŸ"].iloc[-1]],
                            hovertemplate=f'<b>%{{customdata}}</b><br>å–¶æ¥­ç›Šæˆé•·ç‡(äºˆ): %{{y:.1f}}%%<extra></extra>',
                            showlegend=True
                        ),
                        row=2, col=1
                    )

            if "ä¿®æ­£1æ ªç›Š" in df_growth.columns and df_growth["ä¿®æ­£1æ ªç›Š"].notna().any():
                eps_growth_full = df_growth["ä¿®æ­£1æ ªç›Š"].tolist()
                fig.add_trace(
                    go.Scatter(
                        x=x_full_growth_plot[:-1], y=eps_growth_full[:-1], mode="lines+markers",
                        name="EPSæˆé•·ç‡ï¼ˆ%ï¼‰",
                        hovertemplate='EPSæˆé•·ç‡: %{y:.1f}%%<extra></extra>', showlegend=True
                    ),
                    row=2, col=1
                )
                if len(eps_growth_full) >= 2 and pd.notna(eps_growth_full[-1]):
                    fig.add_trace(
                        go.Scatter(
                            x=[x_full_growth_plot[-2], x_full_growth_plot[-1]], y=[eps_growth_full[-2], eps_growth_full[-1]],
                            mode="lines", name="EPSï¼ˆäºˆï¼‰æ¥ç¶šï¼ˆæˆé•·ç‡ï¼‰",
                            line=dict(dash='dot'),
                            hovertemplate='EPS(äºˆ)æ¥ç¶š (æˆé•·ç‡)<extra></extra>', showlegend=False
                        ),
                        row=2, col=1
                    )
                    fig.add_trace(
                        go.Scatter(
                            x=[x_full_growth_plot[-1]], y=[eps_growth_full[-1]], mode="markers",
                            name="EPSæˆé•·ç‡ï¼ˆäºˆï¼‰", marker_symbol="diamond-open",
                            customdata=[df["æ±ºç®—æœŸ"].iloc[-1]],
                            hovertemplate=f'<b>%{{customdata}}</b><br>EPSæˆé•·ç‡(äºˆ): %{{y:.1f}}%%<extra></extra>',
                            showlegend=True
                        ),
                        row=2, col=1
                    )

        fig.update_xaxes(title_text="æ±ºç®—æœŸ", tickangle=0, type='category',
                         ticktext=x_full_growth_plot, tickvals=x_full_growth_plot, row=2, col=1)
        fig.update_yaxes(title_text="æˆé•·ç‡ï¼ˆ%ï¼‰", row=2, col=1)
        fig.update_layout(height=900, legend=dict(orientation="v"), margin=dict(l=60, r=40, t=60, b=100))
        body = fig.to_html(include_plotlyjs="cdn", full_html=False)

    verdict_html_content = (verdict_str or "").replace('\n', '<br>')
    verdict_html = (
        f'<div id="verdict_placeholder" style="margin-top:20px; color:#c9302c; font-weight:600; '
        f'text-align:left; white-space:pre-wrap; border:1px solid #ccc; padding:10px; '
        f'margin-left:10%; margin-right:10%; background-color:#f9f9f9;">'
        f'{verdict_html_content}'
        f'</div>'
    )
    html = f"""<!doctype html><html lang="ja"><meta charset="utf-8">
    <title>Fundamentals {code}</title>
    <style>body{{font-family:system-ui,-apple-system,'Noto Sans JP',sans-serif;margin:16px;}}</style>
    {body}
    {verdict_html}
    </html>"""
    with open(out_html, "w", encoding="utf-8") as f:
        f.write(html)
    print(f"[INFO] saved HTML: {out_html}")

# ===== ãƒ¯ãƒ¼ã‚«ãƒ¼ =====
async def process_single_code(code: str, out_dir: str, session: aiohttp.ClientSession, semaphore: asyncio.Semaphore) -> dict:
    code_full = str(code).strip()
    if not code_full or not re.match(r'^[0-9A-Za-z]{4,}$', code_full):
        print(f"[ERROR] {code_full}: éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰å½¢å¼ä¸æ­£ã€‚ã‚¹ã‚­ãƒƒãƒ—ã€‚")
        return {'status': 'ERROR', 'code': code_full, 'message': "invalid code", 'progress_percent': None}
    # ---- å¸‚å ´ãŒETF/æŒ‡æ•°ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæ ªæ¢URLã‚’ä½œã‚‰ãªã„ï¼‰----
    market = _get_market_from_db(code_full)
    if _is_skip_market(market):
        print(f"[SKIP(MARKET)] {code_full}: å¸‚å ´='{market}' ã®ãŸã‚æ ªæ¢URLç”Ÿæˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return {'status': 'SKIP', 'code': code_full, 'message': f"skip by market ({market})", 'progress_percent': None}
    
    opt = _ARGS
    # DBã‚¹ã‚­ãƒƒãƒ—ã¯å®šæ•°ã§æ—¢å®šONã€‚--no-db-skip ã‚’ä»˜ã‘ãŸæ™‚ã ã‘ç„¡åŠ¹åŒ–ã€‚
    use_db_skip = ENABLE_DB_SKIP and (not bool(getattr(opt, 'no_db_skip', False)))
    # é–¾å€¤ï¼šæŒ‡å®šãªã‘ã‚Œã°å®šæ•°ã‚’ä½¿ã†
    skip_days = getattr(opt, 'skip_recent_days', None)
    if skip_days is None:
        skip_days = SKIP_RECENT_DAYS_DEFAULT
    force_refresh = bool(getattr(opt, 'force_refresh', False))

    # ---- DBã‚­ãƒ£ãƒƒã‚·ãƒ¥äº‹å‰ã‚¹ã‚­ãƒƒãƒ—ï¼ˆHTTPå‰ï¼‰----
    if use_db_skip and skip_days is not None and not force_refresh:
        cached_dt, cached_status = db_get_cached_announce(code_full)
        if cached_dt is not None:
            if cached_status in BAD_LAST_STATUSES:
                print(f"[DB-SKIP-BYPASS] {code_full}: last_status={cached_status} ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã›ãšå–å¾—ã¸ã€‚")
            else:
                # 3ã‹æœˆ/6ã‹æœˆã‚¹ã‚­ãƒƒãƒ—ï¼ˆæˆåŠŸéŠ˜æŸ„ã ã‘6ã‹æœˆæ‹¡å¼µï¼‰
                SKIP_3M = int(skip_days or 84)
                SKIP_6M = 168
                delta_days = (datetime.now().date() - cached_dt.date()).days

                if cached_status in {"OK", "FETCHED"}:
                    effective = SKIP_6M if delta_days >= SKIP_3M else SKIP_3M
                elif cached_status in {"ANNOUNCE_ONLY", "EMPTY_QUARTERLY"}:
                    effective = SKIP_3M
                else:
                    effective = SKIP_3M

                if delta_days < effective:
                    policy = "6m" if (cached_status in {"OK","FETCHED"} and effective == SKIP_6M) else "3m"
                    print(f"[SKIP(DB)] {code_full}: last_status={cached_status}, latest={cached_dt.date()}, "
                          f"{delta_days}d < {effective}d (policy={policy})")
                    return {'status': 'SKIP', 'code': code_full,
                            'message': f"db-recent-{cached_status}-{policy}", 'progress_percent': None}

    async with semaphore:
        try:
            df_full_year, df_quarterly = await asyncio.gather(
                fetch_full_year_financials(code_full, session),
                fetch_quarterly_financials(code_full, session)
            )

            # å–å¾—ã§ããŸã‚‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›´æ–°ï¼ˆæ­£å¸¸å° or announce-onlyï¼‰
            latest_ad = get_latest_announce_date(df_quarterly)
            if latest_ad is None:
                # å››åŠæœŸãŒç©ºã§ã‚‚ãƒšãƒ¼ã‚¸ã‹ã‚‰ç™ºè¡¨æ—¥ã ã‘æ‹¾ã†
                latest_ad = await fetch_latest_announce_date_only(session, code_full)

            if latest_ad is not None:
                st = "OK" if (df_quarterly is not None and not df_quarterly.empty) else "ANNOUNCE_ONLY"
                db_upsert_cached_announce(code_full, latest_ad, st)
            else:
                db_upsert_cached_announce(code_full, None, "EMPTY_QUARTERLY")

            df_forecast_row = pd.Series()
            if not df_full_year.empty and "æ±ºç®—æœŸ" in df_full_year.columns:
                _m = df_full_year["æ±ºç®—æœŸ"].astype(str).str.contains("äºˆ", na=False)
                if _m.any():
                    df_forecast_row = df_full_year[_m].iloc[-1]

            out_html = os.path.join(out_dir, f"finance_{code_full}.html")
            verdict, score = judge_and_score_performance(df_full_year)
            overall_alpha = _get_overall_alpha(score)  # â˜… ã‚¹ã‚³ã‚¢ã‹ã‚‰ã‚¢ãƒ«ãƒ•ã‚¡ã‚’ç¢ºå®š
            qp = calc_progress_from_df_op(df_quarterly, df_forecast_row)
            progress_percent_db = qp[3] if qp is not None else None

            # é€²æ—å¼ãƒ­ã‚°
            _log_on = bool(getattr(opt, 'log_progress', False))
            _log_file = getattr(opt, 'log_file', 'progress_debug.csv')
            details = compute_progress_details(df_quarterly, df_forecast_row)
            _force_log = (progress_percent_db == -1.0)
            if _log_on or _force_log:
                log_progress_details(code_full, details, (_log_file if _log_on else None))

            formatted_v = _format_verdict_with_progress(qp, verdict, score)
            export_html(df_full_year, code_full, out_html=out_html, qp_result=qp, verdict_str=formatted_v)
            print(f"[OK] {code_full} done. (Score: {score} points, Alpha: {overall_alpha}, Progress: {progress_percent_db}%)")

            return {
                'status': 'OK',
                'code': code_full,
                'score': score,
                'overall_alpha': overall_alpha,     # â˜… è¿”å´
                'progress_percent': progress_percent_db,
                'formatted_verdict': formatted_v,
                'out_html': out_html,
            }

        except aiohttp.ClientResponseError as e:
            status_code = getattr(e, "status", None)
            # ä¾‹å¤–æ™‚ã‚‚ announce-only ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            latest_ad = await fetch_latest_announce_date_only(session, code_full)
            if latest_ad is not None:
                db_upsert_cached_announce(code_full, latest_ad, "ANNOUNCE_ONLY")
            else:
                err_key = f"ERROR_{status_code}" if status_code in (429, 500, 502, 503, 504) else "HTTP_ERROR"
                db_upsert_cached_announce(code_full, None, err_key)
            print(f"[ERROR] {code_full}: HTTPã‚¨ãƒ©ãƒ¼ - {status_code}: {e.message}")
            return {'status': 'ERROR', 'code': code_full, 'message': f"HTTPã‚¨ãƒ©ãƒ¼: {status_code}", 'progress_percent': None}

        except aiohttp.ClientConnectorError as e:
            latest_ad = await fetch_latest_announce_date_only(session, code_full)
            if latest_ad is not None:
                db_upsert_cached_announce(code_full, latest_ad, "ANNOUNCE_ONLY")
            else:
                db_upsert_cached_announce(code_full, None, "CONN_ERROR")
            print(f"[ERROR] {code_full}: æ¥ç¶šã‚¨ãƒ©ãƒ¼ - {type(e).__name__}: {e}")
            return {'status': 'ERROR', 'code': code_full, 'message': f"æ¥ç¶šã‚¨ãƒ©ãƒ¼: {type(e).__name__}", 'progress_percent': None}

        except asyncio.TimeoutError as e:
            latest_ad = await fetch_latest_announce_date_only(session, code_full)
            if latest_ad is not None:
                db_upsert_cached_announce(code_full, latest_ad, "ANNOUNCE_ONLY")
            else:
                db_upsert_cached_announce(code_full, None, "TIMEOUT")
            print(f"[ERROR] {code_full}: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ - {type(e).__name__}: {e}")
            return {'status': 'ERROR', 'code': code_full, 'message': "TIMEOUT", 'progress_percent': None}

        except RuntimeError as e:
            latest_ad = await fetch_latest_announce_date_only(session, code_full)
            if latest_ad is not None:
                db_upsert_cached_announce(code_full, latest_ad, "ANNOUNCE_ONLY")
            else:
                db_upsert_cached_announce(code_full, None, "PARSE_ERROR")
            print(f"[ERROR] {code_full}: å‡¦ç†ã‚¨ãƒ©ãƒ¼ - {type(e).__name__}: {e}")
            return {'status': 'ERROR', 'code': code_full, 'message': f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {type(e).__name__}", 'progress_percent': None}

        except Exception as e:
            latest_ad = await fetch_latest_announce_date_only(session, code_full)
            if latest_ad is not None:
                db_upsert_cached_announce(code_full, latest_ad, "ANNOUNCE_ONLY")
            else:
                db_upsert_cached_announce(code_full, None, "UNKNOWN_ERROR")
            print(f"[ERROR] {code_full}: äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ - {type(e).__name__}: {e}")
            return {'status': 'ERROR', 'code': code_full, 'message': f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {type(e).__name__}", 'progress_percent': None}

# ===== ãƒ¡ã‚¤ãƒ³ =====
async def main_async(target_code: str | None = None):
    out_dir = r"H:\desctop\æ ªæ”»ç•¥\1-ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°è‡ªå‹•åŒ–ãƒ—ãƒ­ã‚°ãƒ©ãƒ \main\output_data\graph"
    os.makedirs(out_dir, exist_ok=True)

    if target_code:
        codes = {target_code}
        print(f"[INFO] æŒ‡å®šã‚³ãƒ¼ãƒ‰ {target_code} ã®ã¿å‡¦ç†ã—ã¾ã™")
    else:
        try:
            master = pd.read_csv(MASTER_CODES_PATH, encoding="utf8", sep=",", engine="python", dtype={'ã‚³ãƒ¼ãƒ‰': str})
            codes = set(master["ã‚³ãƒ¼ãƒ‰"].astype(str))
            print(f"[INFO] {len(codes)} éŠ˜æŸ„ã‚’å‡¦ç†ã—ã¾ã™ï¼ˆéåŒæœŸå‡¦ç†é–‹å§‹ï¼‰")
        except FileNotFoundError:
            print(f"[CRITICAL ERROR] ãƒã‚¹ã‚¿ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {MASTER_CODES_PATH}")
            return

    concurrency = getattr(_ARGS, 'workers', ASYNC_CONCURRENCY_LIMIT) or ASYNC_CONCURRENCY_LIMIT
    semaphore = asyncio.Semaphore(concurrency)
    print(f"[INFO] aiohttp + asyncioã§æœ€å¤§ {concurrency} ã®ä¸¦åˆ—ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’è¡Œã„ã¾ã™ã€‚")

    async with aiohttp.ClientSession(headers=HEADERS, trust_env=True) as session:
        tasks = [process_single_code(code, out_dir, session, semaphore) for code in codes]
        all_results = await asyncio.gather(*tasks, return_exceptions=True)

    successful_results, error_count, skip_count = [], 0, 0
    for result in all_results:
        if isinstance(result, dict):
            st = result.get('status')
            if st == 'OK':
                successful_results.append(result)
            elif st == 'SKIP':
                skip_count += 1
            else:
                error_count += 1
        elif isinstance(result, Exception):
            error_count += 1
            print(f"[SUMMARY] äºˆæœŸã›ã¬ä¾‹å¤–: {type(result).__name__}: {result}")

    # DBä¿å­˜ï¼ˆ--no-db ãŒç„¡ã„æ™‚ã ã‘ï¼‰
    if successful_results and not getattr(_ARGS, 'no_db', False):
        batch_record_to_sqlite(successful_results)
    elif successful_results:
        print(f"[DB][SKIP] --no-db æŒ‡å®šã®ãŸã‚ {len(successful_results)} ä»¶ã®DBæ›¸ãè¾¼ã¿ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")

    print("=" * 30)
    print(f"[DONE] å‡¦ç†å®Œäº†ã€‚æˆåŠŸ: {len(successful_results)}ä»¶, ã‚¹ã‚­ãƒƒãƒ—: {skip_count}ä»¶, ã‚¨ãƒ©ãƒ¼: {error_count}ä»¶.")
    print("=" * 30)

def main(target_code: str | None = None):
    try:
        main_async_coro = main_async(target_code=target_code)
        if sys.platform == "win32":
            asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
        asyncio.run(main_async_coro)
    except Exception as e:
        print(f"[CRITICAL ERROR] ãƒ¡ã‚¤ãƒ³å‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}", file=sys.stderr)
        sys.exit(1)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='æ ªæ¢ã‹ã‚‰è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆã—ã¾ã™ã€‚ï¼ˆéåŒæœŸãƒ»é«˜é€ŸåŒ–å¯¾å¿œï¼‰')
    parser.add_argument('code', nargs='?', default=None, help='å‡¦ç†ã™ã‚‹éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ (çœç•¥æ™‚ã¯ãƒã‚¹ã‚¿ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«å†…ã®å…¨ã‚³ãƒ¼ãƒ‰)')
    parser.add_argument('--workers', type=int, default=ASYNC_CONCURRENCY_LIMIT, help='åŒæ™‚ä¸¦åˆ—æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 15ï¼‰')
    parser.add_argument('--log-progress', action='store_true', help='é€²æ—ã®å¼ã¨ä½¿ã£ãŸå€¤ã‚’æ¨™æº–å‡ºåŠ›ã«å‡ºã™')
    parser.add_argument('--log-file', type=str, default='progress_debug.csv', help='é€²æ—ãƒ­ã‚°ã®CSVå‡ºåŠ›å…ˆ')
    parser.add_argument('--skip-recent-days', type=int, default=None, help='æœ€æ–°ã®æ±ºç®—ç™ºè¡¨æ—¥ã‹ã‚‰ã“ã®æ—¥æ•°ä»¥å†…ãªã‚‰å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæœªæŒ‡å®šãªã‚‰å®šæ•°ã‚’ä½¿ç”¨ï¼‰')
    parser.add_argument('--force-refresh', action='store_true', help='DBã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç„¡è¦–ã—ã¦å¿…ãšå–å¾—ã™ã‚‹')
    parser.add_argument('--no-db-skip', action='store_true', help='DBã‚¹ã‚­ãƒƒãƒ—æ©Ÿèƒ½ã‚’ç„¡åŠ¹åŒ–ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯æœ‰åŠ¹ï¼‰')
    parser.add_argument('--no-db', action='store_true', help='DBæ›¸ãè¾¼ã¿ã‚’ç„¡åŠ¹åŒ–ï¼ˆfinance_notes ã¸ä¿å­˜ã—ãªã„ï¼‰')

    args, _unknown = parser.parse_known_args()
    _GLOBALS = globals()
    _GLOBALS['_ARGS'] = args

    try:
        main(target_code=args.code)
    except Exception:
        sys.exit(1)
